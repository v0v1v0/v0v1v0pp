<div class="container">

<table style="width: 100%;"><tr>
<td>kmspc</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>MULTISPATI-PCA clustering</h2>

<h3>Description</h3>

<p>MULTISPATI-PCA clustering
</p>


<h3>Usage</h3>

<pre><code class="language-R">kmspc(
  data,
  variables,
  number_cluster = 3:5,
  explainedVariance = 70,
  ldist = 0,
  udist = 40,
  center = TRUE,
  fuzzyness = 1.2,
  distance = "euclidean",
  zero.policy = FALSE,
  only_spca_results = TRUE,
  all_results = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>sf object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>variables</code></td>
<td>
<p>variables to use for clustering, if missing, all numeric
variables will be used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>number_cluster</code></td>
<td>
<p><code>numeric</code> vector with number of final clusters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>explainedVariance</code></td>
<td>
<p><code>numeric</code> number in percentage of explained variance
from PCA analysis to keep and make cluster process</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ldist</code></td>
<td>
<p><code>numeric</code> lower distance bound to identify neighbors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>udist</code></td>
<td>
<p><code>numeric</code> upper distance bound to identify neighbors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>
<p>a logical or numeric value, centring option
if TRUE, centring by the mean
if FALSE no centring
if a numeric vector, its length must be equal to the number of
columns of the data frame df and gives the decentring</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fuzzyness</code></td>
<td>
<p>A number greater than 1 giving the degree of fuzzification.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>distance</code></td>
<td>
<p><code>character</code> Must be one of the following:
If "euclidean", the mean square error, if "manhattan", the mean
absolute error is computed. Abbreviations are also accepted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>zero.policy</code></td>
<td>
<p>default NULL, use global option value;
if FALSE stop with error for any empty neighbors sets,
if TRUE permit the weights list to be formed with zero-length
weights vectors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>only_spca_results</code></td>
<td>
<p><code>logical</code>; should return both PCA and sPCA
results (<code>FALSE</code>), or only sPCA results (<code>TRUE</code>)? This can be a
time consuming process if there are multiple variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>all_results</code></td>
<td>
<p><code>logical</code>; should return the results from the
sPCA and PCA call?</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a list with classification results and indices to select best number of
clusters.
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(sf)
data(wheat, package = 'paar')

# Transform the data.frame into a sf object
wheat_sf &lt;- st_as_sf(wheat,
                     coords = c('x', 'y'),
                     crs = 32720)

# Run the kmspc function
kmspc_results &lt;- kmspc(wheat_sf,
                       number_cluster = 2:4)

# Print the summaryResults
kmspc_results$summaryResults

# Print the indices
kmspc_results$indices

# Print the cluster
head(kmspc_results$cluster, 5)

# Combine the results in a single object
wheat_clustered &lt;- cbind(wheat_sf, kmspc_results$cluster)

# Plot the results
plot(wheat_clustered[, "Cluster_2"])
</code></pre>


</div>