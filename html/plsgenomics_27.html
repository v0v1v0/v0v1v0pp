<div class="container">

<table style="width: 100%;"><tr>
<td>multinom.spls.stab</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Stability selection procedure  to estimate probabilities of selection of
covariates for the multinomial-SPLS method</h2>

<h3>Description</h3>

<p>The function <code>multinom.spls.stab</code> train a multinomial-spls model for 
each candidate values <code>(ncomp, lambda.l1, lambda.ridge)</code> of 
hyper-parameters on multiple sub-samplings in the data. The stability 
selection procedure selects the covariates that are selected by most of the 
models among the grid of hyper-parameters, following the procedure 
described in Durif et al.  (2018). Candidates values for <code>ncomp</code>, 
<code>lambda.l1</code> and <code>lambda.l2</code> are respectively given by 
the input arguments <code>ncomp.range</code>, <code>lambda.l1.range</code> 
and <code>lambda.l2.range</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">multinom.spls.stab(
  X,
  Y,
  lambda.ridge.range,
  lambda.l1.range,
  ncomp.range,
  adapt = TRUE,
  maxIter = 100,
  svd.decompose = TRUE,
  ncores = 1,
  nresamp = 100,
  center.X = TRUE,
  scale.X = FALSE,
  weighted.center = TRUE,
  seed = NULL,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>a (n x p) data matrix of predictors. <code>X</code> must be a matrix. 
Each row corresponds to an observation and each column to a 
predictor variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>a (n) vector of (continuous) responses. <code>Y</code> must be a 
vector or a one column matrix. It contains the response variable for 
each observation.  <code>Y</code> should take values in {0,...,nclass-1}, 
where nclass is the number of class.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.ridge.range</code></td>
<td>
<p>a vector of positive real values. 
<code>lambda.ridge</code> is the Ridge regularization parameter for the 
RIRLS algorithm (see details), the optimal value will be chosen among
<code>lambda.ridge.range</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.l1.range</code></td>
<td>
<p>a vecor of positive real values, in [0,1]. 
<code>lambda.l1</code> is the sparse penalty parameter for the dimension 
reduction step by sparse PLS (see details), the optimal value will be 
chosen among <code>lambda.l1.range</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncomp.range</code></td>
<td>
<p>a vector of positive integers. <code>ncomp</code> is the 
number of PLS components. The optimal value will be chosen 
among <code>ncomp.range</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adapt</code></td>
<td>
<p>a boolean value, indicating whether the sparse PLS selection 
step sould be adaptive or not (see details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxIter</code></td>
<td>
<p>a positive integer, the maximal number of iterations in the 
RIRLS algorithm (see details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>svd.decompose</code></td>
<td>
<p>a boolean parameter. <code>svd.decompose</code> indicates 
wether or not the predictor matrix <code>Xtrain</code> should be decomposed by 
SVD (singular values decomposition) for the RIRLS step (see details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncores</code></td>
<td>
<p>a positve integer, indicating the number of cores that the 
cross-validation is allowed to use for parallel computation (see details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nresamp</code></td>
<td>
<p>number of resamplings of the data to estimate the probility 
of selection for each covariate, default is 100.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center.X</code></td>
<td>
<p>a boolean value indicating whether the data matrices 
<code>Xtrain</code> and <code>Xtest</code> (if provided) should be centered or not.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale.X</code></td>
<td>
<p>a boolean value indicating whether the data matrices 
<code>Xtrain</code> and <code>Xtest</code> (if provided) should be scaled or not 
(<code>scale.X=TRUE</code> implies <code>center.X=TRUE</code>) in the spls step.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weighted.center</code></td>
<td>
<p>a boolean value indicating whether the centering 
should take into account the weighted l2 metric or not in the SPLS step.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>a positive integer value (default is NULL). If non NULL, 
the seed for pseudo-random number generation is set accordingly.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>a boolean parameter indicating the verbosity.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The columns of the data matrices <code>X</code> may not be standardized, 
since standardizing is performed by the function <code>multinom.spls.stab</code> 
as a preliminary step. 
</p>
<p>The procedure is described in Durif et al. (2018). The stability selection 
procedure can be summarize as follow (c.f. Meinshausen and Buhlmann, 2010).
</p>
<p>(i) For each candidate values <code>(ncomp, lambda.l1, lambda.ridge)</code> of 
hyper-parameters, a multinomial-spls is trained on <code>nresamp</code> 
resamplings of the data. Then, for each triplet 
<code>(ncomp, lambda.l1, lambda.ridge)</code>, the probability that a covariate 
(i.e. a column in <code>X</code>) is selected is computed among the resamplings.
</p>
<p>The estimated probabilities can be visualized as a heatmap with the 
function <code>stability.selection.heatmap</code>.
</p>
<p>(ii) Eventually, the set of "stable selected" variables corresponds to the 
set of covariates that were selected by most of the training among the 
grid of hyper-parameters candidate values.
</p>
<p>This function achieves the first step (i) of the stability selection 
procedure. The second step (ii) is achieved by the function 
<code>stability.selection</code>
</p>
<p>This procedures uses <code>mclapply</code> from the <code>parallel</code> package, 
available on GNU/Linux and MacOS. Users of Microsoft Windows can refer to 
the README file in the source to be able to use a mclapply type function.
</p>


<h3>Value</h3>

<p>An object with the following attributes
</p>
<table>
<tr style="vertical-align: top;">
<td><code>q.Lambda</code></td>
<td>
<p>A table with values of q.Lambda (c.f. Durif 
et al. (2018) for the notation), being the averaged number of covariates
selected among the entire grid of hyper-parameters candidates values,
for increasing size of hyper-parameter grid.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>probs.lambda</code></td>
<td>
<p>A table with estimated probability of selection for each 
covariates depending on the candidates values for hyper-parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>An integer values indicating the number of covariates in the 
model.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Ghislain Durif (<a href="https://gdurif.perso.math.cnrs.fr/">https://gdurif.perso.math.cnrs.fr/</a>).
</p>


<h3>References</h3>

<p>Durif, G., Modolo, L., Michaelsson, J., Mold, J.E., Lambert-Lacroix, S., 
Picard, F., 2018. High dimensional classification with combined 
adaptive sparse PLS and logistic regression. Bioinformatics 34, 
485â€“493. <a href="https://doi.org/10.1093/bioinformatics/btx571">doi:10.1093/bioinformatics/btx571</a>.
Available at <a href="http://arxiv.org/abs/1502.05933">http://arxiv.org/abs/1502.05933</a>.
</p>
<p>Meinshausen, N., Buhlmann P. (2010). Stability Selection. Journal of the 
Royal Statistical Society: Series B (Statistical Methodology) 
72, no. 4, 417-473.
</p>


<h3>See Also</h3>

<p><code>multinom.spls</code>, <code>stability.selection</code>, 
<code>stability.selection.heatmap</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
### load plsgenomics library
library(plsgenomics)

### generating data
n &lt;- 100
p &lt;- 100
nclass &lt;- 3
sample1 &lt;- sample.multinom(n, p, nb.class=nclass, kstar=20, lstar=2, 
                           beta.min=0.25, beta.max=0.75, 
                           mean.H=0.2, sigma.H=10, sigma.F=5)

X &lt;- sample1$X
Y &lt;- sample1$Y

### pertinent covariates id
sample1$sel

### hyper-parameters values to test
lambda.l1.range &lt;- seq(0.05,0.95,by=0.1) # between 0 and 1
ncomp.range &lt;- 1:10
# log-linear range between 0.01 a,d 1000 for lambda.ridge.range
logspace &lt;- function( d1, d2, n) exp(log(10)*seq(d1, d2, length.out=n))
lambda.ridge.range &lt;- signif(logspace(d1 &lt;- -2, d2 &lt;- 3, n=21), digits=3)

### tuning the hyper-parameters
stab1 &lt;- multinom.spls.stab(X=X, Y=Y, lambda.ridge.range=lambda.ridge.range, 
                            lambda.l1.range=lambda.l1.range, 
                            ncomp.range=ncomp.range, 
                            adapt=TRUE, maxIter=100, svd.decompose=TRUE, 
                            ncores=1, nresamp=100)
                       
str(stab1)

### heatmap of estimated probabilities
stability.selection.heatmap(stab1)

### selected covariates
stability.selection(stab1, piThreshold=0.6, rhoError=10)

## End(Not run)

</code></pre>


</div>