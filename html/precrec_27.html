<div class="container">

<table style="width: 100%;"><tr>
<td>evalmod</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Evaluate models and calculate performance evaluation measures</h2>

<h3>Description</h3>

<p>The <code>evalmod</code> function calculates ROC and Precision-Recall curves for
specified prediction scores and binary labels. It also calculate several
basic performance evaluation measures, such as accuracy, error rate, and
precision, by specifying <code>mode</code> as "basic".
</p>


<h3>Usage</h3>

<pre><code class="language-R">evalmod(
  mdat,
  mode = NULL,
  scores = NULL,
  labels = NULL,
  modnames = NULL,
  dsids = NULL,
  posclass = NULL,
  na_worst = TRUE,
  ties_method = "equiv",
  calc_avg = TRUE,
  cb_alpha = 0.05,
  raw_curves = FALSE,
  x_bins = 1000,
  interpolate = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>mdat</code></td>
<td>
<p>An <code>S3</code> object created by the <code>mmdata</code>
function. It contains formatted scores and labels.
The <code>evalmod</code> function ignores the following arguments
when <code>mdat</code> is specified.
</p>

<ul>
<li> <p><code>scores</code>
</p>
</li>
<li> <p><code>labels</code>
</p>
</li>
<li> <p><code>modnames</code>
</p>
</li>
<li> <p><code>dsids</code>
</p>
</li>
<li> <p><code>posclass</code>
</p>
</li>
<li> <p><code>na_worst</code>
</p>
</li>
<li> <p><code>ties_method</code>
</p>
</li>
</ul>
<p>These arguments are internally passed to the <code>mmdata</code> function
when <code>mdat</code> is unspecified.
In that case, both <code>scores</code> and <code>labels</code> must be
at least specified.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mode</code></td>
<td>
<p>A string that specifies the types of evaluation measures
that the <code>evalmod</code> function calculates.
</p>

<dl>
<dt>"rocprc"</dt>
<dd>
<p>ROC and Precision-Recall curves</p>
</dd>
<dt>"prcroc"</dt>
<dd>
<p>Same as above</p>
</dd>
<dt>"basic"</dt>
<dd>
<p>Normalized ranks vs. accuracy, error rate, specificity,
sensitivity, precision, Matthews correlation coefficient,
and F-score. </p>
</dd>
<dt>"aucroc"</dt>
<dd>
<p>Fast AUC(ROC) calculation with the U statistic</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scores</code></td>
<td>
<p>A numeric dataset of predicted scores. It can be a vector,
a matrix, an array, a data frame, or a list. The <code>join_scores</code>
function can be useful to make scores with multiple datasets.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>labels</code></td>
<td>
<p>A numeric, character, logical, or factor dataset
of observed labels. It can be a vector, a matrix, an array,
a data frame, or a list. The <code>join_labels</code>
function can be useful to make labels with multiple datasets.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>modnames</code></td>
<td>
<p>A character vector for the names of the models.
The <code>evalmod</code> function automatically generates default names
as "m1", "m2", "m3", and so on when it is <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dsids</code></td>
<td>
<p>A numeric vector for test dataset IDs.
The <code>evalmod</code> function automatically generates the default ID
as <code>1</code> when it is <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>posclass</code></td>
<td>
<p>A scalar value to specify the label of positives
in <code>labels</code>. It must be the same data type as <code>labels</code>.
For example, <code>posclass = -1</code> changes the positive label
from <code>1</code> to <code>-1</code> when <code>labels</code> contains
<code>1</code> and <code>-1</code>. The positive label will be automatically
detected when <code>posclass</code> is <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na_worst</code></td>
<td>
<p>A Boolean value for controlling the treatment of NAs
in <code>scores</code>.
</p>

<dl>
<dt>TRUE</dt>
<dd>
<p>All NAs are treated as the worst scores</p>
</dd>
<dt>FALSE</dt>
<dd>
<p>All NAs are treated as the best scores</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ties_method</code></td>
<td>
<p>A string for controlling ties in <code>scores</code>.
</p>

<dl>
<dt>"equiv"</dt>
<dd>
<p>Ties are equivalently ranked</p>
</dd>
<dt>"first"</dt>
<dd>
<p>Ties are ranked in an increasing order as appeared</p>
</dd>
<dt>"random"</dt>
<dd>
<p> Ties are ranked in random order</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>calc_avg</code></td>
<td>
<p>A logical value to specify whether average curves should
be calculated. It is effective only when <code>dsids</code> contains multiple
dataset IDs. For instance, the function calculates the average for the
model "m1" when <code>modnames</code> is <code>c("m1", "m1", "m1")</code> and
<code>dsids</code> is <code>c(1, 2, 3)</code>. The calculation points are defined by
<code>x_bins</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cb_alpha</code></td>
<td>
<p>A numeric value with range [0, 1] to specify the alpha
value of the point-wise confidence bounds calculation. It is effective only
when <code>calc_avg</code> is set to <code>TRUE</code>. For example, it should be
<code>0.05</code> for the 95% confidence level. The calculation points are
defined by <code>x_bins</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>raw_curves</code></td>
<td>
<p>A logical value to specify whether all raw curves
should be discarded after the average curves are calculated.
It is effective only when <code>calc_avg</code> is set to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x_bins</code></td>
<td>
<p>An integer value to specify the number of minimum bins
on the x-axis. It is then used to define supporting points For instance,
the x-values of the supporting points will be <code>c(0, 0.5, 1)</code> and
<code>c(0, 0.25, 0.5, 0.75, 1)</code> when <code>x_bins = 2</code>
and <code>x_bins = 4</code>, respectively. All corresponding y-values of
the supporting points are calculated. <code>x_bins</code> is effective only
when <code>mode</code> is set to <code>rocprc</code> or <code>prcroc</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>interpolate</code></td>
<td>
<p>A Boolean value to specify whether or not
interpolation of ROC and precision-recall curves are
performed. <code>x_bins</code> and <code>calc_avg</code> are
ignored and  when <code>x_bins</code> is set to <code>FALSE</code>.
<code>interpolate</code> is effective only when <code>mode</code> is set
to <code>rocprc</code> or <code>prcroc</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>These additional arguments are passed to <code>mmdata</code>
for data preparation.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The <code>evalmod</code> function returns an <code>S3</code> object
that contains performance evaluation measures. The number of models and
the number of datasets can be controlled by <code>modnames</code> and
<code>dsids</code>. For example, the number of models is "single" and the number
of test datasets is "multiple" when <code>modnames = c("m1", "m1", "m1")</code>
and <code>dsids = c(1, 2, 3)</code> are specified.
</p>
<p>Different <code>S3</code> objects have different default behaviors of <code>S3</code>
generics, such as <code>plot</code>, <code>autoplot</code>, and
<code>fortify</code>.
</p>

<ol>
<li>
<p>  The <code>evalmod</code> function returns one of the following <code>S3</code>
objects when <code>mode</code> is "prcroc".
The objects contain ROC and Precision-Recall curves.
</p>

<table>
<tr>
<td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td>
<td style="text-align: left;"> <strong># of models</strong>
    </td>
<td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
<td style="text-align: left;">

    sscurves </td>
<td style="text-align: left;"> single   </td>
<td style="text-align: left;"> single   </td>
</tr>
<tr>
<td style="text-align: left;">
    mscurves </td>
<td style="text-align: left;"> multiple </td>
<td style="text-align: left;"> single   </td>
</tr>
<tr>
<td style="text-align: left;">
    smcurves </td>
<td style="text-align: left;"> single   </td>
<td style="text-align: left;"> multiple </td>
</tr>
<tr>
<td style="text-align: left;">
    mmcurves </td>
<td style="text-align: left;"> multiple </td>
<td style="text-align: left;"> multiple
  </td>
</tr>
</table>
</li>
<li>
<p> The <code>evalmod</code> function returns one of the following <code>S3</code>
objects when <code>mode</code> is "basic".
They contain five different basic evaluation measures; error rate,
accuracy, specificity, sensitivity, and precision.
</p>

<table>
<tr>
<td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td>
<td style="text-align: left;"> <strong># of models</strong>
    </td>
<td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
<td style="text-align: left;">

    sspoints </td>
<td style="text-align: left;"> single   </td>
<td style="text-align: left;"> single   </td>
</tr>
<tr>
<td style="text-align: left;">
    mspoints </td>
<td style="text-align: left;"> multiple </td>
<td style="text-align: left;"> single   </td>
</tr>
<tr>
<td style="text-align: left;">
    smpoints </td>
<td style="text-align: left;"> single   </td>
<td style="text-align: left;"> multiple </td>
</tr>
<tr>
<td style="text-align: left;">
    mmpoints </td>
<td style="text-align: left;"> multiple </td>
<td style="text-align: left;"> multiple
  </td>
</tr>
</table>
</li>
<li>
<p> The <code>evalmod</code> function returns the <code>aucroc</code> S3 object
when <code>mode</code> is "aucroc", which can be used with 'print'
and 'as.data.frame'.
</p>
</li>
</ol>
<h3>See Also</h3>

<p><code>plot</code> for plotting curves with the general R plot.
<code>autoplot</code> and <code>fortify</code> for plotting curves
with <span class="pkg">ggplot2</span>. <code>mmdata</code> for formatting input data.
<code>join_scores</code> and <code>join_labels</code> for formatting
scores and labels with multiple datasets.
<code>format_nfold</code> for creating n-fold cross validation dataset
from data frame.
<code>create_sim_samples</code> for generating random samples
for simulations.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
##################################################
### Single model &amp; single test dataset
###

## Load a dataset with 10 positives and 10 negatives
data(P10N10)

## Generate an sscurve object that contains ROC and Precision-Recall curves
sscurves &lt;- evalmod(scores = P10N10$scores, labels = P10N10$labels)
sscurves

## Generate an sspoints object that contains basic evaluation measures
sspoints &lt;- evalmod(
  mode = "basic", scores = P10N10$scores,
  labels = P10N10$labels
)
sspoints


##################################################
### Multiple models &amp; single test dataset
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(1, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mscurves &lt;- evalmod(mdat)
mscurves

## Generate an mspoints object that contains basic evaluation measures
mspoints &lt;- evalmod(mdat, mode = "basic")
mspoints


##################################################
### Single model &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(4, 100, 100, "good_er")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an smcurve object that contains ROC and Precision-Recall curves
smcurves &lt;- evalmod(mdat)
smcurves

## Generate an smpoints object that contains basic evaluation measures
smpoints &lt;- evalmod(mdat, mode = "basic")
smpoints


##################################################
### Multiple models &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(4, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an mmcurve object that contains ROC and Precision-Recall curves
mmcurves &lt;- evalmod(mdat)
mmcurves

## Generate an mmpoints object that contains basic evaluation measures
mmpoints &lt;- evalmod(mdat, mode = "basic")
mmpoints


##################################################
### N-fold cross validation datasets
###

## Load test data
data(M2N50F5)

## Speficy nessesary columns to create mdat
cvdat &lt;- mmdata(
  nfold_df = M2N50F5, score_cols = c(1, 2),
  lab_col = 3, fold_col = 4,
  modnames = c("m1", "m2"), dsids = 1:5
)

## Generate an mmcurve object that contains ROC and Precision-Recall curves
cvcurves &lt;- evalmod(cvdat)
cvcurves

## Generate an mmpoints object that contains basic evaluation measures
cvpoints &lt;- evalmod(cvdat, mode = "basic")
cvpoints

## Specify mmdata arguments from evalmod
cvcurves2 &lt;- evalmod(
  nfold_df = M2N50F5, score_cols = c(1, 2),
  lab_col = 3, fold_col = 4,
  modnames = c("m1", "m2"), dsids = 1:5
)
cvcurves2


##################################################
### AUC with the U statistic
###

## mode = "aucroc" returns 'aucroc' S3 object
data(P10N10)

# 'aucroc' S3 object
uauc1 &lt;- evalmod(
  scores = P10N10$scores, labels = P10N10$labels,
  mode = "aucroc"
)

# print 'aucroc'
uauc1

# as.data.frame 'aucroc'
as.data.frame(uauc1)

## It is 2-3 times faster than mode = "rocprc"
# A sample of 100,000
samp1 &lt;- create_sim_samples(1, 50000, 50000)

# a function to test mode = "rocprc"
func_evalmod_rocprc &lt;- function(samp) {
  curves &lt;- evalmod(scores = samp$scores, labels = samp$labels)
  aucs &lt;- auc(curves)
}

# a function to test mode = "aucroc"
func_evalmod_aucroc &lt;- function(samp) {
  uaucs &lt;- evalmod(
    scores = samp$scores, labels = samp$labels,
    mode = "aucroc"
  )
  as.data.frame(uaucs)
}

# Process time
system.time(res1 &lt;- func_evalmod_rocprc(samp1))
system.time(res2 &lt;- func_evalmod_aucroc(samp1))

# AUCs
res1
res2

</code></pre>


</div>