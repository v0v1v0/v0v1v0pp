<div class="container">

<table style="width: 100%;"><tr>
<td>get_token_stream</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Get Token Stream.</h2>

<h3>Description</h3>

<p>Auxiliary method to get the fulltext of a corpus, subcorpora etc. Can be used
to export corpus data to other tools.
</p>


<h3>Usage</h3>

<pre><code class="language-R">get_token_stream(.Object, ...)

## S4 method for signature 'numeric'
get_token_stream(
  .Object,
  corpus,
  registry = NULL,
  p_attribute,
  subset = NULL,
  boost = NULL,
  encoding = NULL,
  collapse = NULL,
  beautify = TRUE,
  cpos = FALSE,
  cutoff = NULL,
  decode = TRUE,
  ...
)

## S4 method for signature 'matrix'
get_token_stream(.Object, corpus, registry = NULL, split = FALSE, ...)

## S4 method for signature 'corpus'
get_token_stream(.Object, left = NULL, right = NULL, ...)

## S4 method for signature 'character'
get_token_stream(.Object, left = NULL, right = NULL, ...)

## S4 method for signature 'slice'
get_token_stream(.Object, p_attribute, collapse = NULL, cpos = FALSE, ...)

## S4 method for signature 'partition'
get_token_stream(.Object, p_attribute, collapse = NULL, cpos = FALSE, ...)

## S4 method for signature 'subcorpus'
get_token_stream(.Object, p_attribute, collapse = NULL, cpos = FALSE, ...)

## S4 method for signature 'regions'
get_token_stream(
  .Object,
  p_attribute = "word",
  collapse = NULL,
  cpos = FALSE,
  split = FALSE,
  ...
)

## S4 method for signature 'partition_bundle'
get_token_stream(
  .Object,
  p_attribute = "word",
  vocab = NULL,
  phrases = NULL,
  subset = NULL,
  min_length = NULL,
  collapse = NULL,
  cpos = FALSE,
  decode = TRUE,
  beautify = FALSE,
  verbose = TRUE,
  progress = FALSE,
  mc = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>.Object</code></td>
<td>
<p>Input object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Arguments that will be be passed into the
<code>get_token_stream</code>-method for a <code>numeric</code> vector, the real worker.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>corpus</code></td>
<td>
<p>A CWB indexed corpus.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>registry</code></td>
<td>
<p>Registry directory with registry file describing the corpus.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p_attribute</code></td>
<td>
<p>A <code>character</code> vector, the p-attribute(s) to decode.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>
<p>An expression applied on p-attributes, using non-standard
evaluation. Note that symbols used in the expression may not be used
internally (e.g. 'stopwords').</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>boost</code></td>
<td>
<p>A length-one <code>logical</code> value, whether to speed up decoding
a long vector of token ids by directly by reading in the lexion file from
the data directory of a corpus. If <code>NULL</code> (default), the internal
decision rule is that <code>boost</code> will be <code>TRUE</code> if the corpus is
larger than 10 000 000 million tokens and more than 5 percent of the corpus
are to be decoded.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>encoding</code></td>
<td>
<p>If not <code>NULL</code> (default) a length-one <code>character</code> vector
stating an encoding that will be assigned to the (decoded) token stream.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>collapse</code></td>
<td>
<p>If not <code>NULL</code> (default), a length-one <code>character</code> string
passed into <code>paste</code> to collapse character vector into a single string.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beautify</code></td>
<td>
<p>A (length-one) <code>logical</code> value, whether to adjust whitespace
before and after interpunctation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cpos</code></td>
<td>
<p>A <code>logical</code> value, whether to return corpus positions as names of
the tokens.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cutoff</code></td>
<td>
<p>Maximum number of tokens to be reconstructed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>decode</code></td>
<td>
<p>A (length-one) <code>logical</code> value, whether to decode token ids to
character strings. Defaults to <code>TRUE</code>, if <code>FALSE</code>, an integer vector with
token ids is returned.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>split</code></td>
<td>
<p>A <code>logical</code> value, whether to return a <code>character</code> vector (when
<code>split</code> is <code>FALSE</code>, default) or a <code>list</code> of <code>character</code> vectors; each of
these vectors will then represent the tokens of a region defined by a row
in a regions matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>left</code></td>
<td>
<p>Left corpus position.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>right</code></td>
<td>
<p>Right corpus position.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vocab</code></td>
<td>
<p>A <code>character</code> vector with an alternative vocabulary to the one
stored on disk.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>phrases</code></td>
<td>
<p>A <code>phrases</code> object. Defined phrases will be concatenated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_length</code></td>
<td>
<p>If not <code>NULL</code> (default), an <code>integer</code> value with minimum
length of documents required to keep them in the <code>list</code> object that is
returned.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>A length-one <code>logical</code> value, whether to show messages.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>progress</code></td>
<td>
<p>A length-one <code>logical</code> value, whether to show progress bar.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mc</code></td>
<td>
<p>Number of cores to use. If <code>FALSE</code> (default), only one thread will
be used.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>CWB indexed corpora have a fixed order of tokens which is called the
<em>token stream</em>. Every token is assigned to a unique <em>corpus
position</em>, Subsets of the (entire) token stream defined by a left and a
right corpus position are called <em>regions</em>. The
<code>get_token_stream</code>-method will extract the tokens (for regions) from a
corpus.
</p>
<p>The primary usage of this method is to return the token stream of a
(sub-)corpus as defined by a <code>corpus</code>, <code>subcorpus</code> or <code>partition</code> object.
The methods defined for a <code>numeric</code> vector or a (two-column) <code>matrix</code>
defining regions (i.e. left and right corpus positions in the first and
second column) are the actual workers for this operation.
</p>
<p>The <code>get_token_stream</code> has been introduced so serve as a worker by
higher level methods such as <code>read</code>, <code>html</code>, and <code>as.markdown</code>. It may
however be useful for decoding a corpus so that it can be exported to other
tools.
</p>


<h3>Examples</h3>

<pre><code class="language-R">use(pkg = "RcppCWB", corpus = "REUTERS")

# Decode first words of REUTERS corpus (first sentence)
get_token_stream(0:20, corpus = "REUTERS", p_attribute = "word")

# Decode first sentence and collapse tokens into single string
get_token_stream(0:20, corpus = "REUTERS", p_attribute = "word", collapse = " ")

# Decode regions defined by two-column integer matrix
region_matrix &lt;- matrix(c(0L,20L,21L,38L), ncol = 2, byrow = TRUE)
get_token_stream(
  region_matrix,
  corpus = "REUTERS",
  p_attribute = "word",
  encoding = "latin1"
)

# Use argument 'beautify' to remove surplus whitespace
## Not run: 
get_token_stream(
  region_matrix,
  corpus = "GERMAPARLMINI",
  p_attribute = "word",
  encoding = "latin1",
  collapse = " ", beautify = TRUE
)

## End(Not run)

# Decode entire corpus (corpus object / specified by corpus ID)
corpus("REUTERS") %&gt;%
  get_token_stream(p_attribute = "word") %&gt;%
  head()

# Decode subcorpus
corpus("REUTERS") %&gt;%
  subset(id == "127") %&gt;%
  get_token_stream(p_attribute = "word") %&gt;%
  head()

# Decode partition_bundle
## Not run: 
pb_tokstr &lt;- corpus("REUTERS") %&gt;%
  split(s_attribute = "id") %&gt;%
  get_token_stream(p_attribute = "word")

## End(Not run)
## Not run: 
# Get token stream for partition_bundle
pb &lt;- partition_bundle("REUTERS", s_attribute = "id")
ts_list &lt;- get_token_stream(pb)

# Use two p-attributes
sp &lt;- corpus("GERMAPARLMINI") %&gt;%
  as.speeches(s_attribute_name = "speaker", s_attribute_date = "date", progress = FALSE)
p2 &lt;- get_token_stream(sp, p_attribute = c("word", "pos"), verbose = FALSE)

# Apply filter
p_sub &lt;- get_token_stream(
  sp, p_attribute = c("word", "pos"),
  subset = {!grepl("(\\$.$|ART)", pos)}
)

# Concatenate phrases and apply filter
queries &lt;- c('"freiheitliche" "Grundordnung"', '"Bundesrepublik" "Deutschland"' )
phr &lt;- corpus("GERMAPARLMINI") %&gt;%
  cpos(query = queries) %&gt;%
  as.phrases(corpus = "GERMAPARLMINI")

kill &lt;- tm::stopwords("de")

ts_phr &lt;- get_token_stream(
  sp,
  p_attribute = c("word", "pos"),
  subset = {!word %in% kill  &amp; !grepl("(\\$.$|ART)", pos)},
  phrases = phr,
  progress = FALSE,
  verbose = FALSE
)

## End(Not run)
</code></pre>


</div>