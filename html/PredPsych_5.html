<div class="container">

<table style="width: 100%;"><tr>
<td>DTModel</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Generic Decision Tree Function</h2>

<h3>Description</h3>

<p>A simple function to create Decision Trees
</p>


<h3>Usage</h3>

<pre><code class="language-R">DTModel(Data, classCol, selectedCols, tree, cvType, nTrainFolds,
  ntrainTestFolds, modelTrainFolds, foldSep, cvFraction,
  extendedResults = FALSE, SetSeed = TRUE, silent = FALSE,
  NewData = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Data</code></td>
<td>
<p>(dataframe) a data frame with regressors and response</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classCol</code></td>
<td>
<p>(numeric or string) which column should be used as response col</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectedCols</code></td>
<td>
<p>(optional) (numeric or string) which columns should be treated as data(features + response) (defaults to all columns)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tree</code></td>
<td>
<p>which decision tree model to implement; One of the following values:
</p>

<ul>
<li>
<p> CART        =   Classification And Regression Tree; 
</p>
</li>
<li>
<p> CARTNACV    =   Crossvalidated CART Tree removing missing values;
</p>
</li>
<li>
<p> CARTCV      =   Crossvalidated CART Tree With missing values;
</p>
</li>
<li>
<p> CF          =   Conditional inference framework Tree;
</p>
</li>
<li>
<p> RF          =   Random Forest Tree;    
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cvType</code></td>
<td>
<p>(optional) (string) which type of cross-validation scheme to follow - only in case of CARTCV or CARTNACV;
One of the following values:
</p>

<ul>
<li>
<p> folds       =   (default) k-fold cross-validation 
</p>
</li>
<li>
<p> LOSO        =   Leave-one-subject-out cross-validation
</p>
</li>
<li>
<p> holdout     =   holdout Crossvalidation. Only a portion of data (cvFraction) is used for training.
</p>
</li>
<li>
<p> LOTO        =   Leave-one-trial out cross-validation.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nTrainFolds</code></td>
<td>
<p>(optional) (parameter for only k-fold cross-validation) No. of folds in which to further divide Training dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ntrainTestFolds</code></td>
<td>
<p>(optional) (parameter for only k-fold cross-validation) No. of folds for training and testing dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>modelTrainFolds</code></td>
<td>
<p>=   (optional) (parameter for only k-fold cross-validation) specific folds from the first train/test split
(ntrainTestFolds) to use for training</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>foldSep</code></td>
<td>
<p>(numeric)  (parameter for only Leave-One_subject Out) mandatory column number for Leave-one-subject out cross-validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cvFraction</code></td>
<td>
<p>(optional) (numeric) Fraction of data to keep for training data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>extendedResults</code></td>
<td>
<p>(optional) (logical) Return extended results with model and other metrics</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>SetSeed</code></td>
<td>
<p>(optional) (logical) Whether to setseed or not. use SetSeed to seed the random number generator to get consistent results;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>silent</code></td>
<td>
<p>(optional) (logical) whether to print messages or not</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>NewData</code></td>
<td>
<p>(optional) (dataframe) New Data frame features for which the class membership is requested</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>(optional) additional arguments for the function</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function implements the Decision Tree models (DT models).
DT models fall under the general "Tree based methods"
involving generation of a recursive binary tree (Hastie et al., 2009).
In terms of input, DT  models can handle both continuous and categorical variables
as well as missing data. From the input data, DT  models build a set of logical "if ..then" rules
that permit accurate prediction of the input cases.
</p>
<p>The function "rpart" handles the missing data by creating surrogate variables 
instead of removing them entirely (Therneau, &amp; Atkinson, 1997). 
This could be useful in case the data contains multiple missing values. 
</p>
<p>Unlike regression methods like GLMs,  Decision Trees are more flexible and can model nonlinear interactions.
</p>


<h3>Value</h3>

<p>model result for the input tree <code>Results</code>  or Test accuracy <code>accTest</code> based on <code>tree</code>. If <code>extendedResults</code> = TRUE 
outputs Test accuracy <code>accTest</code> of discrimination,<code>ConfMatrix</code> Confusion matrices and <code>fit</code> the model 
and  <code>ConfusionMatrixResults</code> Overall cross-validated confusion matrix results
</p>


<h3>Author(s)</h3>

<p>Atesh Koul, C'MON unit, Istituto Italiano di Tecnologia
</p>
<p><a href="mailto:atesh.koul@gmail.com">atesh.koul@gmail.com</a>
</p>


<h3>References</h3>

<p>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). The Elements of Statistical Learning. 
Springer Series in Statistics (2nd ed., Vol. 1). New York, NY: Springer New York.
</p>
<p>Terry Therneau, Beth Atkinson and Brian Ripley (2015). rpart: Recursive Partitioning and Regression Trees. 
R package version 4.1-10.  https://CRAN.R-project.org/package=rpart
</p>
<p>Therneau, T. M., &amp; Atkinson, E. J. (1997). An introduction to recursive partitioning using the RPART routines (Vol. 61, p. 452).
Mayo Foundation: Technical report.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># generate a cart model for 10% of the data with cross-validation
model &lt;- DTModel(Data = KinData,classCol=1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112), tree='CARTCV',cvType = "holdout")
# Output:
# Performing Decision Tree Analysis 
#
# [1] "Generating crossvalidated Tree With Missing Values"
#
# Performing holdout Cross-validation
# 
# cvFraction was not specified,
#  Using default value of 0.8 (cvFraction = 0.8)" 
# Proportion of Test/Train Data was :  0.2470588 
# 
# [1] "Test holdout Accuracy is  0.62"
# holdout CART Analysis: 
# cvFraction : 0.8 
# Test Accuracy 0.62
# *Legend:
# cvFraction = Fraction of data to keep for training data 
# Test Accuracy = Accuracy from the Testing dataset

#' # --CART MOdel --

# Alternate uses:  
# k-fold cross-validation with removing missing values
model &lt;- DTModel(Data = KinData,classCol=1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),
tree='CARTNACV',cvType="folds")

# holdout cross-validation without removing missing values
model &lt;- DTModel(Data = KinData,classCol=1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),
tree='CARTCV',cvType = "holdout")

# k-fold cross-validation without removing missing values
model &lt;- DTModel(Data = KinData,classCol=1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),
tree='CARTCV',cvType="folds")

</code></pre>


</div>