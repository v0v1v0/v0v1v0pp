<div class="container">

<table style="width: 100%;"><tr>
<td>benchmark.regression</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Comparison of Partial Least Squares Regression, Principal Components
Regression and Ridge Regression.</h2>

<h3>Description</h3>

<p>This function computes the test error over several runs for (a) PLS, (b) PCR
(c) Ridge Regression and (d) the null model, that is the mean of <code>y</code>.
In the first three cases, the optimal model is selected via
cross-validation.
</p>


<h3>Usage</h3>

<pre><code class="language-R">benchmark.regression(
  X,
  y,
  m = ncol(X),
  R = 20,
  ratio = 0.8,
  verbose = TRUE,
  k = 10,
  nsamples = nrow(X),
  use.kernel = FALSE,
  supervised = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>matrix of predictor observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>vector of response observations. The length of <code>y</code> is the same
as the number of rows of <code>X</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m</code></td>
<td>
<p>maximal number of components for PLS. Default is <code>m=ncol(X)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>R</code></td>
<td>
<p>number of runs. Default is 20.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ratio</code></td>
<td>
<p>ratio no of training examples/(no of training examples + no of
test examples). Default is 0.8</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>If <code>TRUE</code>, the functions plots the progress of the
function. Default is <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>number of cross-validation splits. Default is 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nsamples</code></td>
<td>
<p>number of data points. Default is <code>nrow(X)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use.kernel</code></td>
<td>
<p>Use kernel representation for PLS? Default is
<code>use.kernel=FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>supervised</code></td>
<td>
<p>Should the principal components be sorted by decreasing
squared correlation to the response? Default is FALSE.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function computes the test error, the cross-validation-optimal model
parameters, their corresponding Degrees of Freedom, and the
sum-of-squared-residuals (SSR) for PLS and PCR.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>MSE</code></td>
<td>
<p>data frame of size R x 4. It contains the test error for
the four different methods for each of the R runs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>M</code></td>
<td>
<p>data frame of
size R x 4. It contains the optimal model parameters for the four different
methods for each of the R runs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DoF</code></td>
<td>
<p>data frame of size R x 4. It
contains the Degrees of Freedom (corresponding to <code>M</code>) for the four
different methods for each of the R runs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>res.pls</code></td>
<td>
<p>matrix of size R x
(ncol(X+1)). It contains the SSR for PLS for each of the R runs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>res.pcr</code></td>
<td>
<p>matrix of size R x (ncol(X+1)). It contains the SSR for PCR
for each of the R runs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DoF.all</code></td>
<td>
<p>matrix of size R x (ncol(X+1)). It
contains the Degrees of Freedom for PLS for all components for each of the R
runs.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Nicole Kraemer
</p>


<h3>References</h3>

<p>Kraemer, N., Sugiyama M. (2011). "The Degrees of Freedom of Partial Least
Squares Regression". Journal of the American Statistical Association 106
(494) <a href="https://www.tandfonline.com/doi/abs/10.1198/jasa.2011.tm10107">https://www.tandfonline.com/doi/abs/10.1198/jasa.2011.tm10107</a>
</p>


<h3>See Also</h3>

<p><code>pls.cv</code>, <code>pcr.cv</code>,
<code>benchmark.pls</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">

# Boston Housing data
library(MASS)
data(Boston)
X&lt;-as.matrix(Boston[,1:4]) # select the first 3 columns as predictor variables
y&lt;-as.vector(Boston[,14])

my.benchmark&lt;-benchmark.regression(X,y,ratio=0.5,R=10,k=5)

# boxplot of the mean squared error

boxplot(my.benchmark$MSE,outline=FALSE)

# boxplot of the degrees of freedom, without the null model

boxplot(my.benchmark$DoF[,-4])


</code></pre>


</div>