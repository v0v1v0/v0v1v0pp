<div class="container">

<table style="width: 100%;"><tr>
<td>knnmi</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Parallel Mutual Information Estimation</h2>

<h3>Description</h3>

<p>A function to perform a parallel estimation of the mutual information
of vectors <code>x</code> and <code>y</code> using entropy estimates from K-nearest neighbor
distances.
</p>


<h3>Usage</h3>

<pre><code class="language-R">knnmi(x, y, k=3, noise=1e-12)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a numeric vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a numeric vector with the same length of <code>x</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>the number of nearest neighbors to be considered to estimate the
mutual information. Must be less than the number of elements of <code>x</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>noise</code></td>
<td>
<p>the magnitude of the random noise added to break ties.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function adds a small random noise to the data in order to break ties due
to limited numerical precision.
</p>
<p>By default, the function uses all available cores. You can
set the actual number of threads used to N by exporting the
environment variable <code>OMP_NUM_THREADS=N</code>.
</p>


<h3>References</h3>

<p>Kraskov, Alexander  and Stogbauer, Harald  and Grassberger, Peter.
<em>Estimating mutual information.</em> Phys. Rev. E, 2004.
</p>


<h3>See Also</h3>

<p><code>knnmi.cross</code>
</p>
<p><code>knnmi.all</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">x &lt;- rnorm(100)
y &lt;- rnorm(100)
knnmi(x, y, 5)
</code></pre>


</div>