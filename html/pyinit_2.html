<div class="container">

<table style="width: 100%;"><tr>
<td>pyinit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>PY (Pena-Yohai) initial estimates for S-estimates of regression</h2>

<h3>Description</h3>

<p>Computes the PY initial estimates for S-estimates of regression.
</p>


<h3>Usage</h3>

<pre><code class="language-R">pyinit(
  x,
  y,
  intercept = TRUE,
  delta = 0.5,
  cc,
  maxit = 10,
  psc_keep,
  resid_keep_method = c("threshold", "proportion"),
  resid_keep_prop,
  resid_keep_thresh,
  eps = 1e-08,
  mscale_maxit = 200,
  mscale_tol = eps,
  mscale_rho_fun = c("bisquare", "huber", "gauss")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a matrix with the data, each observation in a row.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>the response vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>logical, should an intercept be included in the model? Defaults to
<code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta, cc</code></td>
<td>
<p>parameters for the M-scale estimator equation. If <code>cc</code> is
missing it will be set to yield consistency under the Normal model for the
given <code>delta</code> (right-hand side of the M-scale equation).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxit</code></td>
<td>
<p>the maximum number of iterations to perform.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>psc_keep</code></td>
<td>
<p>proportion of observations to keep based on PSCs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>resid_keep_method</code></td>
<td>
<p>how to clean the data based on large residuals.
If <code>"threshold"</code>, all observations with scaled residuals larger
than <code>resid_keep_thresh</code> will be removed (<code>resid_keep_thresh</code>
corresponds to the constant <code class="reqn">C_1</code> from equation (21) in Pena &amp; Yohai
(1999). If <code>"proportion"</code>, observations with the largest
<code>resid_keep_prop</code> residuals will be removed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>resid_keep_prop, resid_keep_thresh</code></td>
<td>
<p>see parameter
<code>resid_keep_method</code> for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>the relative tolerance for convergence. Defaults to <code>1e-8</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mscale_maxit</code></td>
<td>
<p>maximum number of iterations allowed for the M-scale
algorithm. Defaults to <code>200</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mscale_tol</code></td>
<td>
<p>convergence threshold for the m-scale</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mscale_rho_fun</code></td>
<td>
<p>A string containing the name of the rho
function to use for the M-scale. Valid options
are <code>bisquare</code>, <code>huber</code> and <code>gauss</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>coefficients</code></td>
<td>
<p>numeric matrix with coefficient vectors in columns. These
are regression estimators based on "cleaned" subsets of the data. The
M-scales of the corresponding residuals are returned in the entry
<code>objective</code>. The regression coefficients with smallest estimated
residual scale is in the first column, but the others need not be ordered.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>objective</code></td>
<td>
<p>vector of values of the M-scale estimate of the residuals
associated with each vector of regression coefficients in the columns of
<code>coefficients</code>.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Pena, D., &amp; Yohai, V.. (1999). A Fast Procedure for Outlier Diagnostics in Large
Regression Problems. <em>Journal of the American Statistical Association</em>, 94(446),
434-445. &lt;doi:10.2307/2670164&gt;
</p>


<h3>Examples</h3>

<pre><code class="language-R"># generate a simple synthetic data set for a linear regression model
# with true regression coefficients all equal to one "(1, 1, 1, 1, 1)"
set.seed(123)
x &lt;- matrix(rnorm(100*4), 100, 4)
y &lt;- rnorm(100) + rowSums(x) + 1
# add masked outliers
a &lt;- svd(var(x))$v[,4]
x &lt;- rbind(x, t(outer(a, rnorm(20, mean=4, sd=1))))
y &lt;- c(y, rnorm(20, mean=-2, sd=.2))

# these outliers are difficult to find
plot(lm(y~x), ask=FALSE)

# use pyinit to obtain estimated regression coefficients
tmp &lt;- pyinit(x=x, y=y, resid_keep_method='proportion', psc_keep = .5, resid_keep_prop=.5)
# the vector of regression coefficients with smallest residuals scale
# is returned in the first column of the "coefficients" element
tmp$coefficients[,1]
# compare that with the LS estimator on the clean data
coef(lm(y~x, subset=1:100))
# compare it with the LS estimator on the full data
coef(lm(y~x))


</code></pre>


</div>