<div class="container">

<table style="width: 100%;"><tr>
<td>kernelpls.fit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Kernel PLS (Dayal and MacGregor)</h2>

<h3>Description</h3>

<p>Fits a PLSR model with the kernel algorithm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">kernelpls.fit(X, Y, ncomp, center = TRUE, stripped = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>a matrix of observations.  <code>NA</code>s and <code>Inf</code>s are not
allowed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>a vector or matrix of responses.  <code>NA</code>s and <code>Inf</code>s are
not allowed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncomp</code></td>
<td>
<p>the number of components to be used in the modelling.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>
<p>logical, determines if the <code class="reqn">X</code> and <code class="reqn">Y</code> matrices are
mean centered or not. Default is to perform mean centering.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stripped</code></td>
<td>
<p>logical.  If <code>TRUE</code> the calculations are stripped as
much as possible for speed; this is meant for use with cross-validation or
simulations when only the coefficients are needed.  Defaults to
<code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>other arguments.  Currently ignored.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function should not be called directly, but through the generic
functions <code>plsr</code> or <code>mvr</code> with the argument
<code>method="kernelpls"</code> (default).  Kernel PLS is particularly efficient
when the number of objects is (much) larger than the number of variables.
The results are equal to the NIPALS algorithm.  Several different forms of
kernel PLS have been described in literature, e.g.  by De Jong and Ter
Braak, and two algorithms by Dayal and MacGregor.  This function implements
the fastest of the latter, not calculating the crossproduct matrix of X.  In
the Dyal &amp; MacGregor paper, this is “algorithm 1”.
</p>


<h3>Value</h3>

<p>A list containing the following components is returned:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>coefficients</code></td>
<td>
<p>an array of regression coefficients for 1, ...,
<code>ncomp</code> components.  The dimensions of <code>coefficients</code> are
<code>c(nvar, npred, ncomp)</code> with <code>nvar</code> the number of <code>X</code>
variables and <code>npred</code> the number of variables to be predicted in
<code>Y</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scores</code></td>
<td>
<p>a matrix of scores.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loadings</code></td>
<td>
<p>a matrix of
loadings.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loading.weights</code></td>
<td>
<p>a matrix of loading weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Yscores</code></td>
<td>
<p>a matrix of Y-scores.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Yloadings</code></td>
<td>
<p>a matrix of
Y-loadings.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>projection</code></td>
<td>
<p>the projection matrix used to convert X to
scores.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xmeans</code></td>
<td>
<p>a vector of means of the X variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ymeans</code></td>
<td>
<p>a vector of means of the Y variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitted.values</code></td>
<td>
<p>an
array of fitted values.  The dimensions of <code>fitted.values</code> are
<code>c(nobj, npred, ncomp)</code> with <code>nobj</code> the number samples and
<code>npred</code> the number of Y variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>residuals</code></td>
<td>
<p>an array of
regression residuals.  It has the same dimensions as <code>fitted.values</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xvar</code></td>
<td>
<p>a vector with the amount of X-variance explained by each
component.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xtotvar</code></td>
<td>
<p>Total variance in <code>X</code>.</p>
</td>
</tr>
</table>
<p>If <code>stripped</code> is <code>TRUE</code>, only the components <code>coefficients</code>,
<code>Xmeans</code> and <code>Ymeans</code> are returned.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>References</h3>

<p>de Jong, S. and ter Braak, C. J. F. (1994) Comments on the PLS
kernel algorithm.  <em>Journal of Chemometrics</em>, <b>8</b>, 169–174.
</p>
<p>Dayal, B. S. and MacGregor, J. F. (1997) Improved PLS algorithms.
<em>Journal of Chemometrics</em>, <b>11</b>, 73–85.
</p>


<h3>See Also</h3>

<p><code>mvr</code> <code>plsr</code> <code>cppls</code>
<code>pcr</code> <code>widekernelpls.fit</code> <code>simpls.fit</code>
<code>oscorespls.fit</code>
</p>


</div>