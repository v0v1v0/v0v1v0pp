<div class="container">

<table style="width: 100%;"><tr>
<td>parglm.control</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Auxiliary for Controlling GLM Fitting in Parallel</h2>

<h3>Description</h3>

<p>Auxiliary function for <code>parglm</code> fitting.
</p>


<h3>Usage</h3>

<pre><code class="language-R">parglm.control(epsilon = 1e-08, maxit = 25, trace = FALSE,
  nthreads = 1L, block_size = NULL, method = "LINPACK")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>epsilon</code></td>
<td>
<p>positive convergence tolerance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxit</code></td>
<td>
<p>integer giving the maximal number of IWLS iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>
<p>logical indicating if output should be produced doing estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nthreads</code></td>
<td>
<p>number of cores to use. You may get the best performance by
using your number of physical cores if your data set is sufficiently large.
Using the number of physical CPUs/cores may yield the best performance
(check your number e.g., by calling <code>parallel::detectCores(logical = FALSE)</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>block_size</code></td>
<td>
<p>number of observation to include in each parallel block.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>string specifying which method to use. Either <code>"LINPACK"</code>,
<code>"LAPACK"</code>, or <code>"FAST"</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The <code>LINPACK</code> method uses the same QR method as <code>glm.fit</code> for the final QR decomposition.
This is the <code>dqrdc2</code> method described in <code>qr</code>. All other QR
decompositions but the last are made with <code>DGEQP3</code> from <code>LAPACK</code>.
See Wood, Goude, and Shaw (2015) for details on the QR method.
</p>
<p>The <code>FAST</code> method computes the Fisher information and then solves the normal
equation. This is faster but less numerically stable.
</p>


<h3>Value</h3>

<p>A list with components named as the arguments.
</p>


<h3>References</h3>

<p>Wood, S.N., Goude, Y. &amp; Shaw S. (2015) Generalized additive models for
large datasets. Journal of the Royal Statistical Society, Series C
64(1): 139-155.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># use one core
clotting &lt;- data.frame(
 u = c(5,10,15,20,30,40,60,80,100),
 lot1 = c(118,58,42,35,27,25,21,19,18),
 lot2 = c(69,35,26,21,18,16,13,12,12))
f1 &lt;- parglm(lot1 ~ log(u), data = clotting, family = Gamma,
             control = parglm.control(nthreads = 1L))

# use two cores
f2 &lt;- parglm(lot1 ~ log(u), data = clotting, family = Gamma,
             control = parglm.control(nthreads = 2L))
all.equal(coef(f1), coef(f2))

</code></pre>


</div>