<div class="container">

<table style="width: 100%;"><tr>
<td>p_gdfa</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Gamma Discriminant Function Approach for Estimating Odds Ratio with Exposure
Measured in Pools and Potentially Subject to Multiplicative Lognormal Errors</h2>

<h3>Description</h3>

<p>Assumes exposure given covariates and outcome is a constant-scale Gamma
regression. Pooled exposure measurements can be assumed precise or subject to
multiplicative lognormal processing error and/or measurement error.
Parameters are estimated using maximum likelihood.
</p>


<h3>Usage</h3>

<pre><code class="language-R">p_gdfa(g, y, xtilde, c = NULL, constant_or = TRUE,
  errors = "processing", estimate_var = TRUE,
  start_nonvar_var = c(0.01, 1), lower_nonvar_var = c(-Inf, 1e-04),
  upper_nonvar_var = c(Inf, Inf), jitter_start = 0.01,
  hcubature_list = list(tol = 1e-08), nlminb_list = list(control =
  list(trace = 1, eval.max = 500, iter.max = 500)),
  hessian_list = list(method.args = list(r = 4)), nlminb_object = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>g</code></td>
<td>
<p>Numeric vector with pool sizes, i.e. number of members in each pool.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Numeric vector with poolwise Y values, coded 0 if all members are
controls and 1 if all members are cases.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xtilde</code></td>
<td>
<p>Numeric vector (or list of numeric vectors, if some pools have
replicates) with Xtilde values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>c</code></td>
<td>
<p>List where each element is a numeric matrix containing the
<strong>C</strong> values for members of a particular pool (1 row for each member).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>constant_or</code></td>
<td>
<p>Logical value for whether to assume a constant OR for
X, which means that gamma_y = 0. If <code>NULL</code>, model is fit with and
without this assumption, and a likelihood ratio test is performed to test it.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>errors</code></td>
<td>
<p>Character string specifying the errors that <code>X</code> is subject
to. Choices are <code>"neither"</code>, <code>"processing"</code> for processing error
only, <code>"measurement"</code> for measurement error only, and <code>"both"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>estimate_var</code></td>
<td>
<p>Logical value for whether to return variance-covariance
matrix for parameter estimates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start_nonvar_var</code></td>
<td>
<p>Numeric vector of length 2 specifying starting value
for non-variance terms and variance terms, respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower_nonvar_var</code></td>
<td>
<p>Numeric vector of length 2 specifying lower bound for
non-variance terms and variance terms, respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>upper_nonvar_var</code></td>
<td>
<p>Numeric vector of length 2 specifying upper bound for
non-variance terms and variance terms, respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>jitter_start</code></td>
<td>
<p>Numeric value specifying standard deviation for mean-0
normal jitters to add to starting values for a second try at maximizing the
log-likelihood, should the initial call to <code>nlminb</code> result
in non-convergence. Set to <code>NULL</code> for no second try.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hcubature_list</code></td>
<td>
<p>List of arguments to pass to
<code>hcubature</code> for numerical integration.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlminb_list</code></td>
<td>
<p>List of arguments to pass to <code>nlminb</code>
for log-likelihood maximization.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hessian_list</code></td>
<td>
<p>List of arguments to pass to
<code>hessian</code> for approximating the Hessian matrix. Only
used if <code>estimate_var = TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlminb_object</code></td>
<td>
<p>Object returned from <code>nlminb</code> in a
prior call. Useful for bypassing log-likelihood maximization if you just want
to re-estimate the Hessian matrix with different options.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>List containing:
</p>

<ol>
<li>
<p> Numeric vector of parameter estimates.
</p>
</li>
<li>
<p> Variance-covariance matrix.
</p>
</li>
<li>
<p> Returned <code>nlminb</code> object from maximizing the
log-likelihood function.
</p>
</li>
<li>
<p> Akaike information criterion (AIC).
</p>
</li>
</ol>
<p>If <code>constant_or = NULL</code>, two such lists are returned (one under a
constant odds ratio assumption and one not), along with a likelihood ratio
test for <code>H0: gamma_y = 0</code>, which is equivalent to
<code>H0: odds ratio is constant</code>.
</p>


<h3>References</h3>

<p>Lyles, R.H., Van Domelen, D.R., Mitchell, E.M. and Schisterman, E.F. (2015)
"A discriminant function approach to adjust for processing and measurement
error When a biomarker is assayed in pooled samples."
<em>Int. J. Environ. Res. Public Health</em> <strong>12</strong>(11): 14723–14740.
</p>
<p>Mitchell, E.M, Lyles, R.H., and Schisterman, E.F. (2015) "Positing, fitting,
and selecting regression models for pooled biomarker data." <em>Stat. Med</em>
<strong>34</strong>(17): 2544–2558.
</p>
<p>Schisterman, E.F., Vexler, A., Mumford, S.L. and Perkins, N.J. (2010) "Hybrid
pooled-unpooled design for cost-efficient measurement of biomarkers."
<em>Stat. Med.</em> <strong>29</strong>(5): 597–613.
</p>
<p>Whitcomb, B.W., Perkins, N.J., Zhang, Z., Ye, A., and Lyles, R. H. (2012)
"Assessment of skewed exposure in case-control studies with pooling."
<em>Stat. Med.</em> <strong>31</strong>: 2461–2472.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Load data frame with (g, Y, X, Xtilde) values for 496 pools, list of C
# values for members of each pool, and list of Xtilde values where 25
# single-specimen pools have replicates. Xtilde values are affected by
# processing error and measurement error. True log-OR = 0.5, sigsq_p = 0.25,
# sigsq_m = 0.1.
data(dat_p_gdfa)
dat &lt;- dat_p_gdfa$dat
reps &lt;- dat_p_gdfa$reps
c.list &lt;- dat_p_gdfa$c.list

# Unobservable truth estimator - use precise X's
fit.unobservable &lt;- p_gdfa(
  g = dat$g,
  y = dat$y,
  xtilde = dat$x,
  c = c.list,
  errors = "neither"
)
fit.unobservable$estimates

# Naive estimator - use imprecise Xtilde's, but treat as precise
fit.naive &lt;- p_gdfa(
  g = dat$g,
  y = dat$y,
  xtilde = dat$xtilde,
  c = c.list,
  errors = "neither"
)
fit.naive$estimates

# Corrected estimator - use Xtilde's and account for errors (not using
# replicates here)
## Not run: 
fit.noreps &lt;- p_gdfa(
  g = dat$g,
  y = dat$y,
  xtilde = dat$xtilde,
  c = c.list,
  errors = "both"
)
fit.noreps$estimates

# Corrected estimator - use Xtilde's including 25 replicates
fit.reps &lt;- p_gdfa(
  g = dat$g,
  y = dat$y,
  xtilde = reps,
  c = c.list,
  errors = "both"
)
fit.reps$estimates

# Same as previous, but allowing for non-constant odds ratio.
fit.nonconstant &lt;- p_gdfa(
  g = dat$g,
  y = dat$y,
  xtilde = reps,
  c = c.list,
  constant_or = FALSE,
  errors = "both",
  hcubature_list = list(tol = 1e-4)
)
fit.nonconstant$estimates

# Visualize estimated log-OR vs. X based on previous model fit
p &lt;- plot_gdfa(
  estimates = fit.nonconstant$estimates,
  varcov = fit.nonconstant$theta.var,
  xrange = range(dat$xtilde[dat$g == 1]),
  cvals = mean(unlist(c))
)
p

## End(Not run)

</code></pre>


</div>