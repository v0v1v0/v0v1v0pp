<div class="container">

<table style="width: 100%;"><tr>
<td>details_bart_dbarts</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Bayesian additive regression trees via dbarts</h2>

<h3>Description</h3>

<p><code>dbarts::bart()</code> creates an ensemble of tree-based model whose training
and assembly is determined using Bayesian analysis.
</p>


<h3>Details</h3>

<p>For this engine, there are multiple modes: classification and regression
</p>


<h4>Tuning Parameters</h4>

<p>This model has 4 tuning parameters:
</p>

<ul>
<li> <p><code>trees</code>: # Trees (type: integer, default: 200L)
</p>
</li>
<li> <p><code>prior_terminal_node_coef</code>: Terminal Node Prior Coefficient (type:
double, default: 0.95)
</p>
</li>
<li> <p><code>prior_terminal_node_expo</code>: Terminal Node Prior Exponent (type:
double, default: 2.00)
</p>
</li>
<li> <p><code>prior_outcome_range</code>: Prior for Outcome Range (type: double, default:
2.00)
</p>
</li>
</ul>
<h4>Important engine-specific options</h4>

<p>Some relevant arguments that can be passed to <code>set_engine()</code>:
</p>

<ul>
<li> <p><code>keepevery</code>, <code>n.thin</code>: Every <code>keepevery</code> draw is kept to be returned
to the user. Useful for “thinning” samples.
</p>
</li>
<li> <p><code>ntree</code>, <code>n.trees</code>: The number of trees in the sum-of-trees
formulation.
</p>
</li>
<li> <p><code>ndpost</code>, <code>n.samples</code>: The number of posterior draws after burn in,
<code>ndpost</code> / <code>keepevery</code> will actually be returned.
</p>
</li>
<li> <p><code>nskip</code>, <code>n.burn</code>: Number of MCMC iterations to be treated as burn in.
</p>
</li>
<li> <p><code>nchain</code>, <code>n.chains</code>: Integer specifying how many independent tree
sets and fits should be calculated.
</p>
</li>
<li> <p><code>nthread</code>, <code>n.threads</code>: Integer specifying how many threads to use.
Depending on the CPU architecture, using more than the number of
chains can degrade performance for small/medium data sets. As such
some calculations may be executed single threaded regardless.
</p>
</li>
<li> <p><code>combinechains</code>, <code>combineChains</code>: Logical; if <code>TRUE</code>, samples will be
returned in arrays of dimensions equal to <code>nchain</code> times <code>ndpost</code>
times number of observations.
</p>
</li>
</ul>
<h4>Translation from parsnip to the original package (classification)</h4>

<div class="sourceCode r"><pre>bart(
  trees = integer(1),
  prior_terminal_node_coef = double(1),
  prior_terminal_node_expo = double(1),
  prior_outcome_range = double(1)
) %&gt;% 
  set_engine("dbarts") %&gt;% 
  set_mode("classification") %&gt;% 
  translate()
</pre></div>
<div class="sourceCode"><pre>## BART Model Specification (classification)
## 
## Main Arguments:
##   trees = integer(1)
##   prior_terminal_node_coef = double(1)
##   prior_terminal_node_expo = double(1)
##   prior_outcome_range = double(1)
## 
## Computational engine: dbarts 
## 
## Model fit template:
## dbarts::bart(x = missing_arg(), y = missing_arg(), ntree = integer(1), 
##     base = double(1), power = double(1), k = double(1), verbose = FALSE, 
##     keeptrees = TRUE, keepcall = FALSE)
</pre></div>



<h4>Translation from parsnip to the original package (regression)</h4>

<div class="sourceCode r"><pre>bart(
  trees = integer(1),
  prior_terminal_node_coef = double(1),
  prior_terminal_node_expo = double(1),
  prior_outcome_range = double(1)
) %&gt;% 
  set_engine("dbarts") %&gt;% 
  set_mode("regression") %&gt;% 
  translate()
</pre></div>
<div class="sourceCode"><pre>## BART Model Specification (regression)
## 
## Main Arguments:
##   trees = integer(1)
##   prior_terminal_node_coef = double(1)
##   prior_terminal_node_expo = double(1)
##   prior_outcome_range = double(1)
## 
## Computational engine: dbarts 
## 
## Model fit template:
## dbarts::bart(x = missing_arg(), y = missing_arg(), ntree = integer(1), 
##     base = double(1), power = double(1), k = double(1), verbose = FALSE, 
##     keeptrees = TRUE, keepcall = FALSE)
</pre></div>



<h4>Preprocessing requirements</h4>

<p>Factor/categorical predictors need to be converted to numeric values
(e.g., dummy or indicator variables) for this engine. When using the
formula method via <code>fit()</code>, parsnip will
convert factor columns to indicators.
</p>
<p><code>dbarts::bart()</code> will also convert the factors to
indicators if the user does not create them first.
</p>



<h4>References</h4>


<ul><li>
<p> Chipman, George, McCulloch. “BART: Bayesian additive regression
trees.” <em>Ann. Appl. Stat.</em> 4 (1) 266 - 298, March 2010.
</p>
</li></ul>
</div>