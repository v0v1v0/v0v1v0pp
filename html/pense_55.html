<div class="container">

<table style="width: 100%;"><tr>
<td>prinsens</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Principal Sensitivity Components</h2>

<h3>Description</h3>

<p>Compute Principal Sensitivity Components for Elastic Net Regression
</p>


<h3>Usage</h3>

<pre><code class="language-R">prinsens(
  x,
  y,
  alpha,
  lambda,
  intercept = TRUE,
  penalty_loadings,
  en_algorithm_opts,
  eps = 1e-06,
  sparse = FALSE,
  ncores = 1L,
  method = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p><code>n</code> by <code>p</code> matrix of numeric predictors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>vector of response values of length <code>n</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>elastic net penalty mixing parameter with <code class="reqn">0 \le \alpha \le 1</code>.
<code>alpha = 1</code> is the LASSO penalty, and <code>alpha = 0</code> the Ridge penalty.
Can be a vector of several values, but <code>alpha = 0</code> cannot be mixed with other values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>optional user-supplied sequence of penalization levels. If given and not <code>NULL</code>,
<code>nlambda</code> and <code>lambda_min_ratio</code> are ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>include an intercept in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty_loadings</code></td>
<td>
<p>a vector of positive penalty loadings (a.k.a. weights) for different
penalization of each coefficient. Only allowed for <code>alpha</code> &gt; 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>en_algorithm_opts</code></td>
<td>
<p>options for the LS-EN algorithm. See en_algorithm_options for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>numerical tolerance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sparse</code></td>
<td>
<p>use sparse coefficient vectors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncores</code></td>
<td>
<p>number of CPU cores to use in parallel. By default, only one CPU core is used.
Not supported on all platforms, in which case a warning is given.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>defunct. PSCs are always computed for EN estimates. For the PY procedure for unpenalized estimation
use package <a href="https://cran.r-project.org/package=pyinit">pyinit</a>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a list of principal sensitivity components, one per element in <code>lambda</code>. Each PSC is itself a list
with items <code>lambda</code>, <code>alpha</code>, and <code>pscs</code>.
</p>


<h3>References</h3>

<p>Cohen Freue, G.V.; Kepplinger, D.; Salibián-Barrera, M.; Smucler, E.
Robust elastic net estimators for variable selection and identification of proteomic biomarkers.
<em>Ann. Appl. Stat.</em> <strong>13</strong> (2019), no. 4, 2065–2090 <a href="https://doi.org/10.1214/19-AOAS1269">doi:10.1214/19-AOAS1269</a>
</p>
<p>Pena, D., and Yohai, V.J.
A Fast Procedure for Outlier Diagnostics in Large Regression Problems.
<em>J. Amer. Statist. Assoc.</em> <strong>94</strong> (1999). no. 446, 434–445. <a href="https://doi.org/10.2307/2670164">doi:10.2307/2670164</a>
</p>


<h3>See Also</h3>

<p>Other functions for initial estimates: 
<code>enpy_initial_estimates()</code>,
<code>starting_point()</code>
</p>


</div>