<div class="container">

<table style="width: 100%;"><tr>
<td>fletcher_powell</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Fletcher-Powell Conjugate Gradient Minimization
</h2>

<h3>Description</h3>

<p>Conjugate Gradient (CG) minimization through the Davidon-Fletcher-Powell 
approach for function minimization.
</p>
<p>The Davidon-Fletcher-Powell (DFP) and the Broyden-Fletcher-Goldfarb-Shanno
(BFGS) methods are the first quasi-Newton minimization methods developed.
These methods differ only in some details; in general, the BFGS approach
is more robust.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fletcher_powell(x0, f, g = NULL,
                maxiter = 1000, tol = .Machine$double.eps^(2/3))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x0</code></td>
<td>
<p>start value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f</code></td>
<td>
<p>function to be minimized.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>g</code></td>
<td>
<p>gradient function of <code>f</code>;
if <code>NULL</code>, a numerical gradient will be calculated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiter</code></td>
<td>
<p>max. number of iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>relative tolerance, to be used as stopping rule.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The starting point is Newton's method in the multivariate case, when
the estimate of the minimum is updated by the following equation
</p>
<p style="text-align: center;"><code class="reqn">x_{new} = x - H^{-1}(x) grad(g)(x)</code>
</p>

<p>where <code class="reqn">H</code> is the Hessian and <code class="reqn">grad</code> the gradient.
</p>
<p>The basic idea is to generate a sequence of good approximations to the
inverse Hessian matrix, in such a way that the approximations are again
positive definite.
</p>


<h3>Value</h3>

<p>List with following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>xmin</code></td>
<td>
<p>minimum solution found.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fmin</code></td>
<td>
<p>value of <code>f</code> at minimum.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>niter</code></td>
<td>
<p>number of iterations performed.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>Used some Matlab code as described in the book “Applied Numerical Analysis
Using Matlab” by L. V.Fausett.
</p>


<h3>References</h3>

<p>J. F. Bonnans, J. C. Gilbert, C. Lemarechal, and C. A. Sagastizabal.
Numerical Optimization: Theoretical and Practical Aspects. Second Edition,
Springer-Verlag, Berlin Heidelberg, 2006.
</p>


<h3>See Also</h3>

<p><code>steep_descent</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">##  Rosenbrock function
rosenbrock &lt;- function(x) {
    n &lt;- length(x)
    x1 &lt;- x[2:n]
    x2 &lt;- x[1:(n-1)]
    sum(100*(x1-x2^2)^2 + (1-x2)^2)
}
fletcher_powell(c(0, 0), rosenbrock)
# $xmin
# [1] 1 1
# $fmin
# [1] 1.774148e-27
# $niter
# [1] 14
</code></pre>


</div>