<div class="container">

<table style="width: 100%;"><tr>
<td>ParseProbDup</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Parse an object of class <code>ProbDup</code> to a data frame.</h2>

<h3>Description</h3>

<p><code>ParseProbDup</code> converts an object of class <code>ProbDup</code> to a data frame for export.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ParseProbDup(pdup, max.count = 30, insert.blanks = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>pdup</code></td>
<td>
<p>An object of class <code>ProbDup</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.count</code></td>
<td>
<p>The maximum count of probable duplicate sets which are to be parsed to a data frame.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>insert.blanks</code></td>
<td>
<p>logical. If <code>TRUE</code>, inserts a row of <code>NAs</code> 
after each set.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A data frame of the long/narrow form of the probable duplicate sets 
data with the following core columns: </p>

<table>
<tr>
<td style="text-align: left;"> 
  <code>SET_NO</code> </td>
<td style="text-align: left;"> The set number. </td>
</tr>
<tr>
<td style="text-align: left;"> <code>TYPE</code> </td>
<td style="text-align: left;"> The type of 
  probable duplicate set. 'F' for fuzzy, 'P' for phonetic and 'S' for 
  semantic matching sets. </td>
</tr>
<tr>
<td style="text-align: left;"> <code>K</code> </td>
<td style="text-align: left;"> The KWIC index or database of 
  origin of the record. The <code>method</code> is specified within the square 
  brackets in the column name.  </td>
</tr>
<tr>
<td style="text-align: left;"> <code>PRIM_ID</code> </td>
<td style="text-align: left;"> The primary ID of the
  accession record from which the set could be identified. </td>
</tr>
<tr>
<td style="text-align: left;"> <code>IDKW</code> 
  </td>
<td style="text-align: left;"> The 'matching' keywords along with the IDs. </td>
</tr>
<tr>
<td style="text-align: left;"> <code>COUNT</code> </td>
<td style="text-align: left;"> The number of elements in a set. </td>
</tr>
<tr>
<td style="text-align: left;"> </td>
</tr>
</table>
<p> For the 
retrieved columns(fields) the prefix <code>K*</code> indicates the KWIC index of 
origin.
</p>


<h3>See Also</h3>

<p><code>ProbDup</code>,
</p>


<h3>Examples</h3>

<pre><code class="language-R">


## Not run: 

#' # Load PGR passport database
GN &lt;- GN1000

# Specify as a vector the database fields to be used
GNfields &lt;- c("NationalID", "CollNo", "DonorID", "OtherID1", "OtherID2")

# Clean the data
GN[GNfields] &lt;- lapply(GN[GNfields], function(x) DataClean(x))
y1 &lt;- list(c("Gujarat", "Dwarf"), c("Castle", "Cary"), c("Small", "Japan"),
c("Big", "Japan"), c("Mani", "Blanco"), c("Uganda", "Erect"),
c("Mota", "Company"))
y2 &lt;- c("Dark", "Light", "Small", "Improved", "Punjab", "SAM")
y3 &lt;- c("Local", "Bold", "Cary", "Mutant", "Runner", "Giant", "No.",
        "Bunch", "Peanut")
GN[GNfields] &lt;- lapply(GN[GNfields], function(x) MergeKW(x, y1, delim = c("space", "dash")))
GN[GNfields] &lt;- lapply(GN[GNfields], function(x) MergePrefix(x, y2, delim = c("space", "dash")))
GN[GNfields] &lt;- lapply(GN[GNfields], function(x) MergeSuffix(x, y3, delim = c("space", "dash")))

# Generate KWIC index
GNKWIC &lt;- KWIC(GN, GNfields)

# Specify the exceptions as a vector
exep &lt;- c("A", "B", "BIG", "BOLD", "BUNCH", "C", "COMPANY", "CULTURE", 
         "DARK", "E", "EARLY", "EC", "ERECT", "EXOTIC", "FLESH", "GROUNDNUT", 
         "GUTHUKAI", "IMPROVED", "K", "KUTHUKADAL", "KUTHUKAI", "LARGE", 
         "LIGHT", "LOCAL", "OF", "OVERO", "P", "PEANUT", "PURPLE", "R", 
         "RED", "RUNNER", "S1", "SAM", "SMALL", "SPANISH", "TAN", "TYPE", 
         "U", "VALENCIA", "VIRGINIA", "WHITE")
          
# Specify the synsets as a list
syn &lt;- list(c("CHANDRA", "AH114"), c("TG1", "VIKRAM"))

# Fetch probable duplicate sets
GNdup &lt;- ProbDup(kwic1 = GNKWIC, method = "a", excep = exep, fuzzy = TRUE,
                 phonetic = TRUE, encoding = "primary", 
                 semantic = TRUE, syn = syn)
                 
# Convert to data frame of sets               
GNdupParsed &lt;- ParseProbDup(GNdup)


## End(Not run)



</code></pre>


</div>