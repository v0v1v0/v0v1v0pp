<div class="container">

<table style="width: 100%;"><tr>
<td>aseq2feature_seq2seq</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Feature Extraction by action sequence autoencoder</h2>

<h3>Description</h3>

<p><code>aseq2feature_seq2seq</code> extract features from action sequences by action
sequence autoencoder.
</p>


<h3>Usage</h3>

<pre><code class="language-R">aseq2feature_seq2seq(aseqs, K, rnn_type = "lstm", n_epoch = 50,
  method = "last", step_size = 1e-04, optimizer_name = "adam",
  samples_train, samples_valid, samples_test = NULL, pca = TRUE,
  verbose = TRUE, return_theta = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>aseqs</code></td>
<td>
<p>a list of <code>n</code> action sequences. Each element is an action
sequence in the form of a vector of actions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>the number of features to be extracted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rnn_type</code></td>
<td>
<p>the type of recurrent unit to be used for modeling
response processes. <code>"lstm"</code> for the long-short term memory unit. 
<code>"gru"</code> for the gated recurrent unit.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_epoch</code></td>
<td>
<p>the number of training epochs for the autoencoder.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>the method for computing features from the output of an
recurrent neural network in the encoder. Available options are 
<code>"last"</code> and <code>"avg"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>step_size</code></td>
<td>
<p>the learning rate of optimizer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optimizer_name</code></td>
<td>
<p>a character string specifying the optimizer to be used
for training. Availabel options are <code>"sgd"</code>, <code>"rmsprop"</code>, 
<code>"adadelta"</code>, and <code>"adam"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>samples_train</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>samples_valid</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>samples_test</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pca</code></td>
<td>
<p>logical. If TRUE, the principal components of features are
returned. Default is TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>logical. If TRUE, training progress is printed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_theta</code></td>
<td>
<p>logical. If TRUE, extracted features are returned.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function trains a sequence-to-sequence autoencoder using keras. The encoder
of the autoencoder consists of an embedding layer and a recurrent neural network.
The decoder consists of another recurrent neural network and a fully connect layer
with softmax activation. The outputs of the encoder are the extracted features.
</p>
<p>The output of the encoder is a function of the encoder recurrent neural network.
It is the last output of the encoder recurrent neural network if <code>method="last"</code>
and the average of the encoder recurrent nenural network if <code>method="avg"</code>.
</p>


<h3>Value</h3>

<p><code>aseq2feature_seq2seq</code> returns a list containing
</p>
<table>
<tr style="vertical-align: top;">
<td><code>theta</code></td>
<td>
<p>a matrix containing <code>K</code> features or principal features. Each column is a feature.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>train_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of training losses.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>valid_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of validation losses.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of test losses. Exists only if <code>samples_test</code> is not <code>NULL</code>.</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p><code>chooseK_seq2seq</code> for choosing <code>K</code> through cross-validation.
</p>
<p>Other feature extraction methods: <code>atseq2feature_seq2seq</code>,
<code>seq2feature_mds_large</code>,
<code>seq2feature_mds</code>,
<code>seq2feature_ngram</code>,
<code>seq2feature_seq2seq</code>,
<code>tseq2feature_seq2seq</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
if (!system("python -c 'import tensorflow as tf'", ignore.stdout = TRUE, ignore.stderr= TRUE)) {
  n &lt;- 50
  seqs &lt;- seq_gen(n)
  seq2seq_res &lt;- aseq2feature_seq2seq(seqs$action_seqs, 5, rnn_type="lstm", n_epoch=5, 
                                   samples_train=1:40, samples_valid=41:50)
  features &lt;- seq2seq_res$theta
  plot(seq2seq_res$train_loss, col="blue", type="l")
  lines(seq2seq_res$valid_loss, col="red")
}


</code></pre>


</div>