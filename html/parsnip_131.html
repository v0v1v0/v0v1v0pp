<div class="container">

<table style="width: 100%;"><tr>
<td>details_poisson_reg_stan_glmer</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Poisson regression via hierarchical Bayesian methods</h2>

<h3>Description</h3>

<p>The <code>"stan_glmer"</code> engine estimates hierarchical regression parameters using
Bayesian estimation.
</p>


<h3>Details</h3>

<p>For this engine, there is a single mode: regression
</p>


<h4>Tuning Parameters</h4>

<p>This model has no tuning parameters.
</p>



<h4>Important engine-specific options</h4>

<p>Some relevant arguments that can be passed to <code>set_engine()</code>:
</p>

<ul>
<li> <p><code>chains</code>: A positive integer specifying the number of Markov chains.
The default is 4.
</p>
</li>
<li> <p><code>iter</code>: A positive integer specifying the number of iterations for
each chain (including warmup). The default is 2000.
</p>
</li>
<li> <p><code>seed</code>: The seed for random number generation.
</p>
</li>
<li> <p><code>cores</code>: Number of cores to use when executing the chains in parallel.
</p>
</li>
<li> <p><code>prior</code>: The prior distribution for the (non-hierarchical) regression
coefficients.
</p>
</li>
<li> <p><code>prior_intercept</code>: The prior distribution for the intercept (after
centering all predictors).
</p>
</li>
</ul>
<p>See <code>?rstanarm::stan_glmer</code> and <code>?rstan::sampling</code> for more information.
</p>



<h4>Translation from parsnip to the original package</h4>

<p>The <strong>multilevelmod</strong> extension package is required to fit this model.
</p>
<div class="sourceCode r"><pre>library(multilevelmod)

poisson_reg(engine = "stan_glmer") %&gt;% 
  set_engine("stan_glmer") %&gt;% 
  translate()
</pre></div>
<div class="sourceCode"><pre>## Poisson Regression Model Specification (regression)
## 
## Computational engine: stan_glmer 
## 
## Model fit template:
## rstanarm::stan_glmer(formula = missing_arg(), data = missing_arg(), 
##     weights = missing_arg(), family = stats::poisson, refresh = 0)
</pre></div>



<h4>Predicting new samples</h4>

<p>This model can use subject-specific coefficient estimates to make
predictions (i.e. partial pooling). For example, this equation shows the
linear predictor (<code style="white-space: pre;">⁠\eta⁠</code>) for a random intercept:
</p>
<div class="sourceCode"><pre>\eta_{i} = (\beta_0 + b_{0i}) + \beta_1x_{i1}
</pre></div>
<p>where $i$ denotes the <code>i</code>th independent experimental unit
(e.g. subject). When the model has seen subject <code>i</code>, it can use that
subject’s data to adjust the <em>population</em> intercept to be more specific
to that subjects results.
</p>
<p>What happens when data are being predicted for a subject that was not
used in the model fit? In that case, this package uses <em>only</em> the
population parameter estimates for prediction:
</p>
<div class="sourceCode"><pre>\hat{\eta}_{i'} = \hat{\beta}_0+ \hat{\beta}x_{i'1}
</pre></div>
<p>Depending on what covariates are in the model, this might have the
effect of making the same prediction for all new samples. The population
parameters are the “best estimate” for a subject that was not included
in the model fit.
</p>
<p>The tidymodels framework deliberately constrains predictions for new
data to not use the training set or other data (to prevent information
leakage).
</p>



<h4>Preprocessing requirements</h4>

<p>There are no specific preprocessing needs. However, it is helpful to
keep the clustering/subject identifier column as factor or character
(instead of making them into dummy variables). See the examples in the
next section.
</p>



<h4>Other details</h4>

<p>The model can accept case weights.
</p>
<p>With parsnip, we suggest using the formula method when fitting:
</p>
<div class="sourceCode r"><pre>library(tidymodels)

poisson_reg() %&gt;% 
  set_engine("stan_glmer") %&gt;% 
  fit(y ~ time + x + (1 | subject), data = longitudinal_counts)
</pre></div>
<p>When using tidymodels infrastructure, it may be better to use a
workflow. In this case, you can add the appropriate columns using
<code>add_variables()</code> then supply the typical formula when adding the model:
</p>
<div class="sourceCode r"><pre>library(tidymodels)

glmer_spec &lt;- 
  poisson_reg() %&gt;% 
  set_engine("stan_glmer")

glmer_wflow &lt;- 
  workflow() %&gt;% 
  # The data are included as-is using:
  add_variables(outcomes = y, predictors = c(time, x, subject)) %&gt;% 
  add_model(glmer_spec, formula = y ~ time + x + (1 | subject))

fit(glmer_wflow, data = longitudinal_counts)
</pre></div>
<p>For prediction, the <code>"stan_glmer"</code> engine can compute posterior
intervals analogous to confidence and prediction intervals. In these
instances, the units are the original outcome. When <code>std_error = TRUE</code>,
the standard deviation of the posterior distribution (or posterior
predictive distribution as appropriate) is returned.
</p>



<h4>Case weights</h4>

<p>This model can utilize case weights during model fitting. To use them,
see the documentation in case_weights and the examples
on <code>tidymodels.org</code>.
</p>
<p>The <code>fit()</code> and <code>fit_xy()</code> arguments have arguments called
<code>case_weights</code> that expect vectors of case weights.
</p>



<h4>References</h4>


<ul>
<li>
<p> McElreath, R. 2020 <em>Statistical Rethinking</em>. CRC Press.
</p>
</li>
<li>
<p> Sorensen, T, Vasishth, S. 2016. Bayesian linear mixed models using
Stan: A tutorial for psychologists, linguists, and cognitive
scientists, arXiv:1506.06201.
</p>
</li>
</ul>
</div>