<div class="container">

<table style="width: 100%;"><tr>
<td>information.criteria</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Information criteria</h2>

<h3>Description</h3>

<p>This function computes the optimal model parameters using three different
model selection criteria (aic, bic, gmdl).
</p>


<h3>Usage</h3>

<pre><code class="language-R">information.criteria(RSS, DoF, yhat = NULL, sigmahat, n, criterion = "bic")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>RSS</code></td>
<td>
<p>vector of residual sum of squares.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DoF</code></td>
<td>
<p>vector of Degrees of Freedom. The length of <code>DoF</code> is the
same as the length of <code>RSS</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>yhat</code></td>
<td>
<p>vector of squared norm of yhat. The length of <code>yhat</code> is the
same as the length of <code>RSS</code>. It is only needed for gmdl. Default value
is <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigmahat</code></td>
<td>
<p>Estimated model error. The length of <code>sigmahat</code> is the
same as the length of <code>RSS</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>number of observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>criterion</code></td>
<td>
<p>one of the options "aic", "bic" and "gmdl".</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The Akaike information criterion (aic) is defined as </p>
<p style="text-align: center;"><code class="reqn">{aic}=
\frac{{RSS}}{n} + 2\frac{{DoF}}{n} \sigma^ 2\,.</code>
</p>
<p> The Bayesian information
criterion (bic) is defined as </p>
<p style="text-align: center;"><code class="reqn">{bic}= \frac{{RSS}}{n} +
log(n)\frac{{DoF}}{n} \sigma^ 2\,.</code>
</p>
<p> The generalized minimum description
length (gmdl) is defined as
</p>
<p style="text-align: center;"><code class="reqn">gmdl=\frac{n}{2}log(S)+\frac{DoF}{2}log(F)+\frac{1}{2}log(n)</code>
</p>
<p> with
</p>
<p style="text-align: center;"><code class="reqn">S=\hat \sigma ^2</code>
</p>
<p> Note that it is also possible to use the function
<code>information.criteria</code> for other regression methods than Partial Least
Squares.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>DoF</code></td>
<td>
<p>degrees of freedom</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>score</code></td>
<td>
<p>vector of the model
selection criterion</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>par</code></td>
<td>
<p>index of the first local minimum of
<code>score</code></p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Nicole Kraemer, Mikio Braun
</p>


<h3>References</h3>

<p>Akaikie, H. (1973) "Information Theory and an Extension of the
Maximum Likelihood Principle". Second International Symposium on Information
Theory, 267 - 281.
</p>
<p>Hansen, M., Yu, B. (2001). "Model Selection and Minimum Descripion Length
Principle". Journal of the American Statistical Association, 96, 746 - 774
</p>
<p>Kraemer, N., Sugiyama M. (2011). "The Degrees of Freedom of Partial Least
Squares Regression". Journal of the American Statistical Association 106
(494) <a href="https://www.tandfonline.com/doi/abs/10.1198/jasa.2011.tm10107">https://www.tandfonline.com/doi/abs/10.1198/jasa.2011.tm10107</a>
</p>
<p>Kraemer, N., Braun, M.L. (2007) "Kernelizing PLS, Degrees of Freedom, and
Efficient Model Selection", Proceedings of the 24th International Conference
on Machine Learning, Omni Press, 441 - 448
</p>
<p>Schwartz, G. (1979) "Estimating the Dimension of a Model" Annals of
Statistics 26(5), 1651 - 1686.
</p>


<h3>See Also</h3>

<p><code>pls.ic</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## This is an internal function called by pls.ic


</code></pre>


</div>