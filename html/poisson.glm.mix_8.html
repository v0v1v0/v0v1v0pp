<div class="container">

<table style="width: 100%;"><tr>
<td>init2.jk.j</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Initialization 2 for the <code class="reqn">\beta_{jk}</code> (<code class="reqn">m=1</code>) or <code class="reqn">\beta_{j}</code> (<code class="reqn">m=2</code>) parameterization.
</h2>

<h3>Description</h3>

<p>This function applies a random splitting small EM initialization scheme (Initialization 2), for parameterizations <code class="reqn">m=1</code> or 2. It can be implemented only in case where a previous run of the EM algorithm is available (with respect to the same parameterization). The initialization scheme proposes random splits of the existing clusters, increasing the number of mixture components by one. Then an EM is ran for (<code>msplit</code>) iterations and the procedure is repeated for <code>tsplit</code> times. The best values in terms of observed loglikelihood  are chosen to initialize the main EM algorithm (<code>bjkmodel</code> or <code>bjmodel</code>).  
</p>


<h3>Usage</h3>

<pre><code class="language-R">init2.jk.j(reference, response, L, K, tsplit, model, msplit, 
           previousz, previousclust, previous.alpha, previous.beta,mnr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>reference</code></td>
<td>
<p>a numeric array of dimension <code class="reqn">n\times V</code> containing the <code class="reqn">V</code> covariates for each of the <code class="reqn">n</code> observations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>response</code></td>
<td>
<p>a numeric array of count data with dimension <code class="reqn">n\times d</code> containing the <code class="reqn">d</code> response variables for each of the <code class="reqn">n</code> observations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>L</code></td>
<td>
<p>numeric vector of positive integers containing the partition of the <code class="reqn">d</code> response variables into <code class="reqn">J\leq d</code> blocks, with <code class="reqn">\sum_{j=1}^{J}L_j=d</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>positive integer denoting the number of mixture components.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tsplit</code></td>
<td>
<p>positive integer denoting the number of different runs.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>binary variable denoting the parameterization of the model: 1 for <code class="reqn">\beta_{jk}</code> and 2 for <code class="reqn">\beta_{j}</code> parameterization.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>msplit</code></td>
<td>
<p>positive integer denoting the number of iterations for each run.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>previousz</code></td>
<td>
<p>numeric array of dimension <code class="reqn">n\times(K-1)</code> containing the estimates of the posterior probabilities according to the previous run of EM. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>previousclust</code></td>
<td>
<p>numeric vector of length $n$ containing the estimated clusters according to the MAP rule obtained by the previous run of EM.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>previous.alpha</code></td>
<td>
<p>numeric array of dimension <code class="reqn">J\times (K-1)</code> containing the matrix of the ML estimates of the regression constants <code class="reqn">\alpha_{jk}</code>, <code class="reqn">j=1,\ldots,J</code>, <code class="reqn">k=1,\ldots,K-1</code>, based on the previous run of EM algorithm.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>previous.beta</code></td>
<td>
<p>numeric array of dimension <code class="reqn">J\times (K-1)\times T</code> (if <code>model = 1</code>) or <code class="reqn">J\times T</code> (if <code>model = 2</code>) containing the matrix of the ML estimates of the regression coefficients <code class="reqn">\beta_{jk\tau}</code> or <code class="reqn">\beta_{j\tau}</code>, <code class="reqn">j=1,\ldots,J</code>, <code class="reqn">k=1,\ldots,K-1</code>, <code class="reqn">\tau=1,\ldots,T</code>, based on the previous run of EM algorithm. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mnr</code></td>
<td>
<p>positive integer denoting the maximum number of Newton-Raphson iterations.
</p>
</td>
</tr>
</table>
<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>alpha </code></td>
<td>
<p>numeric array of dimension <code class="reqn">J \times K</code> containing the selected values <code class="reqn">\alpha_{jk}^{0})</code>, <code class="reqn">j=1,\ldots,J</code>, <code class="reqn">k=1,\ldots,K</code> that will be used to initialize main EM (<code>bjkmodel</code> or <code>bjmodel</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta </code></td>
<td>
<p>numeric array of dimension <code class="reqn">J \times K \times T</code> (if <code>model = 1</code>) or <code class="reqn">J \times T</code> (if <code>model = 2</code>) containing the selected values of <code class="reqn">\beta_{jk\tau}^{0})</code> (or <code class="reqn">\beta_{j\tau}^{t})</code>), <code class="reqn">j=1,\ldots,J</code>, <code class="reqn">k=1,\ldots,K</code>, <code class="reqn">\tau=1,\ldots,T</code>, that will be used to initialize the main EM.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>psim </code></td>
<td>
<p>numeric vector of length <code class="reqn">K</code> containing the weights that will initialize the main EM.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ll </code></td>
<td>
<p>numeric, the value of the loglikelihood, computed according to the <code>mylogLikePoisMix</code> function.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>In case that an exhaustive search is desired instead of a random selection of the splitted components, use <code>tsplit = -1</code>.
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>See Also</h3>

<p><code>init1.1.jk.j</code>, <code>init1.2.jk.j</code>, <code>bjkmodel</code>, <code>bjmodel</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">

data("simulated_data_15_components_bjk")
x &lt;- sim.data[,1]
x &lt;- array(x,dim=c(length(x),1))
y &lt;- sim.data[,-1]

# At first a 2 component mixture is fitted using parameterization $m=1$.
run.previous&lt;-bjkmodel(reference=x, response=y, L=c(3,2,1), m=100, K=2, 
                       nr=-10*log(10), maxnr=5, m1=2, m2=2, t1=1, t2=2, 
                       msplit, tsplit, prev.z, prev.clust, start.type=1, 
                       prev.alpha, prev.beta)
## Then the estimated clusters and parameters are used to initialize a 
##   3 component mixture using Initialization 2. The number of different
##   runs is set to $tsplit=3$ with each one of them using msplit = 2 
##   em iterations. 
q &lt;- 3
tau &lt;- 1
nc &lt;- 3
z &lt;- run.previous$z
ml &lt;- length(run.previous$psim)/(nc - 1)
alpha &lt;- array(run.previous$alpha[ml, , ], dim = c(q, nc - 1))
beta &lt;- array(run.previous$beta[ml, , , ], dim = c(q, nc - 1, tau))
clust &lt;- run.previous$clust
run&lt;-init2.jk.j(reference=x, response=y, L=c(3,2,1), K=nc, tsplit=2, 
                model=1, msplit=2, previousz=z, previousclust=clust,
                previous.alpha=alpha, previous.beta=beta,mnr = 5)
# note: useR should specify larger values for msplit and tsplit for a complete analysis.
</code></pre>


</div>