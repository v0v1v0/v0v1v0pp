<div class="container">

<table style="width: 100%;"><tr>
<td>pcovr_est</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Estimation of Principal Covariates Regression parameters, given a prespecified weighting value and number of components</h2>

<h3>Description</h3>

<p>Analyzing regression data with many and/or highly collinear predictor variables, by simultaneously reducing the predictor variables to a given number of components and regressing the criterion variables on these components. A weighting parameter value is specified that determines the extent to which both aspects influence the solution. Cross-validation (Hastie, Tibshirani &amp; Friedman, 2001) options are included.</p>


<h3>Usage</h3>

<pre><code class="language-R">pcovr_est(X, Y, r, a, cross = FALSE, fold = "LeaveOneOut")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Matrix containing predictor scores (observations x predictors)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>Matrix containing criterion scores (observations x criteria)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r</code></td>
<td>
<p>The desired number of components</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a</code></td>
<td>
<p>The desired weighting parameter value</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cross</code></td>
<td>
<p>Logical. If <kbd>TRUE</kbd> cross-validation is performed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fold</code></td>
<td>
<p>Value of <em>k</em> when performing <em>k</em>-fold cross-validation. By default, leave-one-out cross-validation is performed.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>W</code></td>
<td>
<p>Component weights matrix (predictors x components)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>
<p>Regression weights for predictors (predictors x criteria)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Rx2</code></td>
<td>
<p>Proportion of explained variance in <span class="env">X</span></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ry2</code></td>
<td>
<p>Proportion of explained variance in <span class="env">Y</span></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Te</code></td>
<td>
<p>Component score matrix (observations x components)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Px</code></td>
<td>
<p>Loading matrix of components (components x predictors)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Py</code></td>
<td>
<p>Regression weights matrix (components x criteria)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Qy2</code></td>
<td>
<p>Cross-validation fit</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Marlies Vervloet (<a href="mailto:marlies.vervloet@ppw.kuleuven.be">marlies.vervloet@ppw.kuleuven.be</a>)</p>


<h3>References</h3>

<p><cite>De Jong, S., &amp; Kiers, H. A. (1992). Principal covariates regression: Part I. Theory. Chemometrics and Intelligent Laboratory Systems , 155-164.</cite>
</p>
<p><cite>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2001). The elements of statistical learning: Data mining, inference and prediction. New York: Springer.</cite>
</p>
<p><cite>Marlies Vervloet, Henk A. Kiers, Wim Van den Noortgate, Eva Ceulemans (2015). PCovR: An R Package for Principal Covariates Regression. Journal of Statistical Software, 65(8), 1-14. URL http://www.jstatsoft.org/v65/i08/.</cite></p>


<h3>Examples</h3>

<pre><code class="language-R">data(alexithymia)
X &lt;- data.matrix(alexithymia$X)
Y &lt;- data.matrix(alexithymia$Y)
results &lt;- pcovr_est(X, Y, r=2, a=.90)
str(results)
</code></pre>


</div>