<div class="container">

<table style="width: 100%;"><tr>
<td>CDdiagram.Nemenyi</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
CD diagrams for the post-hoc Nemenyi test
</h2>

<h3>Description</h3>

<p>This function obtains a Critical Difference (CD) diagram for the
post-hoc Nemenyi test in the lines defined by Demsar (2006). These
diagrams provide an interesting visualization of the statistical
significance of the observed paired differences between a set of
workflows on a set of predictive tasks. They allow us to compare all
workflows against each other on these set of tasks and check the results
of all these paired comparisons.
</p>


<h3>Usage</h3>

<pre><code class="language-R">CDdiagram.Nemenyi(r, metric = names(r)[1])
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>r</code></td>
<td>

<p>A list resulting from a call to <code>pairedComparisons</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>

<p>The metric for which the CD diagram will be obtained (defaults to the
first metric of the comparison).
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Critical Difference (CD) diagrams are interesting sucint
visualizations of the results of a Nemenyi post-hoc test that is
designed to check the statistical significance between the differences
in average rank of a set of workflows on a set of predictive tasks.
</p>
<p>In the resulting graph each workflow is represented by a colored
line. The X axis where the lines end represents the average rank position
of the respective workflow across all tasks. The null hypothesis is that
the average ranks of each pair of workflows to not differ with
statistical significance (at some confidence level defined in the call
to <code>pairedComparisons</code> that creates the object used to
obtain these graphs). Horizontal lines connect the lines of the
workflows for which we cannot exclude the hypothesis that their average
ranks is equal. Any pair of workflows whose lines are not connected with an
horizontal line can be seen as having an average rank that is different
with statistical significance. On top of the graph an horizontal line is
shown with the required difference between the average ranks (known as
the critical difference) for two pair of workflows to be considered
significantly different. 
</p>


<h3>Value</h3>

<p>Nothing, the graph is draw on the current device.
</p>


<h3>Author(s)</h3>

<p> Luis Torgo <a href="mailto:ltorgo@dcc.fc.up.pt">ltorgo@dcc.fc.up.pt</a> </p>


<h3>References</h3>

<p>Demsar, J. (2006) <em>Statistical Comparisons of Classifiers over
Multiple Data Sets</em>. Journal of Machine Learning Research, 7, 1-30.
</p>
<p>Torgo, L. (2014) <em>An Infra-Structure for Performance
Estimation and Experimental Comparison of Predictive Models in R</em>. arXiv:1412.0436 [cs.MS]
<a href="http://arxiv.org/abs/1412.0436">http://arxiv.org/abs/1412.0436</a>
</p>


<h3>See Also</h3>

<p><code>CDdiagram.Nemenyi</code>,
<code>CDdiagram.BD</code>,  
<code>signifDiffs</code>,
<code>performanceEstimation</code>,
<code>metricNames</code>,
<code>topPerformers</code>,
<code>topPerformer</code>,
<code>rankWorkflows</code>,
<code>metricsSummary</code>,
<code>ComparisonResults</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
## Estimating MSE for 3 variants of both
## regression trees and SVMs, on  two data sets, using one repetition
## of 10-fold CV
library(e1071)
data(iris)
data(Satellite,package="mlbench")
data(LetterRecognition,package="mlbench")


## running the estimation experiment
res &lt;- performanceEstimation(
           c(PredTask(Species ~ .,iris),
             PredTask(classes ~ .,Satellite,"sat"),
             PredTask(lettr ~ .,LetterRecognition,"letter")),
           workflowVariants(learner="svm",
                 learner.pars=list(cost=1:4,gamma=c(0.1,0.01))),
           EstimationTask(metrics=c("err","acc"),method=CV()))


## checking the top performers
topPerformers(res)

## now let us assume that we will choose "svm.v2" as our baseline
## carry out the paired comparisons
pres &lt;- pairedComparisons(res,"svm.v2")

## obtaining a CD diagram comparing all workflows against
## each other
CDdiagram.Nemenyi(pres,metric="err")


## End(Not run)
</code></pre>


</div>