<div class="container">

<table style="width: 100%;"><tr>
<td>details_mlp_nnet</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Multilayer perceptron via nnet</h2>

<h3>Description</h3>

<p><code>nnet::nnet()</code> fits a single layer, feed-forward neural network.
</p>


<h3>Details</h3>

<p>For this engine, there are multiple modes: classification and regression
</p>


<h4>Tuning Parameters</h4>

<p>This model has 3 tuning parameters:
</p>

<ul>
<li> <p><code>hidden_units</code>: # Hidden Units (type: integer, default: none)
</p>
</li>
<li> <p><code>penalty</code>: Amount of Regularization (type: double, default: 0.0)
</p>
</li>
<li> <p><code>epochs</code>: # Epochs (type: integer, default: 100L)
</p>
</li>
</ul>
<p>Note that, in <code>nnet::nnet()</code>, the maximum number of
parameters is an argument with a fairly low value of <code>maxit = 1000</code>. For
some models, you may need to pass this value in via
<code>set_engine()</code> so that the model does not fail.
</p>



<h4>Translation from parsnip to the original package (regression)</h4>

<div class="sourceCode r"><pre>mlp(
  hidden_units = integer(1),
  penalty = double(1),
  epochs = integer(1)
) %&gt;%  
  set_engine("nnet") %&gt;% 
  set_mode("regression") %&gt;% 
  translate()
</pre></div>
<div class="sourceCode"><pre>## Single Layer Neural Network Model Specification (regression)
## 
## Main Arguments:
##   hidden_units = integer(1)
##   penalty = double(1)
##   epochs = integer(1)
## 
## Computational engine: nnet 
## 
## Model fit template:
## nnet::nnet(formula = missing_arg(), data = missing_arg(), size = integer(1), 
##     decay = double(1), maxit = integer(1), trace = FALSE, linout = TRUE)
</pre></div>
<p>Note that parsnip automatically sets linear activation in the last
layer.
</p>



<h4>Translation from parsnip to the original package (classification)</h4>

<div class="sourceCode r"><pre>mlp(
  hidden_units = integer(1),
  penalty = double(1),
  epochs = integer(1)
) %&gt;% 
  set_engine("nnet") %&gt;% 
  set_mode("classification") %&gt;% 
  translate()
</pre></div>
<div class="sourceCode"><pre>## Single Layer Neural Network Model Specification (classification)
## 
## Main Arguments:
##   hidden_units = integer(1)
##   penalty = double(1)
##   epochs = integer(1)
## 
## Computational engine: nnet 
## 
## Model fit template:
## nnet::nnet(formula = missing_arg(), data = missing_arg(), size = integer(1), 
##     decay = double(1), maxit = integer(1), trace = FALSE, linout = FALSE)
</pre></div>



<h4>Preprocessing requirements</h4>

<p>Factor/categorical predictors need to be converted to numeric values
(e.g., dummy or indicator variables) for this engine. When using the
formula method via <code>fit()</code>, parsnip will
convert factor columns to indicators.
</p>
<p>Predictors should have the same scale. One way to achieve this is to
center and scale each so that each predictor has mean zero and a
variance of one.
</p>



<h4>Case weights</h4>

<p>The underlying model implementation does not allow for case weights.
</p>



<h4>Saving fitted model objects</h4>

<p>This model object contains data that are not required to make
predictions. When saving the model for the purpose of prediction, the
size of the saved object might be substantially reduced by using
functions from the <a href="https://butcher.tidymodels.org">butcher</a> package.
</p>



<h4>Examples</h4>

<p>The “Fitting and Predicting with parsnip” article contains
<a href="https://parsnip.tidymodels.org/articles/articles/Examples.html#mlp-nnet">examples</a>
for <code>mlp()</code> with the <code>"nnet"</code> engine.
</p>



<h4>References</h4>


<ul><li>
<p> Kuhn, M, and K Johnson. 2013. <em>Applied Predictive Modeling</em>. Springer.
</p>
</li></ul>
</div>