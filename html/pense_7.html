<div class="container">

<table style="width: 100%;"><tr>
<td>elnet</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compute the Least Squares (Adaptive) Elastic Net Regularization Path</h2>

<h3>Description</h3>

<p>Compute least squares EN estimates for linear regression with optional observation
weights and penalty loadings.
</p>


<h3>Usage</h3>

<pre><code class="language-R">elnet(
  x,
  y,
  alpha,
  nlambda = 100,
  lambda_min_ratio,
  lambda,
  penalty_loadings,
  weights,
  intercept = TRUE,
  en_algorithm_opts,
  sparse = FALSE,
  eps = 1e-06,
  standardize = TRUE,
  correction = deprecated(),
  xtest = deprecated(),
  options = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p><code>n</code> by <code>p</code> matrix of numeric predictors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>vector of response values of length <code>n</code>.
For binary classification, <code>y</code> should be a factor with 2 levels.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>elastic net penalty mixing parameter with <code class="reqn">0 \le \alpha \le 1</code>.
<code>alpha = 1</code> is the LASSO penalty, and <code>alpha = 0</code> the Ridge penalty.
Can be a vector of several values, but <code>alpha = 0</code> cannot be mixed with other values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda</code></td>
<td>
<p>number of penalization levels.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda_min_ratio</code></td>
<td>
<p>Smallest value of the penalization level as a fraction of the largest
level (i.e., the smallest value for which all coefficients are zero).
The default depends on the sample size relative to the number of variables and <code>alpha</code>.
If more observations than variables are available, the default is <code>1e-3 * alpha</code>,
otherwise <code>1e-2 * alpha</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>optional user-supplied sequence of penalization levels.
If given and not <code>NULL</code>, <code>nlambda</code> and <code>lambda_min_ratio</code> are ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty_loadings</code></td>
<td>
<p>a vector of positive penalty loadings (a.k.a. weights) for
different penalization of each coefficient.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>a vector of positive observation weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>include an intercept in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>en_algorithm_opts</code></td>
<td>
<p>options for the EN algorithm. See en_algorithm_options
for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sparse</code></td>
<td>
<p>use sparse coefficient vectors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>numerical tolerance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standardize</code></td>
<td>
<p>standardize variables to have unit variance.
Coefficients are always returned in original scale.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>correction</code></td>
<td>
<p>defunct. Correction for EN estimates is not supported anymore.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xtest</code></td>
<td>
<p>defunct.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>options</code></td>
<td>
<p>deprecated. Use <code>en_algorithm_opts</code> instead.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The elastic net estimator for the linear regression model solves
the optimization problem
</p>
<p style="text-align: center;"><code class="reqn">argmin_{\mu, \beta}
  (1/2n) \sum_i w_i (y_i - \mu - x_i' \beta)^2 +
  \lambda \sum_j 0.5 (1 - \alpha) \beta_j^2 + \alpha l_j |\beta_j|  </code>
</p>

<p>with observation weights <code class="reqn">w_i</code> and penalty loadings <code class="reqn">l_j</code>.
</p>


<h3>Value</h3>

<p>a list-like object with the following items
</p>

<dl>
<dt><code>alpha</code></dt>
<dd>
<p>the sequence of <code>alpha</code> parameters.</p>
</dd>
<dt><code>lambda</code></dt>
<dd>
<p>a list of sequences of penalization levels, one per <code>alpha</code> parameter.</p>
</dd>
<dt><code>estimates</code></dt>
<dd>
<p>a list of estimates. Each estimate contains the following information:
</p>

<dl>
<dt><code>intercept</code></dt>
<dd>
<p>intercept estimate.</p>
</dd>
<dt><code>beta</code></dt>
<dd>
<p>beta (slope) estimate.</p>
</dd>
<dt><code>lambda</code></dt>
<dd>
<p>penalization level at which the estimate is computed.</p>
</dd>
<dt><code>alpha</code></dt>
<dd>
<p><em>alpha</em> hyper-parameter at which the estimate is computed.</p>
</dd>
<dt><code>statuscode</code></dt>
<dd>
<p>if <code style="white-space: pre;">⁠&gt; 0⁠</code> the algorithm experienced issues when
computing the estimate.</p>
</dd>
<dt><code>status</code></dt>
<dd>
<p>optional status message from the algorithm.</p>
</dd>
</dl>
</dd>
<dt><code>call</code></dt>
<dd>
<p>the original call.</p>
</dd>
</dl>
<h3>See Also</h3>

<p><code>pense()</code> for an S-estimate of regression with elastic net penalty.
</p>
<p><code>coef.pense_fit()</code> for extracting coefficient estimates.
</p>
<p><code>plot.pense_fit()</code> for plotting the regularization path.
</p>
<p>Other functions for computing non-robust estimates: 
<code>elnet_cv()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Compute the LS-EN regularization path for Freeny's revenue data
# (see ?freeny)
data(freeny)
x &lt;- as.matrix(freeny[ , 2:5])

regpath &lt;- elnet(x, freeny$y, alpha = c(0.5, 0.75))
plot(regpath)
plot(regpath, alpha = 0.75)

# Extract the coefficients at a certain penalization level
coef(regpath, lambda = regpath$lambda[[1]][[5]],
     alpha = 0.75)

# What penalization level leads to good prediction performance?
set.seed(123)
cv_results &lt;- elnet_cv(x, freeny$y, alpha = c(0.5, 0.75),
                       cv_repl = 10, cv_k = 4,
                       cv_measure = "tau")
plot(cv_results, se_mult = 1.5)
plot(cv_results, se_mult = 1.5, what = "coef.path")


# Extract the coefficients at the penalization level with
# smallest prediction error ...
summary(cv_results)
coef(cv_results)
# ... or at the penalization level with prediction error
# statistically indistinguishable from the minimum.
summary(cv_results, lambda = "1.5-se")
coef(cv_results, lambda = "1.5-se")
</code></pre>


</div>