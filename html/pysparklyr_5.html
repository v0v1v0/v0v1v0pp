<div class="container">

<table style="width: 100%;"><tr>
<td>install_pyspark</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Installs PySpark and Python dependencies</h2>

<h3>Description</h3>

<p>Installs PySpark and Python dependencies
</p>
<p>Installs Databricks Connect and Python dependencies
</p>


<h3>Usage</h3>

<pre><code class="language-R">install_pyspark(
  version = NULL,
  envname = NULL,
  python_version = NULL,
  new_env = TRUE,
  method = c("auto", "virtualenv", "conda"),
  as_job = TRUE,
  install_ml = FALSE,
  ...
)

install_databricks(
  version = NULL,
  cluster_id = NULL,
  envname = NULL,
  python_version = NULL,
  new_env = TRUE,
  method = c("auto", "virtualenv", "conda"),
  as_job = TRUE,
  install_ml = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>version</code></td>
<td>
<p>Version of 'databricks.connect' to install. Defaults to <code>NULL</code>.
If <code>NULL</code>, it will check against PyPi to get the current library version.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>envname</code></td>
<td>
<p>The name of the Python Environment to use to install the
Python libraries. Defaults to <code>NULL.</code> If <code>NULL</code>, a name will automatically
be assigned based on the version that will be installed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>python_version</code></td>
<td>
<p>The minimum required version of Python to use to create
the Python environment. Defaults to <code>NULL</code>. If <code>NULL</code>, it will check against
PyPi to get the minimum required Python version.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>new_env</code></td>
<td>
<p>If <code>TRUE</code>, any existing Python virtual environment and/or
Conda environment specified by <code>envname</code> is deleted first.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>The installation method to use. If creating a new environment,
<code>"auto"</code> (the default) is equivalent to <code>"virtualenv"</code>. Otherwise <code>"auto"</code>
infers the installation method based on the type of Python environment
specified by <code>envname</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>as_job</code></td>
<td>
<p>Runs the installation if using this function within the
RStudio IDE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>install_ml</code></td>
<td>
<p>Installs ML related Python libraries. Defaults to TRUE. This
is mainly for machines with limited storage to avoid installing the rather
large 'torch' library if the ML features are not going to be used. This will
apply to any environment backed by 'Spark' version 3.5 or above.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Passed on to <code>reticulate::py_install()</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cluster_id</code></td>
<td>
<p>Target of the cluster ID that will be used with.
If provided, this value will be used to extract the cluster's
version</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>It returns no value to the R session. This function purpose is to
create the 'Python' environment, and install the appropriate set of 'Python'
libraries inside the new environment. During runtime, this function will send
messages to the console describing the steps that the function is
taking. For example, it will let the user know if it is getting the latest
version of the Python library from 'PyPi.org', and the result of such
query.
</p>


</div>