<div class="container">

<table style="width: 100%;"><tr>
<td>xgb_train</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Boosted trees via xgboost</h2>

<h3>Description</h3>

<p><code>xgb_train()</code> and <code>xgb_predict()</code> are wrappers for <code>xgboost</code> tree-based
models where all of the model arguments are in the main function.
</p>


<h3>Usage</h3>

<pre><code class="language-R">xgb_train(
  x,
  y,
  weights = NULL,
  max_depth = 6,
  nrounds = 15,
  eta = 0.3,
  colsample_bynode = NULL,
  colsample_bytree = NULL,
  min_child_weight = 1,
  gamma = 0,
  subsample = 1,
  validation = 0,
  early_stop = NULL,
  counts = TRUE,
  event_level = c("first", "second"),
  ...
)

xgb_predict(object, new_data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A data frame or matrix of predictors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>A vector (factor or numeric) or matrix (numeric) of outcome data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_depth</code></td>
<td>
<p>An integer for the maximum depth of the tree.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nrounds</code></td>
<td>
<p>An integer for the number of boosting iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eta</code></td>
<td>
<p>A numeric value between zero and one to control the learning rate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>colsample_bynode</code></td>
<td>
<p>Subsampling proportion of columns for each node
within each tree. See the <code>counts</code> argument below. The default uses all
columns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>colsample_bytree</code></td>
<td>
<p>Subsampling proportion of columns for each tree.
See the <code>counts</code> argument below. The default uses all columns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_child_weight</code></td>
<td>
<p>A numeric value for the minimum sum of instance
weights needed in a child to continue to split.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>
<p>A number for the minimum loss reduction required to make a
further partition on a leaf node of the tree</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subsample</code></td>
<td>
<p>Subsampling proportion of rows. By default, all of the
training data are used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>validation</code></td>
<td>
<p>The <em>proportion</em> of the data that are used for performance
assessment and potential early stopping.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>early_stop</code></td>
<td>
<p>An integer or <code>NULL</code>. If not <code>NULL</code>, it is the number of
training iterations without improvement before stopping. If <code>validation</code> is
used, performance is base on the validation set; otherwise, the training set
is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>counts</code></td>
<td>
<p>A logical. If <code>FALSE</code>, <code>colsample_bynode</code> and
<code>colsample_bytree</code> are both assumed to be <em>proportions</em> of the proportion of
columns affects (instead of counts).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>event_level</code></td>
<td>
<p>For binary classification, this is a single string of either
<code>"first"</code> or <code>"second"</code> to pass along describing which level of the outcome
should be considered the "event".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other options to pass to <code>xgb.train()</code> or xgboost's method for <code>predict()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>new_data</code></td>
<td>
<p>A rectangular data object, such as a data frame.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A fitted <code>xgboost</code> object.
</p>


</div>