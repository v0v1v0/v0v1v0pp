<div class="container">

<table style="width: 100%;"><tr>
<td>pvs.logreg</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
P-Values to Classify New Observations (Penalized Multicategory Logistic Regression)
</h2>

<h3>Description</h3>

<p>Computes nonparametric p-values for the potential class memberships of new observations. The p-values are based on 'penalized logistic regression'.
</p>


<h3>Usage</h3>

<pre><code class="language-R">pvs.logreg(NewX, X, Y, tau.o = 10, find.tau=FALSE, delta=2, tau.max=80, tau.min=1,
           a0 = NULL, b0 = NULL,
           pen.method = c('vectors', 'simple', 'none'),
           progress = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>NewX</code></td>
<td>
<p> data matrix consisting of one or several new observations (row vectors) to be classified. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p> matrix containing training observations, where each observation is a row vector. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p> vector indicating the classes which the training observations belong to. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tau.o</code></td>
<td>
<p> the penalty parameter (see section 'Details' below). </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>find.tau</code></td>
<td>
<p> logical. If TRUE the program searches for the best <code>tau</code>. For more information see section 'Details'. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta</code></td>
<td>
<p> factor for the penalty parameter. Should be greater than 1. Only needed if <code>find.tau == TRUE</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tau.max</code></td>
<td>
<p> maximal penalty parameter considered.  Only needed if <code>find.tau == TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tau.min</code></td>
<td>
<p> minimal penalty parameter considered.  Only needed if <code>find.tau == TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a0, b0</code></td>
<td>
<p> optional starting values for logistic regression. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pen.method</code></td>
<td>
<p> the method of penalization (see section 'Details' below). </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>progress</code></td>
<td>
<p> optional parameter for reporting the status of the computations. </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Computes nonparametric p-values for the potential class memberships of new observations. Precisely, for each new observation <code>NewX[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code>Y[i]</code> equals <code>b</code>.
<br>
This p-value is based on a permutation test applied to an estimated Bayesian likelihood ratio, using 'penalized logistic regression'. This means, the conditional probability of <code class="reqn">Y = y</code>, given <code class="reqn">X = x</code>, is assumed to be proportional to <code class="reqn">exp(a_y + b_y^T x)</code>. The parameters <code class="reqn">a_y</code>, <code class="reqn">b_y</code> are estimated via penalized maximum log-likelihood. The penalization is either a weighted sum of the euclidean norms of the vectors <code class="reqn">(b_1[j],b_2[j],\ldots,b_L[j])</code> (<code>pen.method=='vectors'</code>) or a weighted sum of all moduli <code class="reqn">|b_{\theta}[j]|</code> (<code>pen.method=='simple'</code>). The weights are given by <code>tau.o</code> times the sample standard deviation (within groups) of the <code class="reqn">j</code>-th components of the feature vectors. 
In case of <code>pen.method=='none'</code>, no penalization is used, but this option may be unstable.
<br>
If <code>find.tau == TRUE</code>, the program searches for the best penalty parameter. To determine the best parameter <code>tau</code> for the p-value <code>PV[i,b]</code>, the new observation <code>NewX[i,]</code> is added to the training data with class label <code>b</code> and then for all training observations with <code>Y[j] != b</code> the estimated probability of <code>X[j,]</code> belonging to class <code>b</code> is computed. Then the <code>tau</code> which minimizes the sum of these values is chosen. First, <code>tau.o</code> is compared with <code>tau.o*delta</code>. If <code>tau.o*delta</code> is better, it is compared with <code>tau.o*delta^2</code>, etc. The maximal parameter considered is <code>tau.max</code>. If <code>tau.o</code> is better than <code>tau.o*delta</code>, it is compared with <code>tau.o*delta^-1</code>, etc. The minimal parameter considered is <code>tau.min</code>. 
</p>


<h3>Value</h3>

<p><code>PV</code> is a matrix containing the p-values. Precisely, for each new observation <code>NewX[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>.
<br>
If <code>find.tau == TRUE</code>, <code>PV</code> has an attribute <code>"tau.opt"</code>, which is a matrix and <code>tau.opt[i,b]</code> is the best <code>tau</code> for observation <code>NewX[i,]</code> and class <code>b</code> (see section 'Details'). <code>tau.opt[i,b]</code> is used to compute the p-value for observation <code>NewX[i,]</code> and class <code>b</code>.
</p>


<h3>Author(s)</h3>

<p>Niki Zumbrunnen <a href="mailto:niki.zumbrunnen@gmail.com">niki.zumbrunnen@gmail.com</a> <br>
Lutz Dümbgen <a href="mailto:lutz.duembgen@stat.unibe.ch">lutz.duembgen@stat.unibe.ch</a> <br><a href="www.imsv.unibe.ch/duembgen/index_ger.html">www.imsv.unibe.ch/duembgen/index_ger.html</a>
</p>


<h3>References</h3>

<p>Zumbrunnen N. and Dümbgen L. (2017)
pvclass: An R Package for p Values for Classification.
<em>Journal of Statistical Software <b>78(4)</b></em>, 1–19.
doi:10.18637/jss.v078.i04
</p>
<p>Dümbgen L., Igl B.-W. and Munk A. (2008)
P-Values for Classification.
<em>Electronic Journal of Statistics <b>2</b></em>, 468–493, available at <a href="http://dx.doi.org/10.1214/08-EJS245">http://dx.doi.org/10.1214/08-EJS245</a>.
</p>
<p>Zumbrunnen N. (2014)
P-Values for Classification – Computational Aspects and Asymptotics.
Ph.D. thesis, University of Bern, available at <a href="http://boris.unibe.ch/id/eprint/53585">http://boris.unibe.ch/id/eprint/53585</a>.
</p>


<h3>See Also</h3>

 
<p><code> pvs, pvs.gaussian, pvs.knn, pvs.wnn</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">X &lt;- iris[c(1:49, 51:99, 101:149), 1:4]
Y &lt;- iris[c(1:49, 51:99, 101:149), 5]
NewX &lt;- iris[c(50, 100, 150), 1:4]

pvs.logreg(NewX, X, Y, tau.o=1, pen.method="vectors", progress=TRUE)

# A bigger data example: Buerk's hospital data.
## Not run: 
data(buerk)
X.raw &lt;- as.matrix(buerk[,1:21])
Y.raw &lt;- buerk[,22]
n0.raw &lt;- sum(1 - Y.raw)
n1 &lt;- sum(Y.raw)
n0 &lt;- 3*n1

X0 &lt;- X.raw[Y.raw==0,]
X1 &lt;- X.raw[Y.raw==1,]

tmpi0 &lt;- sample(1:n0.raw,size=3*n1,replace=FALSE)
tmpi1 &lt;- sample(1:n1    ,size=  n1,replace=FALSE)

Xtrain &lt;- rbind(X0[tmpi0[1:(n0-100)],],X1[1:(n1-100),])
Ytrain &lt;- c(rep(1,n0-100),rep(2,n1-100))
Xtest &lt;- rbind(X0[tmpi0[(n0-99):n0],],X1[(n1-99):n1,])
Ytest &lt;- c(rep(1,100),rep(2,100))

PV &lt;- pvs.logreg(Xtest,Xtrain,Ytrain,tau.o=2,progress=TRUE)
analyze.pvs(Y=Ytest,pv=PV,pvplot=FALSE)

## End(Not run)
</code></pre>


</div>