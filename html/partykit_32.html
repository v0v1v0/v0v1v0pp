<div class="container">

<table style="width: 100%;"><tr>
<td>mob</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Model-based Recursive Partitioning</h2>

<h3>Description</h3>

<p>MOB is an algorithm for model-based recursive partitioning yielding
a tree with fitted models associated with each terminal node.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mob(formula, data, subset, na.action, weights, offset, cluster,
  fit, control = mob_control(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>symbolic description of the model (of type
<code>y ~ z1 + ... + zl</code> or <code>y ~ x1 + ... + xk | z1 + ... + zl</code>;
for details see below).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data, subset, na.action</code></td>
<td>
<p>arguments controlling formula processing
via <code>model.frame</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>optional numeric vector of weights. By default these are
treated as case weights but the default can be changed in
<code>mob_control</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>offset</code></td>
<td>
<p>optional numeric vector with an a priori known component to be
included in the model <code>y ~ x1 + ... + xk</code> (i.e., only when
<code>x</code> variables are specified).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cluster</code></td>
<td>
<p>optional vector (typically numeric or factor) with a
cluster ID to be passed on to the <code>fit</code> function and employed
for clustered covariances in the parameter stability tests.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fit</code></td>
<td>
<p>function. A function for fitting the model within each node.
For details see below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>A list with control parameters as returned by
<code>mob_control</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments passed to the <code>fit</code> function.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Model-based partitioning fits a model tree using two groups of variables:
(1) The model variables which can be just a (set of) response(s) <code>y</code> or
additionally include regressors <code>x1</code>, ..., <code>xk</code>. These are used
for estimating the model parameters.
(2) Partitioning variables <code>z1</code>, ..., <code>zl</code>, which are used for
recursively partitioning the data. The two groups of variables are either specified
as <code>y ~ z1 + ... + zl</code> (when there are no regressors) or
<code>y ~ x1 + ... + xk | z1 + ... + zl</code> (when the model part contains regressors).
Both sets of variables may in principle be overlapping.
</p>
<p>To fit a tree model the following algorithm is used.
</p>

<ol>
<li> <p><code>fit</code> a model to the <code>y</code> or <code>y</code> and <code>x</code> variables
using the observations in the current node
</p>
</li>
<li>
<p> Assess the stability of the model parameters with respect to each
of the partitioning variables <code>z1</code>, ..., <code>zl</code>. If
there is some overall instability, choose the variable <code>z</code>
associated with the smallest <code class="reqn">p</code> value for partitioning, otherwise
stop.
</p>
</li>
<li>
<p> Search for the locally optimal split in <code>z</code> by minimizing the
objective function of the model. Typically, this will be
something like <code>deviance</code> or the negative <code>logLik</code>.
</p>
</li>
<li>
<p> Refit the <code>model</code> in both kid subsamples and repeat from step 2.
</p>
</li>
</ol>
<p>More details on the conceptual design of the algorithm can be found in 
Zeileis, Hothorn, Hornik (2008) and some illustrations are provided in
<code>vignette("MOB")</code>.
For specifying the <code>fit</code> function two approaches are possible:
</p>
<p>(1) It can be a function <code>fit(y, x = NULL, start = NULL, weights = NULL,
offset = NULL, ...)</code>. The arguments <code>y</code>, <code>x</code>, <code>weights</code>, <code>offset</code>
will be set to the corresponding elements in the current node of the tree.
Additionally, starting values will sometimes be supplied via <code>start</code>.
Of course, the <code>fit</code> function can choose to ignore any arguments that are
not applicable, e.g., if the are no regressors <code>x</code> in the model or if
starting values or not supported. The returned object needs to have a class
that has associated <code>coef</code>, <code>logLik</code>, and
<code>estfun</code> methods for extracting the estimated parameters,
the maximized log-likelihood, and the empirical estimating function (i.e.,
score or gradient contributions), respectively.
</p>
<p>(2) It can be a function <code>fit(y, x = NULL, start = NULL, weights = NULL,
offset = NULL, ..., estfun = FALSE, object = FALSE)</code>. The arguments have the
same meaning as above but the returned object needs to have a different structure.
It needs to be a list with elements <code>coefficients</code> (containing the estimated
parameters), <code>objfun</code> (containing the minimized objective function),
<code>estfun</code> (the empirical estimating functions), and <code>object</code> (the
fitted model object). The elements <code>estfun</code>, or <code>object</code> should be
<code>NULL</code> if the corresponding argument is set to <code>FALSE</code>.
</p>
<p>Internally, a function of type (2) is set up by <code>mob()</code> in case a function
of type (1) is supplied. However, to save computation time, a function of type
(2) may also be specified directly.
</p>
<p>For the fitted MOB tree, several standard methods are provided such as
<code>print</code>, <code>predict</code>, <code>residuals</code>, <code>logLik</code>, <code>deviance</code>,
<code>weights</code>, <code>coef</code> and <code>summary</code>. Some of these rely on reusing the
corresponding methods for the individual model objects in the terminal nodes.
Functions such as <code>coef</code>, <code>print</code>, <code>summary</code> also take a
<code>node</code> argument that can specify the node IDs to be queried.
Some examples are given below.
</p>
<p>More details can be found in <code>vignette("mob", package = "partykit")</code>.
An overview of the connections to other functions in the package is provided
by Hothorn and Zeileis (2015).
</p>


<h3>Value</h3>

<p>An object of class <code>modelparty</code> inheriting from <code>party</code>.
The <code>info</code> element of the overall <code>party</code> and the individual
<code>node</code>s contain various informations about the models.
</p>


<h3>References</h3>

 
<p>Hothorn T, Zeileis A (2015).
partykit: A Modular Toolkit for Recursive Partytioning in R.
<em>Journal of Machine Learning Research</em>, <b>16</b>, 3905–3909.
</p>
<p>Zeileis A, Hothorn T, Hornik K (2008).
Model-Based Recursive Partitioning.
<em>Journal of Computational and Graphical Statistics</em>, <b>17</b>(2), 492–514.
</p>


<h3>See Also</h3>

<p><code>mob_control</code>, <code>lmtree</code>, <code>glmtree</code></p>


<h3>Examples</h3>

<pre><code class="language-R">if(require("mlbench")) {

## Pima Indians diabetes data
data("PimaIndiansDiabetes", package = "mlbench")

## a simple basic fitting function (of type 1) for a logistic regression
logit &lt;- function(y, x, start = NULL, weights = NULL, offset = NULL, ...) {
  glm(y ~ 0 + x, family = binomial, start = start, ...)
}

## set up a logistic regression tree
pid_tree &lt;- mob(diabetes ~ glucose | pregnant + pressure + triceps + insulin +
  mass + pedigree + age, data = PimaIndiansDiabetes, fit = logit)
## see lmtree() and glmtree() for interfaces with more efficient fitting functions

## print tree
print(pid_tree)

## print information about (some) nodes
print(pid_tree, node = 3:4)

## visualization
plot(pid_tree)

## coefficients and summary
coef(pid_tree)
coef(pid_tree, node = 1)
summary(pid_tree, node = 1)

## average deviance computed in different ways
mean(residuals(pid_tree)^2)
deviance(pid_tree)/sum(weights(pid_tree))
deviance(pid_tree)/nobs(pid_tree)

## log-likelihood and information criteria
logLik(pid_tree)
AIC(pid_tree)
BIC(pid_tree)

## predicted nodes
predict(pid_tree, newdata = head(PimaIndiansDiabetes, 6), type = "node")
## other types of predictions are possible using lmtree()/glmtree()
}
</code></pre>


</div>