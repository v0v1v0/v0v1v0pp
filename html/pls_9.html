<div class="container">

<table style="width: 100%;"><tr>
<td>cppls.fit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>CPPLS (Indahl et al.)</h2>

<h3>Description</h3>

<p>Fits a PLS model using the CPPLS algorithm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cppls.fit(
  X,
  Y,
  ncomp,
  Y.add = NULL,
  center = TRUE,
  stripped = FALSE,
  lower = 0.5,
  upper = 0.5,
  trunc.pow = FALSE,
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>a matrix of observations.  <code>NA</code>s and <code>Inf</code>s are not
allowed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>a vector or matrix of responses.  <code>NA</code>s and <code>Inf</code>s are
not allowed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncomp</code></td>
<td>
<p>the number of components to be used in the modelling.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y.add</code></td>
<td>
<p>a vector or matrix of additional responses containing relevant
information about the observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>
<p>logical, determines if the <code class="reqn">X</code> and <code class="reqn">Y</code> matrices are
mean centered or not. Default is to perform mean centering.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stripped</code></td>
<td>
<p>logical.  If <code>TRUE</code> the calculations are stripped as
much as possible for speed; this is meant for use with cross-validation or
simulations when only the coefficients are needed.  Defaults to
<code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower</code></td>
<td>
<p>a vector of lower limits for power optimisation. Defaults to
<code>0.5</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>upper</code></td>
<td>
<p>a vector of upper limits for power optimisation. Defaults to
<code>0.5</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trunc.pow</code></td>
<td>
<p>logical. If <code>TRUE</code> an experimental alternative power
algorithm is used. (Optional)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>a vector of individual weights for the observations.
(Optional)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>other arguments.  Currently ignored.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function should not be called directly, but through the generic
functions <code>cppls</code> or <code>mvr</code> with the argument
<code>method="cppls"</code>. Canonical Powered PLS (CPPLS) is a generalisation of
PLS incorporating discrete and continuous responses (also simultaneously),
additional responses, individual weighting of observations and power
methodology for sharpening focus on groups of variables. Depending on the
input to <code>cppls</code> it can produce the following special cases: </p>

<ul>
<li>
<p> PLS: uni-response continuous <code>Y</code> </p>
</li>
<li>
<p> PPLS: uni-response
continuous <code>Y</code>, <code>(lower || upper) != 0.5</code> </p>
</li>
<li>
<p> PLS-DA (using
correlation maximisation - B/W): dummy-coded descrete response <code>Y</code>
</p>
</li>
<li>
<p> PPLS-DA: dummy-coded descrete response <code>Y</code>, <code>(lower ||
upper) != 0.5</code> </p>
</li>
<li>
<p> CPLS: multi-response <code>Y</code> (continuous, discrete or
combination) </p>
</li>
<li>
<p> CPPLS: multi-response <code>Y</code> (continuous, discrete or
combination), <code>(lower || upper) != 0.5</code> </p>
</li>
</ul>
<p> The name "canonical" comes
from canonical correlation analysis which is used when calculating vectors
of loading weights, while "powered" refers to a reparameterisation of the
vectors of loading weights which can be optimised over a given interval.
</p>


<h3>Value</h3>

<p>A list containing the following components is returned:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>coefficients</code></td>
<td>
<p>an array of regression coefficients for 1, ...,
<code>ncomp</code> components.  The dimensions of <code>coefficients</code> are
<code>c(nvar, npred, ncomp)</code> with <code>nvar</code> the number of <code>X</code>
variables and <code>npred</code> the number of variables to be predicted in
<code>Y</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scores</code></td>
<td>
<p>a matrix of scores.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loadings</code></td>
<td>
<p>a matrix of
loadings.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loading.weights</code></td>
<td>
<p>a matrix of loading weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Yscores</code></td>
<td>
<p>a matrix of Y-scores.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Yloadings</code></td>
<td>
<p>a matrix of
Y-loadings.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>projection</code></td>
<td>
<p>the projection matrix used to convert X to
scores.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xmeans</code></td>
<td>
<p>a vector of means of the X variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ymeans</code></td>
<td>
<p>a vector of means of the Y variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitted.values</code></td>
<td>
<p>an
array of fitted values.  The dimensions of <code>fitted.values</code> are
<code>c(nobj, npred, ncomp)</code> with <code>nobj</code> the number samples and
<code>npred</code> the number of Y variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>residuals</code></td>
<td>
<p>an array of
regression residuals.  It has the same dimensions as <code>fitted.values</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xvar</code></td>
<td>
<p>a vector with the amount of X-variance explained by each
component.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xtotvar</code></td>
<td>
<p>total variance in <code>X</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gammas</code></td>
<td>
<p>gamma-values obtained in power optimisation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>canonical.correlations</code></td>
<td>
<p>Canonical correlation values from the
calculations of loading weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>A</code></td>
<td>
<p>matrix containing vectors of
weights <code>a</code> from canonical correlation (<code>cor(Za,Yb)</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>smallNorms</code></td>
<td>
<p>vector of indices of explanatory variables of length close
to or equal to 0.</p>
</td>
</tr>
</table>
<p>If <code>stripped</code> is <code>TRUE</code>, only the components <code>coefficients</code>,
<code>Xmeans</code>, <code>Ymeans</code> and <code>gammas</code> are returned.
</p>


<h3>Author(s)</h3>

<p>Kristian Hovde Liland
</p>


<h3>References</h3>

<p>Indahl, U. (2005) A twist to partial least squares regression.
<em>Journal of Chemometrics</em>, <b>19</b>, 32–44.
</p>
<p>Liland, K.H and Indahl, U.G (2009) Powered partial least squares
discriminant analysis, <em>Journal of Chemometrics</em>, <b>23</b>, 7–18.
</p>
<p>Indahl, U.G., Liland, K.H. and Næs, T. (2009) Canonical partial least
squares - a unified PLS approach to classification and regression problems.
<em>Journal of Chemometrics</em>, <b>23</b>, 495–504.
</p>


<h3>See Also</h3>

<p><code>mvr</code> <code>plsr</code> <code>pcr</code>
<code>widekernelpls.fit</code> <code>simpls.fit</code>
<code>oscorespls.fit</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(mayonnaise)
# Create dummy response
mayonnaise$dummy &lt;-
    I(model.matrix(~y-1, data.frame(y = factor(mayonnaise$oil.type))))

# Predict CPLS scores for test data
may.cpls &lt;- cppls(dummy ~ NIR, 10, data = mayonnaise, subset = train)
may.test &lt;- predict(may.cpls, newdata = mayonnaise[!mayonnaise$train,], type = "score")

# Predict CPLS scores for test data (experimental used design as additional Y information)
may.cpls.yadd &lt;- cppls(dummy ~ NIR, 10, data = mayonnaise, subset = train, Y.add=design)
may.test.yadd &lt;- predict(may.cpls.yadd, newdata = mayonnaise[!mayonnaise$train,], type = "score")

# Classification by linear discriminant analysis (LDA)
library(MASS)
error &lt;- matrix(ncol = 10, nrow = 2)
dimnames(error) &lt;- list(Model = c('CPLS', 'CPLS (Y.add)'), ncomp = 1:10)
for (i in 1:10) {
    fitdata1 &lt;- data.frame(oil.type = mayonnaise$oil.type[mayonnaise$train],
                           NIR.score = I(may.cpls$scores[,1:i,drop=FALSE]))
    testdata1 &lt;- data.frame(oil.type = mayonnaise$oil.type[!mayonnaise$train],
                            NIR.score = I(may.test[,1:i,drop=FALSE]))
    error[1,i] &lt;-
        (42 - sum(predict(lda(oil.type ~ NIR.score, data = fitdata1),
                  newdata = testdata1)$class == testdata1$oil.type)) / 42
    fitdata2 &lt;- data.frame(oil.type = mayonnaise$oil.type[mayonnaise$train],
                           NIR.score = I(may.cpls.yadd$scores[,1:i,drop=FALSE]))
    testdata2 &lt;- data.frame(oil.type = mayonnaise$oil.type[!mayonnaise$train],
                            NIR.score = I(may.test.yadd[,1:i,drop=FALSE]))
    error[2,i] &lt;-
        (42 - sum(predict(lda(oil.type ~ NIR.score, data = fitdata2),
                  newdata = testdata2)$class == testdata2$oil.type)) / 42
}
round(error,2)

</code></pre>


</div>