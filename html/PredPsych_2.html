<div class="container">

<table style="width: 100%;"><tr>
<td>classifyFun</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Generic Classification Analyses</h2>

<h3>Description</h3>

<p>function for performing generic classification Analysis
</p>


<h3>Usage</h3>

<pre><code class="language-R">classifyFun(Data, classCol, selectedCols, cvType, ntrainTestFolds,
  nTrainFolds, modelTrainFolds, nTuneFolds, tuneFolds, foldSep, cvFraction,
  ranges = NULL, tune = FALSE, cost = 1, gamma = 0.5,
  classifierName = "svm", genclassifier, silent = FALSE,
  extendedResults = FALSE, SetSeed = TRUE, NewData = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Data</code></td>
<td>
<p>(dataframe) dataframe of the data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classCol</code></td>
<td>
<p>(numeric or string) column number that contains the variable to be predicted</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectedCols</code></td>
<td>
<p>(optional) (numeric or string) all the columns of data that would be used either as predictor or as feature</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cvType</code></td>
<td>
<p>(optional) (string) which type of cross-validation scheme to follow; One of the following values:
</p>

<ul>
<li>
<p> folds       =  (default) k-fold cross-validation 
</p>
</li>
<li>
<p> LOSO        =  Leave-one-subject-out cross-validation
</p>
</li>
<li>
<p> holdout     =  holdout Crossvalidation. Only a portion of data (cvFraction) is used for training.
</p>
</li>
<li>
<p> LOTO        =  Leave-one-trial out cross-validation.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ntrainTestFolds</code></td>
<td>
<p>(optional) (parameter for only k-fold cross-validation) No. of folds for training and testing dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nTrainFolds</code></td>
<td>
<p>(optional) (parameter for only k-fold cross-validation) No. of folds in which to further divide Training dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>modelTrainFolds</code></td>
<td>
<p>=  (optional) (parameter for only k-fold cross-validation) specific folds from the first train/test split
(ntrainTestFolds) to use for training</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nTuneFolds</code></td>
<td>
<p>(optional) (parameter for only k-fold cross-validation) No. of folds for Tuning</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tuneFolds</code></td>
<td>
<p>(optional) (parameter for only k-fold cross-validation) specific folds from the above nTuneFolds to use for tuning</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>foldSep</code></td>
<td>
<p>(numeric)  (parameter for only Leave-One_subject Out) mandatory column number for Leave-one-subject out cross-validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cvFraction</code></td>
<td>
<p>(optional) (numeric) Fraction of data to keep for training data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ranges</code></td>
<td>
<p>(optional) (list)  ranges for tuning support vector machine</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tune</code></td>
<td>
<p>(optional) (logical) whether tuning of svm parameters should be performed or not</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cost</code></td>
<td>
<p>(optional) (numeric) regularization parameter of svm</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>
<p>(optional) (numeric)  rbf kernel parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classifierName</code></td>
<td>
<p>(optional) (string) name of the classifier to be used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>genclassifier</code></td>
<td>
<p>(optional) (function or string) a classifier function or a name (e.g. Classifier.svm)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>silent</code></td>
<td>
<p>(optional) (logical) whether to print messages or not</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>extendedResults</code></td>
<td>
<p>(optional) (logical) Return extended results with model and other metrics</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>SetSeed</code></td>
<td>
<p>(optional) (logical) Whether to setseed or not. use SetSeed to seed the random number generator to get consistent results; 
set false only for permutation tests</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>NewData</code></td>
<td>
<p>(optional) (dataframe) New Data frame features for which the class membership is requested</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>(optional) additional arguments for the function</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function implements Classification Analysis. 
Classification Analysis is a supervised machine learning approach that attempts to identify 
holistic patters in the data and assign to it classes (classification). Given a set of features, 
a classification analysis automatically learns intrinsic patterns in the data to be able to predict 
respective classes. If the data features are informative about the classes, a high classification score
would be achieved.
</p>


<h3>Value</h3>

<p>Depending upon <code>extendedResults</code>. <code>extendedResults</code>  = FALSE outputs Test accuracy <code>accTest</code> of discrimination; <code>extendedResults</code> = TRUE 
outputs Test accuracy <code>accTest</code> of discrimination, <code>accTestRun</code> discrimination for each run in case of cvType as LOSO,LOTO or Folds <code>ConfMatrix</code> Confusion matrices and <code>classificationResults</code> list of the cross-validation results including the model 
and  <code>ConfusionMatrixResults</code> Overall cross-validated confusion matrix results
</p>


<h3>Author(s)</h3>

<p>Atesh Koul, C'MON unit, Istituto Italiano di Tecnologia
</p>
<p><a href="mailto:atesh.koul@gmail.com">atesh.koul@gmail.com</a>
</p>


<h3>References</h3>

<p>Duda, R. O., Hart, P. E., &amp; Stork, D. G. (2000). Pattern Classification. Wiley-Interscience (Vol. 24).
</p>
<p>Vapnik, V. (1995). The Nature of statistical Learning Theory. Springer-Verlag New York.
</p>
<p>Hsu, C. C., Chang, C. C., &amp; Lin, C. C. (2003). A practical guide to support vector classification, 1(1), 1-16.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># classification analysis with SVM
Results &lt;- classifyFun(Data = KinData,classCol = 1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),cvType="holdout")

# Output:

# Performing Classification Analysis
#
# Performing holdout Cross-validation
# genclassifier was not specified, 
#   Using default value of Classifier.svm (genclassifier = Classifier.svm)"
# 
# cvFraction was not specified, 
#  Using default value of 0.8 (cvFraction = 0.8)
# 
# Proportion of Test/Train Data was :  0.2470588 
# [1] "Test holdout Accuracy is  0.65"
# holdout classification Analysis: 
# cvFraction : 0.8 
# Test Accuracy 0.65
# *Legend:
# cvFraction = Fraction of data to keep for training data 
# Test Accuracy = Accuracy from the Testing dataset

# Alternate uses:
# perform a k-folds cross-validated classification analysis:
Results &lt;- classifyFun(Data = KinData,classCol = 1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),cvType = "folds")

# use extendedResults as well as tuning
Results &lt;- classifyFun(Data = KinData,classCol = 1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),
cvType = "folds",extendedResults = TRUE,tune=TRUE)



</code></pre>


</div>