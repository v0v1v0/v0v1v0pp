<div class="container">

<table style="width: 100%;"><tr>
<td>details_rand_forest_spark</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Random forests via spark</h2>

<h3>Description</h3>

<p><code>sparklyr::ml_random_forest()</code> fits a model that creates a large number of
decision trees, each independent of the others. The final prediction uses all
predictions from the individual trees and combines them.
</p>


<h3>Details</h3>

<p>For this engine, there are multiple modes: classification and regression
</p>


<h4>Tuning Parameters</h4>

<p>This model has 3 tuning parameters:
</p>

<ul>
<li> <p><code>mtry</code>: # Randomly Selected Predictors (type: integer, default: see
below)
</p>
</li>
<li> <p><code>trees</code>: # Trees (type: integer, default: 20L)
</p>
</li>
<li> <p><code>min_n</code>: Minimal Node Size (type: integer, default: 1L)
</p>
</li>
</ul>
<p><code>mtry</code> depends on the number of columns and the model mode. The default
in <code>sparklyr::ml_random_forest()</code> is
<code>floor(sqrt(ncol(x)))</code> for classification and <code>floor(ncol(x)/3)</code> for
regression.
</p>



<h4>Translation from parsnip to the original package (regression)</h4>

<div class="sourceCode r"><pre>rand_forest(
  mtry = integer(1),
  trees = integer(1),
  min_n = integer(1)
) %&gt;%  
  set_engine("spark") %&gt;% 
  set_mode("regression") %&gt;% 
  translate()
</pre></div>
<div class="sourceCode"><pre>## Random Forest Model Specification (regression)
## 
## Main Arguments:
##   mtry = integer(1)
##   trees = integer(1)
##   min_n = integer(1)
## 
## Computational engine: spark 
## 
## Model fit template:
## sparklyr::ml_random_forest(x = missing_arg(), formula = missing_arg(), 
##     type = "regression", feature_subset_strategy = integer(1), 
##     num_trees = integer(1), min_instances_per_node = min_rows(~integer(1), 
##         x), seed = sample.int(10^5, 1))
</pre></div>
<p><code>min_rows()</code> and <code>min_cols()</code> will adjust the number of neighbors if the
chosen value if it is not consistent with the actual data dimensions.
</p>



<h4>Translation from parsnip to the original package (classification)</h4>

<div class="sourceCode r"><pre>rand_forest(
  mtry = integer(1),
  trees = integer(1),
  min_n = integer(1)
) %&gt;% 
  set_engine("spark") %&gt;% 
  set_mode("classification") %&gt;% 
  translate()
</pre></div>
<div class="sourceCode"><pre>## Random Forest Model Specification (classification)
## 
## Main Arguments:
##   mtry = integer(1)
##   trees = integer(1)
##   min_n = integer(1)
## 
## Computational engine: spark 
## 
## Model fit template:
## sparklyr::ml_random_forest(x = missing_arg(), formula = missing_arg(), 
##     type = "classification", feature_subset_strategy = integer(1), 
##     num_trees = integer(1), min_instances_per_node = min_rows(~integer(1), 
##         x), seed = sample.int(10^5, 1))
</pre></div>



<h4>Preprocessing requirements</h4>

<p>This engine does not require any special encoding of the predictors.
Categorical predictors can be partitioned into groups of factor levels
(e.g. <code style="white-space: pre;">⁠{a, c}⁠</code> vs <code style="white-space: pre;">⁠{b, d}⁠</code>) when splitting at a node. Dummy variables
are not required for this model.
</p>



<h4>Other details</h4>

<p>For models created using the <code>"spark"</code> engine, there are several things
to consider.
</p>

<ul>
<li>
<p> Only the formula interface to via <code>fit()</code> is available; using
<code>fit_xy()</code> will generate an error.
</p>
</li>
<li>
<p> The predictions will always be in a Spark table format. The names will
be the same as documented but without the dots.
</p>
</li>
<li>
<p> There is no equivalent to factor columns in Spark tables so class
predictions are returned as character columns.
</p>
</li>
<li>
<p> To retain the model object for a new R session (via <code>save()</code>), the
<code>model$fit</code> element of the parsnip object should be serialized via
<code>ml_save(object$fit)</code> and separately saved to disk. In a new session,
the object can be reloaded and reattached to the parsnip object.
</p>
</li>
</ul>
<h4>Case weights</h4>

<p>This model can utilize case weights during model fitting. To use them,
see the documentation in case_weights and the examples
on <code>tidymodels.org</code>.
</p>
<p>The <code>fit()</code> and <code>fit_xy()</code> arguments have arguments called
<code>case_weights</code> that expect vectors of case weights.
</p>
<p>Note that, for spark engines, the <code>case_weight</code> argument value should be
a character string to specify the column with the numeric case weights.
</p>



<h4>References</h4>


<ul><li>
<p> Kuhn, M, and K Johnson. 2013. <em>Applied Predictive Modeling</em>. Springer.
</p>
</li></ul>
</div>