<div class="container">

<table style="width: 100%;"><tr>
<td>ComparisonResults-class</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Class "ComparisonResults" </h2>

<h3>Description</h3>

<p>	 This is the main class that holds the results of
performance estimation experiments involving several alternative
workflows being applied and compared to several predictive tasks. For
each workflow and task, a set of predictive performance metrics are
estimated using some methodology and the results of this process are
stored in these objets. </p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form
<code>ComparisonResults(...)</code>. These object are essentially
a list of lists of objects of class
<code>EstimationResults</code>. The top level is named list
with has as many components as there are tasks. For each task there
will be a named sub-list containing as many components as there are alternative workflows. Each
of these components will contain and object of class
<code>EstimationResults</code> with the estimation results for
the particular workflow / task combination.
</p>


<h3>Methods</h3>


<dl>
<dt>plot</dt>
<dd>
<p><code>signature(x = "ComparisonResults", y = "missing")</code>: plots
the results of the experiments. It can result in an over-cluttered
graph if too many workflows/tasks/evaluation metrics - use the
subset method (see below) to overcome this.</p>
</dd>
<dt>show</dt>
<dd>
<p><code>signature(object = "ComparisonResults")</code>: shows the contents of an object in a proper way</p>
</dd>
<dt>subset</dt>
<dd>
<p><code>signature(x = "ComparisonResults")</code>: can be used to obtain
a smaller ComparisonResults object containing only a subset of the information
of the provided object. This method also accepts the arguments "tasks",
"workflows" and "metrics". All are vectors of numbers or names
that can be used to subset the original object. They default to all values of each dimension. See "methods?subset" for further details.</p>
</dd>
<dt>summary</dt>
<dd>
<p><code>signature(object = "ComparisonResults")</code>: provides a
summary of the performance estimation experiment. </p>
</dd>
</dl>
<h3>Author(s)</h3>

<p> Luis Torgo <a href="mailto:ltorgo@dcc.fc.up.pt">ltorgo@dcc.fc.up.pt</a> </p>


<h3>References</h3>

<p> Torgo, L. (2014) <em>An Infra-Structure for Performance
Estimation and Experimental Comparison of Predictive Models in R</em>. arXiv:1412.0436 [cs.MS]
<a href="http://arxiv.org/abs/1412.0436">http://arxiv.org/abs/1412.0436</a>  
</p>


<h3>See Also</h3>

<p><code>performanceEstimation</code>,
<code>pairedComparisons</code>,
<code>rankWorkflows</code>,
<code>topPerformers</code>,
<code>metricsSummary</code>,
<code>mergeEstimationRes</code>  
</p>


<h3>Examples</h3>

<pre><code class="language-R">showClass("ComparisonResults")
## Not run: 
## Estimating MAE, MSE, RMSE and MAPE for 3 variants of both
## regression trees and SVMs, on  two data sets, using one repetition
## of 10-fold CV
library(e1071)
library(DMwR)
data(swiss)
data(mtcars)

## running the estimation experiment
res &lt;- performanceEstimation(
  c(PredTask(Infant.Mortality ~ .,swiss),PredTask(mpg ~ ., mtcars)),
  c(workflowVariants(learner="svm",
                     learner.pars=list(cost=c(1,10),gamma=c(0.01,0.5))),
    workflowVariants(learner="rpartXse",
                     learner.pars=list(se=c(0,0.5,1)))
  ),
  EstimationTask(metrics=c("mae","mse","rmse","mape"),method=CV())
  )

## Check a summary of the results
summary(res)

topPerformers(res)

summary(subset(res,metrics="mse"))
summary(subset(res,metrics="mse",partial=FALSE))
summary(subset(res,workflows="v1"))

## End(Not run)

</code></pre>


</div>