<div class="container">

<table style="width: 100%;"><tr>
<td>pgmmEM</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Model-Based Clustering &amp; Classification Using PGMMs</h2>

<h3>Description</h3>

<p>Carries out model-based clustering or classification using parsimonious Gaussian mixture models. AECM algorithms are used for parameter estimation. The BIC or the ICL is used for model selection.</p>


<h3>Usage</h3>

<pre><code class="language-R">pgmmEM(x,rG=1:2,rq=1:2,class=NULL,icl=FALSE,zstart=2,cccStart=TRUE,loop=3,zlist=NULL,
		modelSubset=NULL,seed=123456,tol=0.1,relax=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>A matrix or data frame such that rows correspond to observations and columns correspond to variables.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rG</code></td>
<td>

<p>The range of values for the number of components.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rq</code></td>
<td>

<p>The range of values for the number of factors.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>class</code></td>
<td>

<p>If <code>NULL</code> then model-based clustering is performed. If a vector with length equal to the number of observations, then model-based classification is performed. In this latter case, the ith entry of <code>class</code> is either zero, indicating that the component membership of observation i is unknown, or it corresponds to the component membership of observation i. See Examples below.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>icl</code></td>
<td>

<p>If <code>TRUE</code> then the ICL is used for model selection. Otherwise, the BIC is used for model selection.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>zstart</code></td>
<td>

<p>A number that controls what starting values are used: (<code>1</code>) Random; (<code>2</code>) k-means; or 
(<code>3</code>) user-specified via <code>zlist</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cccStart</code></td>
<td>

<p>If <code>TRUE</code> then random starting values are put through the CCC model and the resulting group memberships are used as starting values for the models specified in <code>modelSubset</code>. Only relevant for <code>zstart=1</code>. See Examples.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loop</code></td>
<td>

<p>A number specifying how many different random starts should be used. Only relevant for <code>zstart=1</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>zlist</code></td>
<td>

<p>A list comprising vectors of initial classifications such that <code>zlist[[g]]</code> gives the g-component starting values. Only relevant for <code>zstart=3</code>. See Examples.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>modelSubset</code></td>
<td>

<p>A vector of strings giving the models to be used.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>

<p>A number giving the pseudo-random number seed to be used.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>

<p>A number specifying the epsilon value for the convergence criteria used in the AECM algorithms. For each algorithm, the criterion is based on the difference between the log-likelihood at an iteration and an asymptotic estimate of the log-likelihood at that iteration. This asymptotic estimate is based on the Aitken acceleration and details are given in the References. Values of <code>tol</code> greater than the default are not accepted.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>relax</code></td>
<td>

<p>By default, the number of factors q must respect (p-q)^2 &gt; p+q, where p is the number of variables (see Lawley &amp; Maxwell, 1962). This is based on the values of q that will give data reduction in the factor analysis model or the mixture of factor analyzers model, i.e., model UUU. The same restriction applies for model CUU. However, for the other PGMM models, the restriction is a little different. The default <code>relax=FALSE</code> applies the constraint (p-q)^2 &gt; p+q to the (maximum) value of q for all models. Setting <code>relax=TRUE</code> relaxes this constraint and allows q to take larger values; however, this option is not recommended for non-experts.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The data <code>x</code> are either clustered using the PGMM approach of McNicholas &amp; Murphy (2005, 2008, 2010) or classified using the method described by McNicholas (2010). In either case, all 12 covariance structures given by McNicholas &amp; Murphy (2010) are available. Parameter estimation is carried out using AECM algorithms, as described in McNicholas et al. (2010). Either the BIC or the ICL is used for model-selection. The number of AECM algorithms to be run depends on the range of values for the number of components <code>rG</code>, the range of values for the number of factors <code>rq</code>, and the number of models in <code>modelSubset</code>. Starting values are very important to the successful operation of these algorithms and so care must be taken in the interpretation of results. 
</p>


<h3>Value</h3>

<p>An object of class <code>pgmm</code> is a list with components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>map</code></td>
<td>
<p>A vector of integers, taking values in the range <code>rG</code>, indicating the maximum <em>a posteriori</em> classifications for the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>A string giving the name of the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>g</code></td>
<td>
<p>The number of components for the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q</code></td>
<td>
<p>The number of factors for the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>zhat</code></td>
<td>
<p>A matrix giving the raw values upon which <code>map</code> is based.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>load</code></td>
<td>
<p>The factor loadings matrix (Lambda) for the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>noisev</code></td>
<td>
<p>The Psi matrix for the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot_info</code></td>
<td>
<p>A list that stores information to enable <code>plot</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>summ_info</code></td>
<td>
<p>A list that stores information to enable <code>summary</code>.</p>
</td>
</tr>
</table>
<p>In addition, the object will contain one of the following, depending on the value of <code>icl</code>.
</p>
<table>
<tr style="vertical-align: top;">
<td><code>bic</code></td>
<td>
<p>A number giving the BIC for each model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>icl</code></td>
<td>
<p>A number giving the ICL for each model.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>Dedicated <code>print</code>, <code>plot</code>, and <code>summary</code> functions are available for objects of class <code>pgmm</code>.
</p>


<h3>Author(s)</h3>

<p>Paul D. McNicholas [aut, cre], Aisha ElSherbiny [aut], K. Raju Jampani [ctb], Aaron McDaid [aut], Brendan Murphy [aut], Larry Banks [ctb]
</p>
<p>Maintainer: Paul D. McNicholas &lt;mcnicholas@math.mcmaster.ca&gt;
</p>


<h3>References</h3>

<p>D. N. Lawley and A. E. Maxwell (1962). Factor analysis as a statistical method. <em>Journal of the Royal Statistical Society: Series D</em> <b>12</b>(3), 209-229.
</p>
<p>Paul D. McNicholas and T. Brendan Murphy (2010). Model-based clustering of microarray expression data via latent Gaussian mixture models. <em>Bioinformatics</em> <b>26</b>(21), 2705-2712.
</p>
<p>Paul D. McNicholas (2010). Model-based classification using latent Gaussian mixture models. <em>Journal of Statistical Planning and Inference</em> <b>140</b>(5), 1175-1181.
</p>
<p>Paul D. McNicholas, T. Brendan Murphy, Aaron F. McDaid and Dermot Frost (2010). Serial and parallel implementations of model-based clustering via parsimonious Gaussian mixture models. <em>Computational Statistics and Data Analysis</em> <b>54</b>(3), 711-723.
</p>
<p>Paul D. McNicholas and T. Brendan Murphy (2008). Parsimonious Gaussian mixture models. <em>Statistics and Computing</em> <b>18</b>(3), 285-296.
</p>
<p>Paul D. McNicholas and T. Brendan Murphy (2005). Parsimonious Gaussian mixture models. Technical Report 05/11, Department of Statistics, Trinity College Dublin.
</p>


<h3>Examples</h3>

<pre><code class="language-R">  ## Not run: 
# Wine clustering example with three random starts and the CUU model.
 data("wine")
 x&lt;-wine[,-1]
 x&lt;-scale(x)
 wine_clust&lt;-pgmmEM(x,rG=1:4,rq=1:4,zstart=1,loop=3,modelSubset=c("CUU"))
 table(wine[,1],wine_clust$map)

# Wine clustering example with custom starts and the CUU model.
 data("wine")
 x&lt;-wine[,-1]
 x&lt;-scale(x)
 hcl&lt;-hclust(dist(x)) 
 z&lt;-list()
 for(g in 1:4){ 
	 z[[g]]&lt;-cutree(hcl,k=g)
 } 
 wine_clust2&lt;-pgmmEM(x,1:4,1:4,zstart=3,modelSubset=c("CUU"),zlist=z)
 table(wine[,1],wine_clust2$map)
 print(wine_clust2)
 summary(wine_clust2)

# Olive oil classification by region (there are three regions), with two-thirds of
# the observations taken as having known group memberships, using the CUC, CUU and 
# UCU models. 
 data("olive") 
 x&lt;-olive[,-c(1,2)] 
 x&lt;-scale(x) 
 cls&lt;-olive[,1]
 for(i in 1:dim(olive)[1]){
	 if(i%%3==0){cls[i]&lt;-0}
 }
 olive_class&lt;-pgmmEM(x,rG=3:3,rq=4:6,cls,modelSubset=c("CUC","CUU", 
  "CUCU"),relax=TRUE)
 cls_ind&lt;-(cls==0) 
 table(olive[cls_ind,1],olive_class$map[cls_ind])

# Another olive oil classification by region, but this time suppose we only know
# two-thirds of the labels for the first two areas but we suspect that there might 
# be a third or even a fourth area. 
 data("olive") 
 x&lt;-olive[,-c(1,2)] 
 x&lt;-scale(x) 
 cls2&lt;-olive[,1]
 for(i in 1:dim(olive)[1]){
   if(i%%3==0||i&gt;420){cls2[i]&lt;-0}
 }
 olive_class2&lt;-pgmmEM(x,2:4,4:6,cls2,modelSubset=c("CUU"),relax=TRUE)
 cls_ind2&lt;-(cls2==0) 
 table(olive[cls_ind2,1],olive_class2$map[cls_ind2])
 
# Coffee clustering example using k-means starting values for all 12
# models with the ICL being used for model selection instead of the BIC.
 data("coffee")
 x&lt;-coffee[,-c(1,2)]
 x&lt;-scale(x)
 coffee_clust&lt;-pgmmEM(x,rG=2:3,rq=1:3,zstart=2,icl=TRUE)
 table(coffee[,1],coffee_clust$map)
 plot(coffee_clust)
 plot(coffee_clust,onlyAll=TRUE)
  
## End(Not run)
  
# Coffee clustering example using k-means starting values for the UUU model, i.e., the
# mixture of factor analyzers model, for G=2 and q=1.
 data("coffee")
 x&lt;-coffee[,-c(1,2)]
 x&lt;-scale(x)
 coffee_clust_mfa&lt;-pgmmEM(x,2:2,1:1,zstart=2,modelSubset=c("UUU"))
 table(coffee[,1],coffee_clust_mfa$map)
 </code></pre>


</div>