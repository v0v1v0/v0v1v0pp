<div class="container">

<table style="width: 100%;"><tr>
<td>object_label</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Labels objects</h2>

<h3>Description</h3>

<p>All pixels for each connected set of foreground (non-zero) pixels in x are
set to an unique increasing integer, starting from 1. Hence, max(x) gives the
number of connected objects in x. This is a wrapper to EBImage::bwlabel or
EBImage::watershed (if <code>watershed = TRUE</code>).
</p>


<h3>Usage</h3>

<pre><code class="language-R">object_label(
  img,
  index = "B",
  invert = FALSE,
  fill_hull = FALSE,
  threshold = "Otsu",
  k = 0.1,
  windowsize = NULL,
  filter = FALSE,
  watershed = FALSE,
  tolerance = NULL,
  extension = NULL,
  object_size = "medium",
  plot = TRUE,
  ncol = NULL,
  nrow = NULL,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>img</code></td>
<td>
<p>An image object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>index</code></td>
<td>
<p>A character value (or a vector of characters) specifying the
target mode for conversion to binary image. See the available indexes with
<code>pliman_indexes()</code> and <code>image_index()</code> for more details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>invert</code></td>
<td>
<p>Inverts the binary image, if desired.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fill_hull</code></td>
<td>
<p>Fill holes in the objects? Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threshold</code></td>
<td>
<p>The theshold method to be used.
</p>

<ul>
<li>
<p> By default (<code>threshold = "Otsu"</code>), a threshold value based
on Otsu's method is used to reduce the grayscale image to a binary image. If
a numeric value is informed, this value will be used as a threshold.
</p>
</li>
<li>
<p> If <code>threshold = "adaptive"</code>, adaptive thresholding (Shafait et al. 2008)
is used, and will depend on the <code>k</code> and <code>windowsize</code> arguments.
</p>
</li>
<li>
<p> If any non-numeric value different than <code>"Otsu"</code> and <code>"adaptive"</code> is used,
an iterative section will allow you to choose the threshold based on a
raster plot showing pixel intensity of the index.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>a numeric in the range 0-1. when <code>k</code> is high, local threshold
values tend to be lower. when <code>k</code> is low, local threshold value tend to be
higher.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>windowsize</code></td>
<td>
<p>windowsize controls the number of local neighborhood in
adaptive thresholding. By default it is set to <code>1/3 * minxy</code>, where
<code>minxy</code> is the minimum dimension of the image (in pixels).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>filter</code></td>
<td>
<p>Performs median filtering in the binary image? (Defaults to
<code>FALSE</code>). Provide a positive integer &gt; 1 to indicate the size of the median
filtering. Higher values are more efficient to remove noise in the
background but can dramatically impact the perimeter of objects, mainly for
irregular perimeters such as leaves with serrated edges.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>watershed</code></td>
<td>
<p>If <code>TRUE</code> (default) performs watershed-based object
detection. This will detect objects even when they are touching one other.
If <code>FALSE</code>, all pixels for each connected set of foreground pixels are set
to a unique object. This is faster but is not able to segment touching
objects.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tolerance</code></td>
<td>
<p>The minimum height of the object in the units of image
intensity between its highest point (seed) and the point where it contacts
another object (checked for every contact pixel). If the height is smaller
than the tolerance, the object will be combined with one of its neighbors,
which is the highest.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>extension</code></td>
<td>
<p>Radius of the neighborhood in pixels for the detection of
neighboring objects. Higher value smooths out small objects.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object_size</code></td>
<td>
<p>The size of the object. Used to automatically set up
<code>tolerance</code> and <code>extension</code> parameters. One of the following. <code>"small"</code>
(e.g, wheat grains), <code>"medium"</code> (e.g, soybean grains), <code>"large"</code>(e.g, peanut
grains), and <code>"elarge"</code> (e.g, soybean pods)'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot</code></td>
<td>
<p>Show image after processing?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nrow, ncol</code></td>
<td>
<p>The number of rows or columns in the plot grid. Defaults to
<code>NULL</code>, i.e., a square grid is produced.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>If <code>TRUE</code> (default) a summary is shown in the console.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list with the same length of <code>img</code> containing the labeled objects.
</p>


<h3>Examples</h3>

<pre><code class="language-R">img &lt;- image_pliman("soybean_touch.jpg")
# segment the objects using the "B" (blue) band.
object_label(img, index = "B")
object_label(img, index = "B", watershed = TRUE)
</code></pre>


</div>