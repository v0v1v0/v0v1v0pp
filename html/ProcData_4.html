<div class="container">

<table style="width: 100%;"><tr>
<td>atseq2feature_seq2seq</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Feature Extraction by action and time sequence autoencoder</h2>

<h3>Description</h3>

<p><code>atseq2feature_seq2seq</code> extract features from action and timestamp sequences by a 
sequence autoencoder.
</p>


<h3>Usage</h3>

<pre><code class="language-R">atseq2feature_seq2seq(atseqs, K, weights = c(1, 0.5),
  cumulative = FALSE, log = TRUE, rnn_type = "lstm", n_epoch = 50,
  method = "last", step_size = 1e-04, optimizer_name = "rmsprop",
  samples_train, samples_valid, samples_test = NULL, pca = TRUE,
  verbose = TRUE, return_theta = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>atseqs</code></td>
<td>
<p>a list of two elements, first element is the list of <code>n</code> action sequences, Each element 
is an action sequence in the form of a vector of actions. The second element is the list of <code>n</code> 
timestamp sequences corresponding to the action sequences. Each element is a numeric sequence in the form 
of a vector of timestamps associated with actions, with the timestamp of the first event (e.g., "start") of 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>the number of features to be extracted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>a vector of 2 elements for the weight of the loss of action sequences
(categorical_crossentropy) and time sequences (mean squared error), respectively. 
The total loss is calculated as the weighted sum of the two losses.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cumulative</code></td>
<td>
<p>logical. If TRUE, the sequence of cumulative time up to each event is
used as input to the neural network. If FALSE, the sequence of inter-arrival time (gap 
time between an event and the previous event) will be used as input to the neural network.
Default is FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>log</code></td>
<td>
<p>logical. If TRUE, for the timestamp sequences, input of the neural net is
the base-10 log of the original sequence of times plus 1 (i.e., log10(t+1)). If FALSE,
the original sequence of times is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rnn_type</code></td>
<td>
<p>the type of recurrent unit to be used for modeling
response processes. <code>"lstm"</code> for the long-short term memory unit. 
<code>"gru"</code> for the gated recurrent unit.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_epoch</code></td>
<td>
<p>the number of training epochs for the autoencoder.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>the method for computing features from the output of an
recurrent neural network in the encoder. Available options are 
<code>"last"</code> and <code>"avg"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>step_size</code></td>
<td>
<p>the learning rate of optimizer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optimizer_name</code></td>
<td>
<p>a character string specifying the optimizer to be used
for training. Availabel options are <code>"sgd"</code>, <code>"rmsprop"</code>, 
<code>"adadelta"</code>, and <code>"adam"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>samples_train</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>samples_valid</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>samples_test</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pca</code></td>
<td>
<p>logical. If TRUE, the principal components of features are
returned. Default is TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>logical. If TRUE, training progress is printed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_theta</code></td>
<td>
<p>logical. If TRUE, extracted features are returned.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function trains a sequence-to-sequence autoencoder using keras. The encoder
of the autoencoder consists of a recurrent neural network.
The decoder consists of another recurrent neural network followed by a fully connected layer
with softmax activation for actions and another fully connected layer with ReLU activation 
for times. The outputs of the encoder are the extracted features.
</p>
<p>The output of the encoder is a function of the encoder recurrent neural network.
It is the last latent state of the encoder recurrent neural network if <code>method="last"</code>
and the average of the encoder recurrent neural network latent states if <code>method="avg"</code>.
</p>


<h3>Value</h3>

<p><code>tseq2feature_seq2seq</code> returns a list containing
</p>
<table>
<tr style="vertical-align: top;">
<td><code>theta</code></td>
<td>
<p>a matrix containing <code>K</code> features or principal features. Each column is a feature.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>train_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of training losses.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>valid_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of validation losses.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of test losses. Exists only if <code>samples_test</code> is not <code>NULL</code>.</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p><code>chooseK_seq2seq</code> for choosing <code>K</code> through cross-validation.
</p>
<p>Other feature extraction methods: <code>aseq2feature_seq2seq</code>,
<code>seq2feature_mds_large</code>,
<code>seq2feature_mds</code>,
<code>seq2feature_ngram</code>,
<code>seq2feature_seq2seq</code>,
<code>tseq2feature_seq2seq</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
if (!system("python -c 'import tensorflow as tf'", ignore.stdout = TRUE, ignore.stderr= TRUE)) {
  n &lt;- 50
  data(cc_data)
  samples &lt;- sample(1:length(cc_data$seqs$time_seqs), n)
  atseqs &lt;- sub_seqs(cc_data$seqs, samples)
  action_and_time_seq2seq_res &lt;- atseq2feature_seq2seq(atseqs, 5, rnn_type="lstm", n_epoch=5, 
                                   samples_train=1:40, samples_valid=41:50)
  features &lt;- action_and_time_seq2seq_res$theta
  plot(action_and_time_seq2seq_res$train_loss, col="blue", type="l",
       ylim = range(c(action_and_time_seq2seq_res$train_loss, 
                      action_and_time_seq2seq_res$valid_loss)))
  lines(action_and_time_seq2seq_res$valid_loss, col="red", type = 'l')
}

</code></pre>


</div>