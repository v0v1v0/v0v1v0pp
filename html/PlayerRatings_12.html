<div class="container">

<table style="width: 100%;"><tr>
<td>metrics</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Prediction Evaluation</h2>

<h3>Description</h3>

<p>Returns measures that assess prediction performance. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">metrics(act, pred, cap = c(0.01,0.99), which = 1:3, na.rm = TRUE, 
  sort = TRUE, digits = 3, scale = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>act</code></td>
<td>
<p>A numeric vector of actual values. Typically equal to
one for a player one win, zero for a player two win, and one
half for a draw.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>A numeric vector of predictions, typically values 
between zero and one. A matrix can also be given, in which
case the jth column contains the predictions for model j.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cap</code></td>
<td>
<p>A numeric vector of length two giving values at which
to cap the binomial deviance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>which</code></td>
<td>
<p>Select metrics using any subset of <code>1:3</code>. All
are produced by default.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>Remove missing values in predictions. The default is
to remove missing values because the default predict method will
predict missing values for games with new players.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sort</code></td>
<td>
<p>By default output is ordered from best to worst using
the first metric specified.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p>Round to this number of digits.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>If <code>TRUE</code> (the default), all metrics are scaled
so that a value of 100 corresponds to predicting 0.5 for every
game.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The preferred metric for assessing predictions in chess is
the capped binomial deviance. Mean squared error and mean 
absolute error metrics are also produced. By default all metrics 
are scaled so that the value 100 represents the zero information
case. If not scaled, then all metrics are multiplied by 100.
</p>


<h3>Value</h3>

<p>A numeric vector.
</p>


<h3>See Also</h3>

<p><code>predict.rating</code></p>


<h3>Examples</h3>

<pre><code class="language-R">afl &lt;- aflodds[,c(2,3,4,7)]
train &lt;- afl[afl$Week &lt;= 80,]
test &lt;- afl[afl$Week &gt; 80,]
robj &lt;- elo(train)
metrics(test$Score, predict(robj, test))
metrics(test$Score, predict(robj, test), scale = FALSE)
</code></pre>


</div>