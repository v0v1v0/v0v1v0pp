<div class="container">

<table style="width: 100%;"><tr>
<td>g_model</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>g_model class object</h2>

<h3>Description</h3>

<p>Use <code>g_glm()</code>, <code>g_empir()</code>,
<code>g_glmnet()</code>, <code>g_rf()</code>, <code>g_sl()</code>, <code>g_xgboost</code> to construct
an action probability model/g-model object.
The constructors are used as input for <code>policy_eval()</code> and <code>policy_learn()</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">g_empir(formula = ~1, ...)

g_glm(
  formula = ~.,
  family = "binomial",
  model = FALSE,
  na.action = na.pass,
  ...
)

g_glmnet(formula = ~., family = "binomial", alpha = 1, s = "lambda.min", ...)

g_rf(
  formula = ~.,
  num.trees = c(500),
  mtry = NULL,
  cv_args = list(nfolds = 5, rep = 1),
  ...
)

g_sl(
  formula = ~.,
  SL.library = c("SL.mean", "SL.glm"),
  family = binomial(),
  env = as.environment("package:SuperLearner"),
  onlySL = TRUE,
  ...
)

g_xgboost(
  formula = ~.,
  objective = "binary:logistic",
  params = list(),
  nrounds,
  max_depth = 6,
  eta = 0.3,
  nthread = 1,
  cv_args = list(nfolds = 3, rep = 1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>An object of class formula specifying the design matrix for
the propensity model/g-model. Use <code>get_history_names()</code> to view the available
variable names.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments passed to <code>glm()</code>, glmnet::glmnet,
ranger::ranger or SuperLearner::SuperLearner.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>A description of the error distribution and link function to
be used in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>(Only used by <code>g_glm</code>) If <code>FALSE</code> model frame will
not be saved.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.action</code></td>
<td>
<p>(Only used by <code>g_glm</code>) A function which indicates what
should happen when the data contain NAs, see na.pass.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>(Only used by <code>g_glmnet</code>) The elastic net mixing parameter
between 0 and 1. alpha equal to 1 is the lasso penalty, and alpha equal
to 0 the ridge penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s</code></td>
<td>
<p>(Only used by <code>g_glmnet</code>) Value(s) of the penalty parameter
lambda at which predictions are required, see <code>glmnet::predict.glmnet()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num.trees</code></td>
<td>
<p>(Only used by <code>g_rf</code>) Number of trees.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mtry</code></td>
<td>
<p>(Only used by <code>g_rf</code>) Number of variables to possibly split
at in each node.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv_args</code></td>
<td>
<p>(Only used by <code>g_rf</code> and <code>g_xgboost</code>) Cross-validation parameters.
Only used if multiple hyper-parameters are given. <code>K</code> is the number
of folds and
<code>rep</code> is the number of replications.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>SL.library</code></td>
<td>
<p>(Only used by <code>g_sl</code>) Either a character vector of prediction algorithms or
a list containing character vectors, see SuperLearner::SuperLearner.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>env</code></td>
<td>
<p>(Only used by <code>g_sl</code>) Environment containing the learner functions. Defaults to the calling environment.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>onlySL</code></td>
<td>
<p>(Only used by <code>g_sl</code>) Logical. If TRUE, only saves and computes predictions
for algorithms with non-zero coefficients in the super learner object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>objective</code></td>
<td>
<p>(Only used by <code>g_xgboost</code>) specify the learning
task and the corresponding learning objective, see xgboost::xgboost.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>params</code></td>
<td>
<p>(Only used by <code>g_xgboost</code>) list of parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nrounds</code></td>
<td>
<p>(Only used by <code>g_xgboost</code>) max number of boosting iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_depth</code></td>
<td>
<p>(Only used by <code>g_xgboost</code>) maximum depth of a tree.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eta</code></td>
<td>
<p>(Only used by <code>g_xgboost</code>) learning rate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nthread</code></td>
<td>
<p>(Only used by <code>g_xgboost</code>) number of threads.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>g_glm()</code> is a wrapper of <code>glm()</code> (generalized linear model).<br><code>g_empir()</code> calculates the empirical probabilities within the groups
defined by the formula.<br><code>g_glmnet()</code> is a wrapper of <code>glmnet::glmnet()</code> (generalized linear model via
penalized maximum likelihood).<br><code>g_rf()</code> is a wrapper of <code>ranger::ranger()</code> (random forest).
When multiple hyper-parameters are given, the
model with the lowest cross-validation error is selected.<br><code>g_sl()</code> is a wrapper of SuperLearner::SuperLearner (ensemble model).<br><code>g_xgboost()</code> is a wrapper of xgboost::xgboost.
</p>


<h3>Value</h3>

<p>g-model object: function with arguments 'A'
(action vector), 'H' (history matrix) and 'action_set'.
</p>


<h3>See Also</h3>

<p><code>get_history_names()</code>, <code>get_g_functions()</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">library("polle")
### Two stages:
d &lt;- sim_two_stage(2e2, seed=1)
pd &lt;- policy_data(d,
                  action = c("A_1", "A_2"),
                  baseline = c("B"),
                  covariates = list(L = c("L_1", "L_2"),
                                    C = c("C_1", "C_2")),
                  utility = c("U_1", "U_2", "U_3"))
pd

# available state history variable names:
get_history_names(pd)
# defining a g-model:
g_model &lt;- g_glm(formula = ~B+C)

# evaluating the static policy (A=1) using inverse propensity weighting
# based on a state glm model across all stages:
pe &lt;- policy_eval(type = "ipw",
                  policy_data = pd,
                  policy = policy_def(1, reuse = TRUE),
                 g_models = g_model)
# inspecting the fitted g-model:
get_g_functions(pe)

# available full history variable names at each stage:
get_history_names(pd, stage = 1)
get_history_names(pd, stage = 2)

# evaluating the same policy based on a full history
# glm model for each stage:
pe &lt;- policy_eval(type = "ipw",
                   policy_data = pd,
                   policy = policy_def(1, reuse = TRUE),
                   g_models = list(g_glm(~ L_1 + B),
                                   g_glm(~ A_1 + L_2 + B)),
                   g_full_history = TRUE)
# inspecting the fitted g-models:
get_g_functions(pe)
</code></pre>


</div>