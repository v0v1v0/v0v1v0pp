<div class="container">

<table style="width: 100%;"><tr>
<td>mgsim.cv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Determination of the ridge regularization parameter and the bandwidth to be used for
classification with GSIM for categorical data</h2>

<h3>Description</h3>

<p>The function <code>mgsim.cv</code> determines the best ridge regularization parameter and bandwidth to 
be used for classification with MGSIM as described in Lambert-Lacroix and Peyre (2005).
</p>


<h3>Usage</h3>

<pre><code class="language-R">mgsim.cv(Ytrain,Xtrain,LambdaRange,hRange,NbIterMax=50)

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Xtrain</code></td>
<td>
<p>a (ntrain x p) data matrix of predictors. <code>Xtrain</code> must be a matrix. 
Each row corresponds to an observation and each column to a predictor variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ytrain</code></td>
<td>
<p>a ntrain vector of responses. <code>Ytrain</code> must be a vector. 
<code>Ytrain</code> is a {1,...,c+1}-valued vector and contains the response variable for each
observation. c+1 is the number of classes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>LambdaRange</code></td>
<td>
<p>the vector of positive real value from which the best ridge regularization 
parameter has to be chosen by cross-validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hRange</code></td>
<td>
<p>the vector of strictly positive real value from which the best bandwidth
has to be chosen by cross-validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>NbIterMax</code></td>
<td>
<p>a positive integer. <code>NbIterMax</code> is the maximal number of iterations in the 
Newton-Rapson parts.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The cross-validation procedure described in Lambert-Lacroix and Peyre (2005)
is used to determine the best ridge regularization parameter and bandwidth to be
used for classification with GSIM for categorical data (for binary data see 
<code>gsim</code> and <code>gsim.cv</code>).
At each cross-validation run, <code>Xtrain</code> is split into a pseudo training
set (ntrain-1 samples) and a pseudo test set (1 sample) and the 
classification error rate is determined for each
value of ridge regularization parameter and bandwidth. Finally, the function 
<code>mgsim.cv</code> returns the values of the ridge regularization parameter and 
bandwidth for which the mean classification error rate is minimal. 
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Lambda</code></td>
<td>
<p>the optimal regularization parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>h</code></td>
<td>
<p>the optimal bandwidth parameter.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Sophie Lambert-Lacroix 
(<a href="http://membres-timc.imag.fr/Sophie.Lambert/">http://membres-timc.imag.fr/Sophie.Lambert/</a>) 
and 
Julie Peyre (<a href="https://membres-ljk.imag.fr/Julie.Peyre/">https://membres-ljk.imag.fr/Julie.Peyre/</a>).
</p>


<h3>References</h3>

<p>S. Lambert-Lacroix,  J. Peyre . (2006) Local likelyhood regression in  generalized linear 
single-index models with applications to microarrays data. Computational Statistics and 
Data Analysis, vol 51, n 3, 2091-2113. 
</p>


<h3>See Also</h3>

<p><code>mgsim</code>, <code>gsim</code>, <code>gsim.cv</code>.</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
## between 5~15 seconds
# load plsgenomics library
library(plsgenomics)

# load SRBCT data
data(SRBCT)
IndexLearn &lt;- c(sample(which(SRBCT$Y==1),10),sample(which(SRBCT$Y==2),4),
                sample(which(SRBCT$Y==3),7),sample(which(SRBCT$Y==4),9))

### Determine optimum h and lambda
# /!\ take 30 secondes to run
#hl &lt;- mgsim.cv(Ytrain=SRBCT$Y[IndexLearn],Xtrain=SRBCT$X[IndexLearn,],
#                            LambdaRange=c(0.1),hRange=c(7,20))

### perform prediction by MGSIM
#res &lt;- mgsim(Ytrain=SRBCT$Y[IndexLearn],Xtrain=SRBCT$X[IndexLearn,],Lambda=hl$Lambda,
#             h=hl$h,Xtest=SRBCT$X[-IndexLearn,])
#res$Cvg
#sum(res$Ytest!=SRBCT$Y[-IndexLearn])


## End(Not run)
</code></pre>


</div>