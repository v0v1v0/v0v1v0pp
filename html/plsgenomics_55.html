<div class="container">

<table style="width: 100%;"><tr>
<td>spls.cv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Cross-validation procedure to calibrate the parameters (ncomp, lambda.l1) 
of the Adaptive Sparse PLS regression</h2>

<h3>Description</h3>

<p>The function <code>spls.cv</code> chooses the optimal values for the 
hyper-parameter of the <code>spls</code> procedure, by minimizing the mean 
squared error of prediction over the hyper-parameter grid, 
using Durif et al. (2018) adaptive SPLS algorithm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">spls.cv(
  X,
  Y,
  lambda.l1.range,
  ncomp.range,
  weight.mat = NULL,
  adapt = TRUE,
  center.X = TRUE,
  center.Y = TRUE,
  scale.X = TRUE,
  scale.Y = TRUE,
  weighted.center = FALSE,
  return.grid = FALSE,
  ncores = 1,
  nfolds = 10,
  nrun = 1,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>a (n x p) data matrix of predictors. <code>X</code> must be a matrix. 
Each row corresponds to an observation and each column to a 
predictor variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>a (n) vector of (continuous) responses. <code>Y</code> must be a 
vector or a one column matrix. It contains the response variable for 
each observation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.l1.range</code></td>
<td>
<p>a vecor of positive real values, in [0,1]. 
<code>lambda.l1</code> is the sparse penalty parameter for the dimension 
reduction step by sparse PLS (see details), the optimal value will be 
chosen among <code>lambda.l1.range</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncomp.range</code></td>
<td>
<p>a vector of positive integers. <code>ncomp</code> is the 
number of PLS components. The optimal value will be chosen 
among <code>ncomp.range</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weight.mat</code></td>
<td>
<p>a (ntrain x ntrain) matrix used to weight the l2 metric 
in the observation space, it can be the covariance inverse of the Ytrain 
observations in a heteroskedastic context. If NULL, the l2 metric is the 
standard one, corresponding to homoskedastic model (<code>weight.mat</code> is the 
identity matrix).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adapt</code></td>
<td>
<p>a boolean value, indicating whether the sparse PLS selection 
step sould be adaptive or not (see details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center.X</code></td>
<td>
<p>a boolean value indicating whether the data matrices 
<code>Xtrain</code> and <code>Xtest</code> (if provided) should be centered or not.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center.Y</code></td>
<td>
<p>a boolean value indicating whether the response values 
<code>Ytrain</code> set should be centered or not.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale.X</code></td>
<td>
<p>a boolean value indicating whether the data matrices 
<code>Xtrain</code> and <code>Xtest</code> (if provided) should be scaled or not 
(<code>scale.X=TRUE</code> implies <code>center.X=TRUE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale.Y</code></td>
<td>
<p>a boolean value indicating whether the response values 
<code>Ytrain</code> should be scaled or not (<code>scale.Y=TRUE</code> implies 
<code>center.Y=TRUE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weighted.center</code></td>
<td>
<p>a boolean value indicating whether the centering 
should take into account the weighted l2 metric or not 
(if TRUE, it requires that weighted.mat is non NULL).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return.grid</code></td>
<td>
<p>a boolean values indicating whether the grid of 
hyper-parameters values with corresponding mean prediction error rate over 
the folds should be returned or not.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncores</code></td>
<td>
<p>a positve integer, indicating the number of cores that the 
cross-validation is allowed to use for parallel computation (see details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>
<p>a positive integer indicating the number of folds in the 
K-folds cross-validation procedure, <code>nfolds=n</code> corresponds 
to the leave-one-out cross-validation, default is 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nrun</code></td>
<td>
<p>a positive integer indicating how many times the K-folds cross-
validation procedure should be repeated, default is 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>a boolean value indicating verbosity.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The columns of the data matrices <code>Xtrain</code> and <code>Xtest</code> may not 
be standardized, since standardizing can be performed by the function 
<code>spls.cv</code> as a preliminary step.
</p>
<p>The procedure is described in Durif et al. (2018). The K-fold 
cross-validation can be summarize as follow: the train set is partitioned 
into K folds, for each value of hyper-parameters the model is fit K times, 
using each fold to compute the prediction error rate, and fitting the 
model on the remaining observations. The cross-validation procedure returns 
the optimal hyper-parameters values, meaning the one that minimize 
the mean squared error of prediction averaged over all the folds.
</p>
<p>This procedures uses the <code>mclapply</code> from the <code>parallel</code> package, 
available on GNU/Linux and MacOS. Users of Microsoft Windows can refer to 
the README file in the source to be able to use a mclapply type function.
</p>


<h3>Value</h3>

<p>An object with the following attributes
</p>
<table>
<tr style="vertical-align: top;">
<td><code>lambda.l1.opt</code></td>
<td>
<p>the optimal value in <code>lambda.l1.range</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncomp.opt</code></td>
<td>
<p>the optimal value in <code>ncomp.range</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv.grid</code></td>
<td>
<p>the grid of hyper-parameters and corresponding prediction 
error rate over the folds. 
<code>cv.grid</code> is NULL if <code>return.grid</code> is set to FALSE.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Ghislain Durif (<a href="https://gdurif.perso.math.cnrs.fr/">https://gdurif.perso.math.cnrs.fr/</a>).
</p>


<h3>References</h3>

<p>Durif, G., Modolo, L., Michaelsson, J., Mold, J.E., Lambert-Lacroix, S., 
Picard, F., 2018. High dimensional classification with combined 
adaptive sparse PLS and logistic regression. Bioinformatics 34, 
485â€“493. <a href="https://doi.org/10.1093/bioinformatics/btx571">doi:10.1093/bioinformatics/btx571</a>.
Available at <a href="http://arxiv.org/abs/1502.05933">http://arxiv.org/abs/1502.05933</a>.
</p>


<h3>See Also</h3>

<p><code>spls</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
### load plsgenomics library
library(plsgenomics)

### generating data
n &lt;- 100
p &lt;- 100
sample1 &lt;- sample.cont(n=n, p=p, kstar=10, lstar=2, 
                       beta.min=0.25, beta.max=0.75, mean.H=0.2, 
                       sigma.H=10, sigma.F=5, sigma.E=5)
                       
X &lt;- sample1$X
Y &lt;- sample1$Y

### hyper-parameters values to test
lambda.l1.range &lt;- seq(0.05,0.95,by=0.1) # between 0 and 1
ncomp.range &lt;- 1:10

### tuning the hyper-parameters
cv1 &lt;- spls.cv(X=X, Y=Y, lambda.l1.range=lambda.l1.range, 
               ncomp.range=ncomp.range, weight.mat=NULL, adapt=TRUE, 
               center.X=TRUE, center.Y=TRUE, 
               scale.X=TRUE, scale.Y=TRUE, weighted.center=FALSE, 
               return.grid=TRUE, ncores=1, nfolds=10, nrun=1)
str(cv1)

### otpimal values
cv1$lambda.l1.opt
cv1$ncomp.opt

## End(Not run)

</code></pre>


</div>