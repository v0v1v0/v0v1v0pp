<div class="container">

<table style="width: 100%;"><tr>
<td>slm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Simple Learning Models (SLMs)</h2>

<h3>Description</h3>

<p>Fits a simple learning model (SLM) for probabilistic knowledge
structures by minimum discrepancy maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class="language-R">slm(K, N.R, method = c("MD", "ML", "MDML"), R = as.binmat(N.R),
    beta = rep(0.1, nitems), eta = rep(0.1, nitems),
    g = rep(0.1, nitems),
    betafix = rep(NA, nitems), etafix = rep(NA, nitems),
    betaequal = NULL, etaequal = NULL,
    randinit = FALSE, incradius = 0,
    tol = 1e-07, maxiter = 10000, zeropad = 16,
    checkK = TRUE)

getSlmPK(g, K, Ko)

## S3 method for class 'slm'
print(x, P.Kshow = FALSE, parshow = TRUE,
      digits=max(3, getOption("digits") - 2), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>a state-by-problem indicator matrix representing the knowledge
space.  An element is one if the problem is contained in the state,
and else zero.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>N.R</code></td>
<td>
<p>a (named) vector of absolute frequencies of response patterns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p><code>MD</code> for minimum discrepancy estimation, <code>ML</code> for
maximum likelihood estimation, <code>MDML</code> for minimum discrepancy
maximum likelihood estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>R</code></td>
<td>
<p>a person-by-problem indicator matrix of unique response patterns.
Per default inferred from the names of <code>N.R</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta, eta, g</code></td>
<td>
<p>vectors of initial values for the error, guessing, and
solvability parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>betafix, etafix</code></td>
<td>
<p>vectors of fixed error and guessing parameter values;
<code>NA</code> indicates a free parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>betaequal, etaequal</code></td>
<td>
<p>lists of vectors of problem indices; each vector
represents an equivalence class: it contains the indices of problems for
which the error or guessing parameters are constrained to be equal.  (See
Examples.)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>randinit</code></td>
<td>
<p>logical, if <code>TRUE</code> then initial parameter values are
sampled uniformly with constraints.  (See Details.)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>incradius</code></td>
<td>
<p>include knowledge states of distance from the minimum
discrepant states less than or equal to <code>incradius</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>tolerance, stopping criterion for iteration.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiter</code></td>
<td>
<p>the maximum number of iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>zeropad</code></td>
<td>
<p>the maximum number of items for which an incomplete
<code>N.R</code> vector is completed and padded with zeros.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>checkK</code></td>
<td>
<p>logical, if <code>TRUE</code> K is checked for well-gradedness.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ko</code></td>
<td>
<p>a state-by-problem indicator matrix representing the outer fringe
for each knowledge state in <code>K</code>; typically the result of a call to
<code>getKFringe</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>an object of class <code>slm</code>, typically the result of a call to
<code>slm</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>P.Kshow</code></td>
<td>
<p>logical, should the estimated distribution of knowledge
states be printed?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parshow</code></td>
<td>
<p>logical, should the estimates of error, guessing, and
solvability parameters be printed?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p>a non-null value for <code>digits</code> specifies the minimum
number of significant digits to be printed in values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments passed to other methods.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>See Doignon and Falmagne (1999) for details on the simple learning model
(SLM) for probabilistic knowledge structures. The model requires a
well-graded knowledge space <code>K</code>.
</p>
<p>An <code>slm</code> object inherits from class <code>blim</code>.  See <code>blim</code> for
details on the function arguments.  The helper function <code>getSlmPK</code>
returns the distribution of knowledge states <code>P.K</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>slm</code> and <code>blim</code>.  It contains all components
of a <code>blim</code> object.  In addition, it includes:
</p>
<table><tr style="vertical-align: top;">
<td><code>g</code></td>
<td>
<p>the vector of estimates of the solvability parameters.</p>
</td>
</tr></table>
<h3>References</h3>

<p>Doignon, J.-P., &amp; Falmagne, J.-C. (1999).
<em>Knowledge spaces</em>. Berlin: Springer.
</p>


<h3>See Also</h3>

<p><code>blim</code>, <code>simulate.blim</code>, <code>getKFringe</code>,
<code>is.downgradable</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(DoignonFalmagne7)
K   &lt;- DoignonFalmagne7$K     # well-graded knowledge space
N.R &lt;- DoignonFalmagne7$N.R   # frequencies of response patterns

## Fit simple learning model (SLM) by different methods
slm(K, N.R, method = "MD")    # minimum discrepancy estimation
slm(K, N.R, method = "ML")    # maximum likelihood estimation by EM
slm(K, N.R, method = "MDML")  # MDML estimation

## Compare SLM and BLIM
m1 &lt;-  slm(K, N.R, method = "ML")
m2 &lt;- blim(K, N.R, method = "ML")
anova(m1, m2)
</code></pre>


</div>