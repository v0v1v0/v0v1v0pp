<div class="container">

<table style="width: 100%;"><tr>
<td>Windy_gridworld</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Windy Gridworld MDP</h2>

<h3>Description</h3>

<p>The Windy gridworld MDP example from Chapter 6 of the textbook
"Reinforcement Learning: An Introduction."
</p>


<h3>Format</h3>

<p>An object of class MDP.
</p>


<h3>Details</h3>

<p>The gridworld has the following layout:
</p>
<p><img src="../help/figures/windy-gridworld.png" alt="Windy Gridworld."></p>
<p>The grid world is represented as a 7 x 10 matrix of states.
In the middle region the next states are shifted upward by wind
(the strength in number of squares is given below each column).
For example, if the agent is one cell to the right of the goal,
then the action left takes the agent to the cell just above the goal.
</p>
<p>No discounting is used (i.e., <code class="reqn">\gamma = 1</code>).
</p>


<h3>References</h3>

<p>Richard S. Sutton and Andrew G. Barto (2018). Reinforcement Learning: An Introduction
Second Edition, MIT Press, Cambridge, MA.
</p>


<h3>See Also</h3>

<p>Other MDP_examples: 
<code>Cliff_walking</code>,
<code>MDP()</code>,
<code>Maze</code>
</p>
<p>Other gridworld: 
<code>Cliff_walking</code>,
<code>Maze</code>,
<code>gridworld</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(Windy_gridworld)
Windy_gridworld

gridworld_matrix(Windy_gridworld)
gridworld_matrix(Windy_gridworld, what = "labels")

# The Goal is an absorbing state 
which(absorbing_states(Windy_gridworld))

# visualize the transition graph
gridworld_plot_transition_graph(Windy_gridworld, 
  vertex.size = 10, vertex.label = NA)

# solve using value iteration
sol &lt;- solve_MDP(Windy_gridworld) 
sol
policy(sol)
gridworld_plot_policy(sol)
</code></pre>


</div>