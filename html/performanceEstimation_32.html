<div class="container">

<table style="width: 100%;"><tr>
<td>loocvEstimates</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Performance estimation using  Leave One Out Cross Validation 
</h2>

<h3>Description</h3>

<p>This function obtains leave one out cross validation estimates of
performance  metrics for a given predictive task and method to solve
it (i.e. a  workflow). The function is general in the sense that the
workflow function that the user provides as the solution to the task,
can implement or call whatever modeling technique the user wants.
</p>
<p>The function implements leave one out cross validation
estimation. Different settings concering this methodology are 
available through the argument <code>estTask</code> (check the help page of
<code>LOOCV</code>).
</p>
<p>Please note that most of the times you will not call this function
directly, though there is nothing wrong in doing it, but instead you
will use the function <code>performanceEstimation</code>, that allows you to
carry out performance estimation of multiple workflows on multiple tasks,
using some estimation method like for instance cross validation. Still, when you
simply want to have the leave one out cross validation estimate of one
workflow on one task, you may use this function directly.
</p>


<h3>Usage</h3>

<pre><code class="language-R">loocvEstimates(wf,task,estTask,verbose=FALSE,cluster)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>wf</code></td>
<td>

<p>an object of the class <code>Workflow</code> representing the
modeling approach to be evaluated on a certain task.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>task</code></td>
<td>

<p>an object of the class <code>PredTask</code> representing the
prediction task to be used in the evaluation.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>estTask</code></td>
<td>

<p>an object of the class <code>EstimationTask</code> indicating the metrics to
be estimated and the leave one out cross validation settings to use.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>

<p>A boolean value controlling the level of output of the function
execution, defaulting to <code>FALSE</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cluster</code></td>
<td>

<p>an optional parameter that can either be <code>TRUE</code> or a
<code>cluster</code>. In case of <code>TRUE</code> the function will run in
parallel and will internally setup the parallel back-end (defaulting
to using half of the cores in your local machine). You may also setup
outside your parallel back-end (c.f. <code>makeCluster</code>) and
then pass the resulting <code>cluster</code> object to this function using
this parameter. In case no value is provided for this parameter the
function will run sequentially.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The idea of this function is to carry out a leave one out cross
validation  experiment with the goal of obtaining reliable estimates
of the predictive performance of a certain approach to a predictive
task. This approach (denoted here as a <em>workflow</em>) will be evaluated on
the given predictive task using some user-selected  metrics,
and this function will provide leave one out cross validation
estimates of the true value of these
evaluation metrics.  Leave one out cross validation estimates are
obtained as the average of <em>N</em> iterations, where <em>N</em> is the
size of the given data sample. On each of these iterations one of the
cases in the data sample is left out as <em>test set</em> and the
worflow is applied to the remaining <em>N-1</em> cases. The process is
repeated for all cases, i.e. <em>N</em> times. This estimation is
similar to k-fold cross validation where k equals to <em>N</em>. The
resulting estimates are obtained by averaging over the <em>N</em>
iteration scores. 
</p>
<p>Parallel execution of the estimation experiment is only recommended
for minimally large data sets otherwise you may actually increase the
computation time due to communication costs between the processes.
</p>


<h3>Value</h3>

<p>The result of the function is an object of class <code>EstimationResults</code>.
</p>


<h3>Author(s)</h3>

<p> Luis Torgo <a href="mailto:ltorgo@dcc.fc.up.pt">ltorgo@dcc.fc.up.pt</a> </p>


<h3>References</h3>

<p> Torgo, L. (2014) <em>An Infra-Structure for Performance
Estimation and Experimental Comparison of Predictive Models in R</em>. arXiv:1412.0436 [cs.MS]
<a href="http://arxiv.org/abs/1412.0436">http://arxiv.org/abs/1412.0436</a>  
</p>


<h3>See Also</h3>

<p><code>LOOCV</code>,
<code>Workflow</code>,
<code>standardWF</code>,
<code>PredTask</code>,
<code>EstimationTask</code>,
<code>performanceEstimation</code>,
<code>hldEstimates</code>,
<code>bootEstimates</code>,  
<code>cvEstimates</code>,
<code>mcEstimates</code>,
<code>EstimationResults</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 

## Estimating the error rate of an SVM on the iris data set using
## leave one out cross validation
library(e1071)
data(iris)

## Now the evaluation
eval.res &lt;- loocvEstimates(
             Workflow(wfID="svmTrial",
                      learner="svm",learner.pars=list(cost=10,gamma=0.1)
                     ),
             PredTask(Species ~ ., iris),
             EstimationTask("err",method=LOOCV()))

## Check a summary of the results
summary(eval.res)


## End(Not run)
</code></pre>


</div>