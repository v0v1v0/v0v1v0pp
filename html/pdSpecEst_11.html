<div class="container">

<table style="width: 100%;"><tr>
<td>pdkMeans</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>K-means clustering for HPD matrices</h2>

<h3>Description</h3>

<p><code>pdkMeans</code> performs (fuzzy) k-means clustering for collections of HPD matrices, such as covariance or
spectral density matrices, based on a number of different metrics in the space of HPD matrices.
</p>


<h3>Usage</h3>

<pre><code class="language-R">pdkMeans(X, K, metric = "Riemannian", m = 1, eps = 1e-05,
  max_iter = 100, centroids)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>a (<code class="reqn">d,d,S</code>)-dimensional array of (<code class="reqn">d,d</code>)-dimensional HPD matrices for <code class="reqn">S</code>
different subjects. Also accepts a (<code class="reqn">d,d,n,S</code>)-dimensional array, which is understood to be an array of
<code class="reqn">n</code>-dimensional sequences of (<code class="reqn">d,d</code>)-dimensional HPD matrices for <code class="reqn">S</code> different subjects.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>the number of clusters, a positive integer larger than 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>
<p>the metric that the space of HPD matrices is equipped with. The default choice is <code>"Riemannian"</code>,
but this can also be one of: <code>"logEuclidean"</code>, <code>"Cholesky"</code>, <code>"rootEuclidean"</code> or
<code>"Euclidean"</code>. Additional details are given below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m</code></td>
<td>
<p>a fuzziness parameter larger or equal to <code class="reqn">1</code>. If <code class="reqn">m = 1</code> the cluster assignments are no longer fuzzy,
i.e., the procedure performs hard clustering. Defaults to <code>m = 1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>an optional tolerance parameter determining the stopping criterion. The k-means algorithm
terminates if the intrinsic distance between cluster centers is smaller than <code>eps</code>, defaults to <code>eps = 1e-05</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter</code></td>
<td>
<p>an optional parameter tuning the maximum number of iterations in the
k-means algorithm, defaults to <code>max_iter = 100</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>centroids</code></td>
<td>
<p>an optional (<code class="reqn">d,d,K</code>)- or (<code class="reqn">d,d,n,K</code>)-dimensional array depending on the input array <code>X</code>
specifying the initial cluster centroids. If not specified, <code>K</code> initial cluster centroids are randomly sampled without
replacement from the input array <code>X</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The input array <code>X</code> corresponds to a collection of <code class="reqn">(d,d)</code>-dimensional HPD matrices
for <code class="reqn">S</code> different subjects. If the fuzziness parameter satisfies <code>m &gt; 1</code>, the <code class="reqn">S</code> subjects are assigned to
<code class="reqn">K</code> different clusters in a probabilistic fashion according to a fuzzy k-means algorithm as detailed in classical texts,
such as (Bezdek 1981). If <code>m = 1</code>, the <code class="reqn">S</code> subjects are assigned to the <code class="reqn">K</code> clusters in a non-probabilistic
fashion according to a standard (hard) k-means algorithm. If not specified by the user, the <code class="reqn">K</code> cluster
centers are initialized by random sampling without replacement from the input array of HPD matrices <code>X</code>.
The distance measure in the (fuzzy) k-means algorithm is induced by the metric on the space of HPD matrices specified by the user.
By default, the space of HPD matrices is equipped with (i) the affine-invariant Riemannian metric (<code>metric = 'Riemannian'</code>)
as detailed in e.g., (Bhatia 2009)[Chapter 6] or (Pennec et al. 2006). Instead, this can also be one of:
(ii) the log-Euclidean metric (<code>metric = 'logEuclidean'</code>), the Euclidean inner product between matrix logarithms;
(iii) the Cholesky metric (<code>metric = 'Cholesky'</code>), the Euclidean inner product between Cholesky decompositions; (iv) the
Euclidean metric (<code>metric = 'Euclidean'</code>); or (v) the root-Euclidean metric (<code>metric = 'rootEuclidean'</code>). The default
choice of metric (affine-invariant Riemannian) satisfies several useful properties not shared by the other metrics, see e.g.,
<cite>C18</cite>pdSpecEst for more details. Note that this comes at the cost of increased computation time in comparison to one
of the other metrics.
</p>


<h3>Value</h3>

<p>Returns a list with two components:
</p>

<dl>
<dt>cl.assignments </dt>
<dd>
<p> an (<code class="reqn">S,K</code>)-dimensional matrix, where the value at position (<code class="reqn">s,k</code>) in the
matrix corresponds to the (probabilistic or binary) cluster membership assignment of subject <code class="reqn">s</code> with respect
to cluster <code class="reqn">k</code>.</p>
</dd>
<dt>cl.centroids </dt>
<dd>
<p> either a (<code class="reqn">d,d,K</code>)- or (<code class="reqn">d,d,n,K</code>)-dimensional array depending on the input array <code>X</code>
corresponding respectively to the <code>K</code> <code class="reqn">(d,d)</code>- or (<code class="reqn">d,d,n</code>)-dimensional final cluster centroids.
</p>
</dd>
</dl>
<h3>References</h3>

<p>Bezdek J (1981).
<em>Pattern Recognition with Fuzzy Objective Function Algorithms</em>.
Plenum Press, New York.<br><br> Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br><br> Pennec X, Fillard P, Ayache N (2006).
“A Riemannian framework for tensor computing.”
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41–66.
</p>


<h3>See Also</h3>

<p><code>pdDist</code>, <code>pdSpecClust1D</code>, <code>pdSpecClust2D</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Generate 20 random HPD matrices in 2 groups
m &lt;- function(rescale){
 x &lt;- matrix(complex(real = rescale * rnorm(9), imaginary = rescale * rnorm(9)), nrow = 3)
 t(Conj(x)) %*% x
}
X &lt;- array(c(replicate(10, m(0.25)), replicate(10, m(1))), dim = c(3, 3, 20))

## Compute fuzzy k-means cluster assignments
cl &lt;- pdkMeans(X, K = 2, m = 2)$cl.assignments

</code></pre>


</div>