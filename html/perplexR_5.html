<div class="container">

<table style="width: 100%;"><tr>
<td>buildUnitTests</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Large Language Model: Create Unit Tests</h2>

<h3>Description</h3>

<p>Create <code>{testthat}</code> test cases for the code.
</p>


<h3>Usage</h3>

<pre><code class="language-R">buildUnitTests(
  code = clipr::read_clip(allow_non_interactive = TRUE),
  PERPLEXITY_API_KEY = Sys.getenv("PERPLEXITY_API_KEY"),
  modelSelection = c("mistral-7b-instruct", "mixtral-8x7b-instruct",
    "codellama-70b-instruct", "sonar-small-chat", "sonar-small-online",
    "sonar-medium-chat", "sonar-medium-online"),
  systemRole = "You are a helpful assistant with extensive programming skills.",
  maxTokens = 265,
  temperature = 1,
  top_p = NULL,
  top_k = 100,
  presence_penalty = 0,
  frequency_penalty = NULL,
  proxy = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>code</code></td>
<td>
<p>The code for which to create unit tests by Large Language Model. If not provided, it will use
what's copied on the clipboard.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>PERPLEXITY_API_KEY</code></td>
<td>
<p>PERPLEXITY API key.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>modelSelection</code></td>
<td>
<p>model choice. Default is mistral-7b-instruct.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>systemRole</code></td>
<td>
<p>Role for model. Default is: "You are a helpful assistant
with extensive knowledge of R programming."</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxTokens</code></td>
<td>
<p>The maximum integer of completion tokens returned by API.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>temperature</code></td>
<td>
<p>The amount of randomness in the response,
valued between 0 inclusive and 2 exclusive. Higher values are more random,
and lower values are more deterministic. Set either temperature or top_p.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>top_p</code></td>
<td>
<p>Nucleus sampling threshold, valued between 0 and 1 inclusive.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>top_k</code></td>
<td>
<p>The number of tokens to keep for highest top-k filtering,
specified as an integer between 0 and 2048 inclusive.
If set to 0, top-k filtering is disabled.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>presence_penalty</code></td>
<td>
<p>A value between -2.0 and 2.0.
Positive values penalize new tokens based on whether they appear in the text
so far, increasing the model's likelihood to talk about new topics.
Incompatible with frequency_penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>frequency_penalty</code></td>
<td>
<p>A multiplicative penalty greater than 0.
Values greater than 1.0 penalize new tokens based on their existing
frequency in the text so far, decreasing the model's likelihood to repeat
the same line verbatim. A value of 1.0 means no penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>proxy</code></td>
<td>
<p>Default value is NULL.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A character value with the response generated by Large Language Model.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
buildUnitTests("squared_numbers &lt;- function(numbers) {\n  numbers ^ 2\n}")

## End(Not run)

</code></pre>


</div>