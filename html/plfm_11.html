<div class="container">

<table style="width: 100%;"><tr>
<td>plfm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Probabilistic latent feature analysis of two-way two-mode frequency data</h2>

<h3>Description</h3>

<p>Computation of parameter estimates, standard errors, criteria for model selection, and goodness-of-fit criteria for 
disjunctive, conjunctive or additive probabilistic latent feature models with <em>F</em> features.</p>


<h3>Usage</h3>

<pre><code class="language-R">plfm(data,object,attribute,rating,freq1,freqtot,F,
     datatype="freq",maprule="disj",M=5,emcrit1=1e-2,
     emcrit2=1e-10,printrun=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p> A data frame that consists of three components: the variables 
<code>object</code>, <code>attribute</code> and <code>rating</code>. Each row of the data frame describes the outcome of a binary rater judgement
about the association between a certain object and a certain attribute.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>The name of the <code>object</code> component in the data frame <code>data</code>. The values of the vector <code>data$object</code> should be (non-missing) numeric or character values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>attribute</code></td>
<td>
<p>The name of the <code>attribute</code> component in the data frame <code>data</code>. The values of the vector <code>data$attribute</code> should be (non-missing) numeric or character values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rating</code></td>
<td>
<p>The name of the <code>rating</code> component in the data frame <code>data</code>. The elements of the vector <code>data$rating</code> should be the numeric values 0 (no association) or 1 (association), 
or should be specified as missing (NA).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>freq1</code></td>
<td>
<p>A <em>J X K</em> matrix of observed association frequencies.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>freqtot</code></td>
<td>
<p>A <em>J X K</em> matrix with the total number of binary ratings in each cell <em>(j,k)</em>. If the total number of ratings is the same for all cells of the matrix 
it is sufficient to enter a single numeric value rather than a matrix. For instance, if <em>N</em> raters have judged <em>J X K</em> associations, one may specify <code>freqtot</code><em>=N</em></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>F</code></td>
<td>
<p>The number of latent features included in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>datatype</code></td>
<td>
<p>The type of data used as input. When <code>datatype</code>="freq" one should specify frequency data <code>freq1</code> and <code>freqtot</code>, and when <code>datatype</code>="dataframe" one should 
specify the name of the data frame <code>data</code>, and its components, <code>object</code>, <code>attribute</code> and <code>rating</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maprule</code></td>
<td>
<p>Disjunctive (<code>maprule</code>="disj"),  conjunctive (<code>maprule</code>="conj") or additive (<code>maprule</code>="add") mapping rule of the probabilistic latent feature model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>M</code></td>
<td>
<p>The number of times a particular model is estimated using random starting points.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>emcrit1</code></td>
<td>
<p>Convergence criterion which indicates when the estimation algorithm should switch from Expectation-Maximization (EM) steps to EM+Newton-Rhapson steps.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>emcrit2</code></td>
<td>
<p>Convergence criterion which indicates final convergence to a local maximum.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>printrun</code></td>
<td>
<p><code>printrun</code>=TRUE prints the analysis type (disjunctive, conjunctive or additive), the number of features (<em>F</em>) and the number of the run to the output screen, whereas 
<code>printrun</code>=FALSE suppresses the printing.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><em>Estimation</em>
</p>
<p>The function <code>plfm</code> uses an accelerated EM-algorithm to locate the posterior mode(s) of the probabilistic latent feature model. 
The algorithm starts with a series of Expectation-Maximization (EM) steps until the difference between subsequent values of the 
logarithm of the posterior density becomes smaller than the convergence criterion <code>emcrit1</code>, and then switches to an accelerated algorithm which 
consists of EM + Newton-Rhapson steps. The accelerated algorithm stops when  the difference between subsequent values of the 
logarithm of the posterior density becomes smaller than the convergence criterion <code>emcrit2</code>.  
Computational details about the implementation of the EM-steps for PLFMs are described in Maris, De Boeck, and Van Mechelen (1996). 
The general scheme of the accelerated algorithm is described in Louis (1982) and Tanner (1996). Computational details about implementing the accelerated algorithm 
for PLFMs are described in Meulders (2013).
</p>
<p>When using the function <code>plfm</code> to estimate a particular PLFM (i.e. with a certain number of latent features and specific mapping rule), 
one may locate the distinct posterior mode(s) by running the algorithm <code>M</code> times using random starting points. The estimated object-and attribute parameters of 
each run are stored in the objects <code>objpar.runs</code> and <code>attpar.runs</code> of the output list. Next, a number of additional statistics 
(estimated object- and attribute parameters, asymptotic standard errors of object- and attribute parameters, model selecion criteria and goodness-of-fit measures) 
are computed for the best model (i.e. the model among <code>M</code> runs with the highest posterior density).
</p>
<p><em>Model selection criteria and goodness-of-fit measures</em>
</p>
<p>To choose among models with different numbers of features, or with different mapping rules, 
one may use information criteria such as the Akaike Information Criterion (AIC, Akaike, 1973, 1974),
or the Schwarz Bayesian Information Criterion (BIC, Schwarz, 1978). AIC and BIC are computed as <em>-2*loglikelihood+k*Npar</em>.
For AIC <em>k</em> equals 2 and for BIC <em>k</em> equals <em>log(N)</em>, with <em>N</em> the observed number of replications 
for which object-attribute associations are collected. <em>Npar</em> represents the number of model parameters; 
for probabilistic latent feature models this equals <em>(J+K)F</em>. Models with the lowest value for AIC or BIC should be selected.
</p>
<p>To assess the statistical fit of the probabilistic feature model one may use a Pearson chi-square measure 
on the <em>J X K</em> frequency table to evaluate whether predicted 
frequencies deviate significantly from observed frequencies (see Meulders et al., 2001). In addition, one may assess the descriptive fit of the model 
using the correlation between observed and expected frequencies in the <em>J X K</em> table, 
and the proportion of the variance in the observed frequencies accounted for by the model (VAF)
(i.e. the squared correlation between observed and expected frequencies).
</p>
<p>The model selection criteria AIC and BIC, the results of the Pearson goodness-of fit test, 
and the descriptive fit measures (correlation observed and expected frequencies, and VAF) are stored in the object <code>fitmeasures</code> of the output list
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>Parameters used to call the function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>objpar</code></td>
<td>
<p>A <em>J X F</em> matrix of object parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>attpar</code></td>
<td>
<p>A <em>K X F</em> matrix of attribute parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitmeasures</code></td>
<td>
<p>A list of model selection criteria and goodness-of-fit criteria for the model with the highest posterior density.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logpost.runs</code></td>
<td>
<p>A list with the logarithm of the posterior density for each of the <em>M</em> computed models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>objpar.runs</code></td>
<td>
<p>A <em>M X J X F</em> array which contains the object parameters for each of the <em>M</em> computed models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>attpar.runs</code></td>
<td>
<p>A <em>M X K X F</em> array which contains the attribute parameters for each of the <em>M</em> computed models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bestsolution</code></td>
<td>
<p>An index which indicates the model with the highest posterior density among each of the <em>M</em> computed models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gradient.objpar</code></td>
<td>
<p>A <em>J X F</em> gradient matrix for the object parameters in the best solution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gradient.attpar</code></td>
<td>
<p>A <em>K X F</em> gradient matrix for the attribute parameters in the best solution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>SE.objpar</code></td>
<td>
<p>A <em>J X F</em> matrix of asymptotic standard errors for the object parameters in the best solution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>SE.attpar</code></td>
<td>
<p>A <em>K X F</em> matrix of asymptotic standard errors for the attribute parameters in the best solution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prob1</code></td>
<td>
<p>A <em>J X K</em> matrix of expected association probabilities for the best solution.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Michel Meulders
</p>


<h3>References</h3>

<p>Akaike, H. (1973). Information theory and an extension of the maximum likelihood
principle. In B. N. Petrov and F. Csaki (Eds.), <em>Second international symposium on
information theory</em> (p. 271-283). Budapest: Academiai Kiado.
</p>
<p>Akaike, H. (1974). A new look at the statistical model identification. <em>IEEE Transactions
on Automatic Control, 19</em>, 716-723.
</p>
<p>Candel, M. J. J. M., and Maris, E. (1997). Perceptual analysis of two-way two-mode
frequency data: probability matrix decomposition and two alternatives.
<em>International Journal of Research in Marketing, 14</em>, 321-339.
</p>
<p>Louis, T. A. (1982). Finding observed information using the em algorithm. <em>Journal of the
Royal Statistical Society, Series B, 44</em>, 98-130.
</p>
<p>Maris, E., De Boeck, P., and Van Mechelen, I. (1996). Probability matrix decomposition models. <em>Psychometrika, 61</em>, 7-29.
</p>
<p>Meulders, M., De Boeck, P., and Van Mechelen, I. (2001). Probability matrix decomposition
models and main-effects generalized linear models for the analysis of replicated
binary associations. <em>Computational Statistics and Data Analysis, 38</em>, 217-233.
</p>
<p>Meulders, M., De Boeck, P., Van Mechelen, I., Gelman, A., and Maris, E. (2001). Bayesian inference with probability matrix decomposition models. 
<em>Journal of Educational and Behavioral Statistics, 26</em>, 153-179.
</p>
<p>Meulders, M., De Boeck, P., Van Mechelen, I., and Gelman, A. (2005). Probabilistic feature analysis of facial perception of emotions. 
<em>Applied Statistics, 54</em>, 781-793.
</p>
<p>Meulders, M. and De Bruecker, P. (2018). Latent class probabilistic latent feature analysis of three-way three-mode binary data. 
<em>Journal of Statistical Software, 87(1)</em>, 1-45.
</p>
<p>Meulders, M. (2013). An R Package for Probabilistic Latent Feature Analysis of Two-Way Two-Mode Frequencies. <em>Journal of Statistical Software, 54(14)</em>, 1-29. 
URL http://www.jstatsoft.org/v54/i14/.
</p>
<p>Tanner, M. A. (1996). <em>Tools for statistical inference: Methods for the exploration of
posterior distributions and likelihood functions</em> (Third ed.). New York:
Springer-Verlag.
</p>
<p>Schwarz, G. (1978). Estimating the dimensions of a model. <em>Annals of Statistics, 6</em>, 461-464.
</p>


<h3>See Also</h3>

<p><code>gendat</code>, <code>print.plfm</code>, 
<code>summary.plfm</code>, <code>print.summary.plfm</code></p>


<h3>Examples</h3>

<pre><code class="language-R">
## Not run: 
## example 1: Analysis of data generated under the model

# define constants
J&lt;-20
K&lt;-15
F&lt;-2

# generate true parameters
set.seed(43565)
objectparameters&lt;-matrix(runif(J*F),nrow=J)
attributeparameters&lt;-matrix(runif(K*F),nrow=K)

# generate data for disjunctive model using N=200 replications
gdat.disj&lt;-gendat(maprule="disj",N=200,
              objpar=objectparameters,attpar=attributeparameters)

# Estimate a disjunctive probabilistic latent feature model with 2 features
# suppress printing the type of analysis to the output screen
disj2&lt;-plfm(maprule="disj",freq1=gdat.disj$freq1,freqtot=200,F=2,M=1,printrun=FALSE)

# generate data for an additive model using N=200 replications
gdat.add&lt;-gendat(maprule="add",N=200,
              objpar=objectparameters,attpar=attributeparameters)

# Estimate an additive probabilistic latent feature model with 2 features
# suppress printing the type of analysis to the output screen
add2&lt;-plfm(maprule="add",freq1=gdat.add$freq1,freqtot=200,F=2,M=1,printrun=FALSE)

## End(Not run)


## Not run: 
# example 2:Perceptual analysis of associations between car models and car attributes

# load car data
data(car)

# compute 1 run of a disjunctive model with 4 features
# use components of a data frame as input
cardisj4&lt;-plfm(datatype="dataframe",data=car$datalongformat,object=objectlabel,
               attribute=attributelabel,rating=rating,maprule="disj",F=4,M=1)

# print the output of a disjunctive 4-feature model  
# for data on the perception of car models
print (cardisj4)


# print a summary of the output of a disjunctive 4-feature model  
# for data on the perception of car models
sumcardisj4&lt;-summary(cardisj4)
sumcardisj4

## End(Not run)

## Not run: 
# example 3: analysis on determinants of anger-related behavior

# load anger data
data(anger)

# compute 1 run of a disjunctive model with 2 features
# use frequency data as input
angerdisj2&lt;-plfm(maprule="disj",freq1=anger$freq1,freqtot=anger$freqtot,F=2,M=1)


# print the output of a disjunctive 2-feature model 
# for data on the situational determinants of anger-related behaviors
print (angerdisj2)


# print a summary of the output of a disjunctive 2-feature model 
# for data on the situational determinants of anger-related behaviors
sumangerdisj2&lt;-summary(angerdisj2)
sumangerdisj2

## End(Not run)


</code></pre>


</div>