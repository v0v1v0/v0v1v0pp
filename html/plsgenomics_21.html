<div class="container">

<table style="width: 100%;"><tr>
<td>mrpls</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Ridge Partial Least Square for categorical data</h2>

<h3>Description</h3>

<p>The function <code>mrpls</code> performs prediction using Fort et al. (2005) MRPLS algorithm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mrpls(Ytrain,Xtrain,Lambda,ncomp,Xtest=NULL,NbIterMax=50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Xtrain</code></td>
<td>
<p>a (ntrain x p) data matrix of predictors. <code>Xtrain</code> must be a matrix. 
Each row corresponds to an observation and each column to a predictor variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ytrain</code></td>
<td>
<p>a ntrain vector of responses. <code>Ytrain</code> must be a vector. 
<code>Ytrain</code> is a {0,...,c}-valued vector and contains the response variable for each
observation. c+1 is the number of classes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xtest</code></td>
<td>
<p>a (ntest x p) matrix containing the predictors for the test data
set. <code>Xtest</code> may also be a vector of length p (corresponding to only one 
test observation).If <code>Xtest</code> is not equal to NULL, then the prediction 
step is made for these new predictor variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Lambda</code></td>
<td>
<p>a positive real value. <code>Lambda</code> is the ridge regularization parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncomp</code></td>
<td>
<p>a positive integer. <code>ncomp</code> is the number of PLS components. 
If <code>ncomp</code>=0,then the Ridge regression is performed without reduction 
dimension. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>NbIterMax</code></td>
<td>
<p>a positive integer. <code>NbIterMax</code> is the maximal number of iterations in the 
Newton-Rapson parts.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The columns of the data matrices <code>Xtrain</code> and <code>Xtest</code> may not be standardized, 
since standardizing is performed by the function <code>mrpls</code> as a preliminary step
before the algorithm is run. 
</p>
<p>The procedure described in Fort et al. (2005) is used to determine
latent components to be used for classification and when <code>Xtest</code> 
is not equal to NULL, the procedure predicts the labels for these new 
predictor variables.  
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Coefficients</code></td>
<td>
<p>the (p+1) x c matrix containing the coefficients weighting the block 
design matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hatY</code></td>
<td>
<p>the ntrain vector containing the estimated {0,...,c}-valued labels for the 
observations from <code>Xtrain</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hatYtest</code></td>
<td>
<p>the ntest vector containing the predicted {0,...,c}-valued labels for the 
observations from <code>Xtest</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>proba</code></td>
<td>
<p>the ntrain vector containing the estimated probabilities for the 
observations from <code>Xtrain</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>proba.test</code></td>
<td>
<p>the ntest vector containing the predicted probabilities for the 
observations from <code>Xtest</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DeletedCol</code></td>
<td>
<p>the vector containing the column number of <code>Xtrain</code> when the 
variance of the corresponding predictor variable is null. Otherwise <code>DeletedCol</code>=NULL</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hatYtest_k</code></td>
<td>
<p>If <code>ncomp</code> is greater than 1, <code>hatYtest_k</code> is a matrix 
of size ntest x ncomp in such a way that the kth column corresponds to the 
predicted label obtained with k PLS components.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Sophie Lambert-Lacroix 
(<a href="http://membres-timc.imag.fr/Sophie.Lambert/">http://membres-timc.imag.fr/Sophie.Lambert/</a>). 
</p>


<h3>References</h3>

<p>G. Fort, S. Lambert-Lacroix and Julie Peyre (2005). Reduction de dimension dans les modeles 
lineaires generalises : application a la classification supervisee de donnees issues des biopuces.
Journal de la SFDS, tome 146, n1-2, 117-152. 
</p>


<h3>See Also</h3>

<p><code>mrpls.cv</code>, <code>rpls</code>, <code>rpls.cv</code>.</p>


<h3>Examples</h3>

<pre><code class="language-R"># load plsgenomics library
library(plsgenomics)

# load SRBCT data
data(SRBCT)
IndexLearn &lt;- c(sample(which(SRBCT$Y==1),10),sample(which(SRBCT$Y==2),4),
			sample(which(SRBCT$Y==3),7),sample(which(SRBCT$Y==4),9))

# perform prediction by MRPLS
res &lt;- mrpls(Ytrain=SRBCT$Y[IndexLearn]-1,Xtrain=SRBCT$X[IndexLearn,],Lambda=0.001,ncomp=2,
			Xtest=SRBCT$X[-IndexLearn,])
sum(res$Ytest!=SRBCT$Y[-IndexLearn]-1)

# prediction for another sample
Xnew &lt;- SRBCT$X[83,]
# Compute the linear predictor for each classes expect class 1
eta &lt;- diag(t(cbind(c(1,Xnew),c(1,Xnew),c(1,Xnew))) %*% res$Coefficients)
Ypred &lt;- which.max(c(0,eta))
Ypred+1
SRBCT$Y[83]

</code></pre>


</div>