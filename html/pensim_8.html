<div class="container">

<table style="width: 100%;"><tr>
<td>opt2D</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Parallelized, two-dimensional tuning of Elastic Net L1/L2 penalties
</h2>

<h3>Description</h3>

<p>This function implements parallelized two-dimensional optimization of Elastic Net
penalty parameters.  This is accomplished by scanning a regular grid
of L1/L2 penalties, then using the top five CVL penalty combinations
from this grid as starting points for the convex optimization problem.
</p>


<h3>Usage</h3>

<pre><code class="language-R">opt2D(nsim,
      L1range = c(0.001, 100),
      L2range = c(0.001, 100),
      dofirst = "both",
      nprocessors = 1,
      L1gridsize = 10, L2gridsize = 10,
      cl = NULL,
      ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>nsim</code></td>
<td>

<p>Number of times to repeat the simulation (around 50 is suggested)
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>L1range</code></td>
<td>

<p>numeric vector of length two, giving minimum and maximum constraints
on the L1 penalty
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>L2range</code></td>
<td>

<p>numeric vector of length two, giving minimum and maximum constraints
on the L2 penalty
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dofirst</code></td>
<td>

<p>"L1" to optimize L1 followed by L2, "L2" to optimize L2 followed by
L1, or "both" to optimize both simultaneously in a two-dimensional optimization.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nprocessors</code></td>
<td>

<p>An integer number of processors to use.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>L1gridsize</code></td>
<td>

<p>Number of values of the L1 penalty in the regular grid of L1/L2 penalties
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>L2gridsize</code></td>
<td>

<p>Number of values of the L2 penalty in the regular grid of L1/L2 penalties
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cl</code></td>
<td>

<p>Optional cluster object created with the makeCluster() function of
the parallel package.  If this is not set, pensim calls
makeCluster(nprocessors, type="SOCK").   Setting this parameter
can enable parallelization in more diverse scenarios than multi-core
desktops; see the documentation for the parallel package.  Note that if
cl is user-defined, this function will not automatically run
parallel::stopCluster() to shut down the cluster.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>arguments passed on to optL1 and optL2 (dofirst="L1" or "L2"), or
cvl (dofirst="both") functions of the penalized R package
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function sets up a SNOW (Simple Network of Workstations) "sock"
cluster to parallelize the task of repeated tunings the Elastic Net
penalty parameters.  Three methods are implemented, as described by
Waldron et al. (2011): lambda1 followed by lambda2 (lambda1-lambda2),
lambda2 followed by lambda1 (lambda2-lambda1), and lambda1 with
lambda2 simultaneously (lambda1+lambda2).  Tuning of the penalty
parameters is done by the optL1 or optL2 functions of the penalized R
package.
</p>


<h3>Value</h3>

<p>Returns a matrix with the following columns:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>L1</code></td>
<td>
<p>optimized value of the L1 penalty parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>L2</code></td>
<td>
<p>optimized value of the L2 penalty parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cvl</code></td>
<td>
<p>optimized cross-validated likelihood</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>convergence</code></td>
<td>
<p>0 if the optimization converged, non-zero otherwise
(see stats:optim for details)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fncalls</code></td>
<td>
<p>number of calls to cvl function during optimization</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coef_1, coef_2, ..., coef_n</code></td>
<td>
<p>argmax coefficients for the model
with this value of the tuning parameter</p>
</td>
</tr>
</table>
<p>The matrix contains one row for each repeat of the regression.
</p>


<h3>Note</h3>

<p>Depends on the R packages: penalized, parallel, rlecuyer
</p>


<h3>Author(s)</h3>

<p>Levi Waldron et al.
</p>


<h3>References</h3>

<p>Waldron L, Pintilie M, Tsao M-S, Shepherd FA, Huttenhower C*, Jurisica
I*: Optimized application of penalized regression methods to diverse
genomic data. Bioinformatics 2011, 27:3399-3406.  (*equal contribution)
</p>


<h3>See Also</h3>

<p>optL1, optL2, cvl
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(beer.exprs)
data(beer.survival)

## Select just 100 genes to speed computation:
set.seed(1)
beer.exprs.sample &lt;- beer.exprs[sample(1:nrow(beer.exprs), 100),]

## Apply an unreasonably strict gene filter here to speed computation
## time for the Elastic Net example.
gene.quant &lt;- apply(beer.exprs.sample, 1, quantile, probs = 0.75)
dat.filt &lt;- beer.exprs.sample[gene.quant &gt; log2(150),]
gene.iqr &lt;- apply(dat.filt, 1, IQR)
dat.filt &lt;- as.matrix(dat.filt[gene.iqr &gt; 1,])
dat.filt &lt;- t(dat.filt)

## Define training and test sets
set.seed(9)
trainingset &lt;- sample(rownames(dat.filt), round(nrow(dat.filt) / 2))
testset &lt;-
  rownames(dat.filt)[!rownames(dat.filt) %in% trainingset]

dat.training &lt;- data.frame(dat.filt[trainingset,])
pheno.training &lt;- beer.survival[trainingset,]

library(survival)
surv.training &lt;- Surv(pheno.training$os, pheno.training$status)

dat.test &lt;- data.frame(dat.filt[testset,])
all.equal(colnames(dat.training), colnames(dat.test))
pheno.test &lt;- beer.survival[testset,]
surv.test &lt;- Surv(pheno.test$os, pheno.test$status)

set.seed(1)
##ideally set nsim=50, fold=10, but this takes 100x longer.
system.time(
  output &lt;- opt2D(
    nsim = 1,
    L1range = c(0.1, 1),
    L2range = c(20, 1000),
    dofirst = "both",
    nprocessors = 1,
    response = surv.training,
    penalized = dat.training,
    fold = 5,
    positive = FALSE,
    standardize = TRUE
  )
)

cc &lt;- output[which.max(output[, "cvl"]),-1:-5]
output[which.max(output[, "cvl"]), 1:5]  #small L1, large L2
sum(abs(cc) &gt; 0)  #number of non-zero coefficients

preds.training &lt;- as.matrix(dat.training) %*% cc
preds.training.median &lt;- median(preds.training)
preds.training.dichot &lt;-
  ifelse(preds.training &gt; preds.training.median, "high risk", "low risk")
preds.training.dichot &lt;-
  factor(preds.training.dichot[, 1], levels = c("low risk", "high risk"))
preds.test &lt;- as.matrix(dat.test) %*% cc
preds.test.dichot &lt;-
  ifelse(preds.test &gt; preds.training.median, "high risk", "low risk")
preds.test.dichot &lt;-
  factor(preds.test.dichot[, 1], levels = c("low risk", "high risk"))

coxphfit.training &lt;- coxph(surv.training ~ preds.training.dichot)
survfit.training &lt;- survfit(surv.training ~ preds.training.dichot)
summary(coxphfit.training)
coxphfit.test &lt;- coxph(surv.test ~ preds.test.dichot)
survfit.test &lt;- survfit(surv.test ~ preds.test.dichot)
summary(coxphfit.test)

(p.training &lt;-
    signif(summary(coxphfit.training)$logtest[3], 2))  #likelihood ratio test
(hr.training &lt;- signif(summary(coxphfit.training)$conf.int[1], 2))
(hr.lower.training &lt;- summary(coxphfit.training)$conf.int[3])
(hr.upper.training &lt;- summary(coxphfit.training)$conf.int[4])
par(mfrow = c(1, 2))
plot(
  survfit.training,
  col = c("black", "red"),
  conf.int = FALSE,
  xlab = "Months",
  main = "TRAINING",
  ylab = "Overall survival"
)
xmax &lt;- par("usr")[2] - 50
text(
  x = xmax,
  y = 0.4,
  lab = paste("HR=", hr.training),
  pos = 2
)
text(
  x = xmax,
  y = 0.3,
  lab = paste("p=", p.training, "", sep = ""),
  pos = 2
)
tmp &lt;- summary(preds.training.dichot)
text(
  x = xmax,
  y = c(0.2, 0.1),
  lab = paste(tmp, names(tmp)),
  col = 1:2,
  pos = 2
)
## Now the test set.
## in the test set,  HR=1.7 is not significant - not surprising with the
## overly strict non-specific pre-filter (IQR&gt;1,  75th percentile &gt; log2(150)
(p.test &lt;-
    signif(summary(coxphfit.test)$logtest[3], 2))  #likelihood ratio test
(hr.test &lt;- signif(summary(coxphfit.test)$conf.int[1], 2))
(hr.lower.test &lt;- summary(coxphfit.test)$conf.int[3])
(hr.upper.test &lt;- summary(coxphfit.test)$conf.int[4])
plot(
  survfit.test,
  col = c("black",  "red"),
  conf.int = FALSE,
  xlab = "Months",
  main = "TEST"
)
text(
  x = xmax,
  y = 0.4,
  lab = paste("HR=", hr.test),
  pos = 2
)
text(
  x = xmax,
  y = 0.3,
  lab = paste("p=", p.test, "", sep = ""),
  pos = 2
)
tmp &lt;- summary(preds.test.dichot)
text(
  x = xmax,
  y = c(0.2, 0.1),
  lab = paste(tmp, names(tmp)),
  col = 1:2,
  pos = 2
)
</code></pre>


</div>