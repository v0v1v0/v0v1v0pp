<div class="container">

<table style="width: 100%;"><tr>
<td>rndLambdaF</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Principal Component Statistics Based on Randomization
</h2>

<h3>Description</h3>

<p>Implements randomization-based procedures to estimate the number of
principal components.
</p>


<h3>Usage</h3>

<pre><code class="language-R">rndLambdaF(data, B = 1000, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A numeric data matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>
<p>An integer; the number of times to scramble the data columns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>A real number between 0 and 1; the significance level.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The randomization procedures implemented here were first developed by
ter Brack [1,2].  In a simulation study, Peres-Neto and colleagues
concluded that these methods were among the best [3]. Our own
simulations on larger data matrices find that rnd-Lambda performs
well (comparably to Auer-Gervini, though slower), but that rnd-F works
poorly.
</p>
<p>The test procedure is: (1) randomize the values with all the attribute
columns of the data matrix; (2) perform PCA on the scrambled data
matrix; and (3) compute the test statistics. All three steps are
repeated a total of (B - 1) times, where B is large enough to
guarantee accuracy when estimating p-values; in practice, B is usually
set to 1000. In each randomization, two test statistics are computed:
(1) the eigenvalue <code class="reqn">\lambda_k</code> for the k-th principal component; and
(2) a pseudo F-ratio computed as <code class="reqn">\lambda_k / \sum_{i=k+1}^n \lambda_i</code>.
Finally, the p-value for each k and each statistic of
interest is estimated to be the proportion of the test statistics in
all data sets that are greater than or equal to the one in the
observed data matrix.
</p>


<h3>Value</h3>

<p>A named vector of length two, containing the predicted number of
principal components based on the rnd-Lambda and rnd-F statistics. </p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;, Min Wang &lt;wang.1807@osu.edu&gt;.
</p>


<h3>References</h3>

<p>[1] ter Braak CFJ. CANOCO – a Fortran program for canonical community
ordination by [partial] [detrended] [canonical] correspondence
analysis, principal component analysis and redundancy analysis
(version 2.1). Agricultural Mathematics Group, Report LWA-88- 02,
Wageningen, 1988.
</p>
<p>[2] ter Braak CFJ. Update notes: CANOCO (version 3.1). Agricultural
Mathematics Group, Wageningen, 1990.
</p>
<p>[3] Peres-Neto PR, Jackson DA and Somers KM. How many principal components? Stopping
rules for determining the number of non-trivial axes revisited. Computational Statistics and
Data Analysis 2005; 49: 974–997.
</p>


<h3>See Also</h3>

<p>AuerGervini-class
</p>


<h3>Examples</h3>

<pre><code class="language-R">dataset &lt;- matrix(rnorm(200*15, 6), ncol=15)
rndLambdaF(dataset)
</code></pre>


</div>