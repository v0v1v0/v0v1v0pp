<div class="container">

<table style="width: 100%;"><tr>
<td>ca,cabase,calm,caglm,caprcomp,cakm,cameans,caquantile,caagg,caknn</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Software Alchemy: Turning Complex Statistical Computations into
Embarrassingly-Parallel Ones</h2>

<h3>Description</h3>

<p>Easy parallelization of most statistical computations.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ca(cls,z,ovf,estf,estcovf=NULL,findmean=TRUE,scramble=FALSE)
cabase(cls,ovf,estf,estcovf=NULL,findmean=TRUE,cacall=FALSE,z=NULL,scramble=FALSE)
calm(cls,lmargs) 
caglm(cls,glmargs) 
caprcomp(cls,prcompargs, p)
cakm(cls,mtdf,ncenters,p)
cameans(cls,cols,na.rm=FALSE) 
caquantile(cls,vec, probs = c(0.25, 0.5, 0.75),na.rm=FALSE) 
caagg(cls,ynames,xnames,dataname,FUN)
caknn(cls, yname, k, xname='')
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>cls</code></td>
<td>
<p>A cluster run under the <span class="pkg">parallel</span> package.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>z</code></td>
<td>
<p>A data frame, matrix or vector, one observation per row/element.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ovf</code></td>
<td>
<p>Overall statistical function, say <code>glm</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>estf</code></td>
<td>
<p>Function to extract the point estimate (typically
vector-valued) from the output of <code>ovf</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>estcovf</code></td>
<td>
<p>If provided, function to extract the estimated 
covariance matrix of the output of <code>estf</code></p>
</td>
</tr>
</table>
<p>.
</p>
<table>
<tr style="vertical-align: top;">
<td><code>findmean</code></td>
<td>
<p>If TRUE, output the average of the estimates from the
chunks; otherwise, output only the estimates themselves.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lmargs</code></td>
<td>
<p>Quoted string representing arguments to <code>lm</code>,
e.g. R formula, <code>data</code> specification.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>glmargs</code></td>
<td>
<p>Quoted string representing arguments to <code>glm</code>,
e.g. R formula, <code>data</code> specification, and <code>family</code>
argument.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prcompargs</code></td>
<td>
<p>Quoted string representing arguments to 
<code>prcomp</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>Number of columns in data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>If TRUE, remove NA values from the analysis.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mtdf</code></td>
<td>
<p>Quoted name of a distributed matrix or data frame.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncenters</code></td>
<td>
<p>Number of clusters to find.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cacall</code></td>
<td>
<p>If TRUE, indicates that <code>cabase</code> had been called by
<code>ca</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scramble</code></td>
<td>
<p>If this and <code>cacall</code> are TRUE, randomize the data
before distributing.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cols</code></td>
<td>
<p>A quoted string that evaluates to a data frame or matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vec</code></td>
<td>
<p>A quoted string that evaluates to a vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>yname</code></td>
<td>
<p>A quoted variable name, for the Y vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>Number of nearest neighbors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xname</code></td>
<td>
<p>A quoted variable name, for the X matrix/data frame.  If
empty, it is assumed that <code>preprocessx</code> has already been run on
the nodes; if nonempty, that function is run on this X data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ynames</code></td>
<td>
<p>A vector of quoted variable names.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xnames</code></td>
<td>
<p>A vector of quoted variable names.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataname</code></td>
<td>
<p>Quoted name of a data frame or matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>probs</code></td>
<td>
<p>As in the argument with the same name in
<code>quantile</code>. Should not be 0.00 or 1.00, as asymptotic
normality doesn't hold.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>FUN</code></td>
<td>
<p>Quoted name of a function.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Implements the “Software Alchemy” (SA) method for
parallelizing statistical computations (N. Matloff, <em>Parallel
Computation for Data Science</em>, Chapman and Hall, 2015, with further
details in N. Matloff, Software Alchemy: Turning Complex Statistical
Computations into Embarrassingly-Parallel Ones, <em>Journal of
Statistical Software</em>, 2016.)  This can result in substantial speedups
in computation, as well as address limits on physical memory.
</p>
<p>The method involves breaking the data into chunks, and then applying the
given estimator to each one.  The results are averaged, and an estimated
covariance matrix computed (optional).  
</p>
<p>Except for <code>ca</code>, it is assumed that the chunking has already been
done, say via <code>distribsplit</code> or <code>readnscramble</code>. 
</p>
<p>Note that in <code>cabase</code>, the data object is not specified explicitly
in the argument list.  This is done through the function <code>ovf</code>.
</p>
<p>Key point:  <em>The SA estimator is statistically equivalent to the
original, nonparallel one, in the sense that they have the SAME
asymptotic statistical accuracy.  Neither the non-SA nor the SA
estimator is "better" than the other</em>, and usually they will be quite
close to each other anyway.  Since we would use SA only with large data
sets anyway (otherwise, parallel computation would not be needed for
speed), the asymptotic aspect should not be an issue.  In other words,
with SA we achieve the same statistical accuracy while possibly
attaining much faster computation.
</p>
<p>It is vital to keep in mind that <em>The memory space issue can be
just as important as run time</em>.  Even if the problem is run on many
cores, if the total memory space needed exceeds that of the machine,
the run may fail.
</p>
<p>Wrapper functions, applying SA to the corresponding R
function (or function elsewere in this package):
</p>

<ul>
<li> <p><code>calm</code>: Wrapper for <code>lm</code>.
</p>
</li>
<li> <p><code>caglm</code>: Wrapper for <code>glm</code>.
</p>
</li>
<li> <p><code>caprcomp</code>: Wrapper for <code>prcomp</code>.
</p>
</li>
<li> <p><code>cakm</code>: Wrapper for <code>kmeans</code>.
</p>
</li>
<li> <p><code>cameans</code>: Wrapper for <code>colMeans</code>.
</p>
</li>
<li> <p><code>caquantile</code>: Wrapper for <code>quantile</code>.
</p>
</li>
<li> <p><code>caagg</code>: Like <code>distribagg</code>, but finds the
average value of <code>FUN</code> across the cluster nodes.
</p>
</li>
</ul>
<p>A note on NA values:  Some R functions such as <code>lm</code>, <code>glm</code> and
<code>prcomp</code> have an <code>na.action</code> argument.  The default is
<code>na.omit</code>, which means that cases with at least one NA value will
be discarded. (This is also settable via <code>options()</code>.) However,
<code>na.omit</code> seems to have no effect in <code>prcomp</code> unless that
function's <code>formula</code> option is used. When in doubt, apply the
function <code>na.omit</code> directly; e.g. <code>na.omit(d)</code> for a data
frame <code>d</code> returns a data frame consisting of only the intact rows of
<code>d</code>.
</p>
<p>The method assumes that the base estimator is asymptotically normal, and
assumes i.i.d. data.  If your data set had been stored in some sorted
order, it must be randomized first, say using the <code>scramble</code> option
in <code>distribsplit</code> or by calling <code>readnscramble</code>, depending on
whether your data is already in memory or still in a file.
</p>


<h3>Value</h3>

<p>R list with these components:
</p>

<ul>
<li> <p><code>thts</code>, the results of applying the requested estimator to
the chunks; the estimator from chunk i is in row i
</p>
</li>
<li> <p><code>tht</code>, the chunk-averaged overall estimator, if requested
</p>
</li>
<li> <p><code>thtcov</code>, the estimated covariance matrix of <code>tht</code>,
if available
</p>
</li>
</ul>
<p>The wrapper functions return the following list elements:
</p>

<ul>
<li> <p><code>calm</code>, <code>caglm</code>: estimated regression coefficients
and their estimated covariance matrix
</p>
</li>
<li> <p><code>caprcomp</code>: <code>sdev</code> (square roots of the
eigenvalues) and <code>rotation</code>, as with <code>prcomp</code>;
<code>thts</code> is returned as well.
</p>
</li>
<li> <p><code>cakm</code>: <code>centers</code> and <code>size</code>, as with
<code>kmeans</code>; <code>thts</code> is returned as well.
</p>
</li>
</ul>
<p>The wrappers that return <code>thts</code> are useful for algorithms that may
expose some instability in the original (i.e. non-SA) algorithm.  With
<code>prcomp</code>, for instance, the eigenvectors corresponding to the
smaller eigenvalues may have high variances in the nonparallel version,
which will be reflected in large differences from chunk to chunk in SA,
visible in <code>thts</code>.  Note that this reflects a fundamental problem
with the algorithm on the given data set, not due to Software Alchemy;
on the contrary, an important advantage of the SA approach is to expose
such problems.
</p>


<h3>Author(s)</h3>

<p>Norm Matloff
</p>


<h3>References</h3>

<p>N. Matloff N (2016). "Software Alchemy: Turning Complex Statistical
Computations into Embarrassingly-Parallel Ones." <em>Journal of Statistical
Software</em>, <b>71(4)</b>, 1-15.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# set up 'parallel' cluster
cls &lt;- makeCluster(2)
setclsinfo(cls)

# generate simulated test data, as distributed data frame
n &lt;- 10000
p &lt;- 2
tmp &lt;- matrix(rnorm((p+1)*n),nrow=n)
u &lt;- tmp[,1:p]  # "X" values
# add a "Y" col
u &lt;- cbind(u,u %*% rep(1,p) + tmp[,p+1])
# now in u, cols 1,2 are the "X" variables, and col 3 is "Y", 
# with regress coefs (0,1,1), with tmp[,p+1] being the error term
distribsplit(cls,"u")  # form distributed d.f.
# apply the function
#### calm(cls,"u[,3] ~ u[,1]+u[,2]")$tht
calm(cls,"V3 ~ .,data=u")$tht
# check; results should be approximately the same
lm(u[,3] ~ u[,1]+u[,2])
# without the wrapper
ovf &lt;- function(dummy=NULL) lm(V3 ~ .,data=z168)
ca(cls,u,ovf,estf=coef,estcovf=vcov)$tht

## Not run: 
# Census data on programmers and engineers; include a quadratic term for
# age, due to nonmonotone relation to income
data(prgeng) 
distribsplit(cls,"prgeng") 
caout &lt;- calm(cls,"wageinc ~ age+I(age^2)+sex+wkswrkd,data=prgeng")
caout$tht
# compare to nonparallel
lm(wageinc ~ age+I(age^2)+sex+wkswrkd,data=prgeng)
# get standard errors of the beta-hats
sqrt(diag(caout$thtcov))

# find mean age for all combinations of the cit and sex variables
caagg(cls,"age",c("cit","sex"),"prgeng","mean") 
# compare to nonparallel
aggregate(age ~ cit+sex,data=prgeng,mean)  

data(newadult) 
distribsplit(cls,"newadult") 
caglm(cls," gt50 ~ ., family = binomial,data=newadult")$tht 

caprcomp(cls,'newadult,scale=TRUE',5)$sdev
prcomp(newadult,scale=TRUE)$sdev

cameans(cls,"prgeng")
cameans(cls,"prgeng[,c('age','wageinc')]")
caquantile(cls,'prgeng$age')

pe &lt;- prgeng[,c(1,3,8)] 
distribsplit(cls,"pe") 
z1 &lt;- cakm(cls,'pe',3,3); z1$size; z1$centers 
# check algorithm unstable
z1$thts  # looks unstable

pe &lt;- prgeng 
pe$ms &lt;- as.integer(pe$educ == 14) 
pe$phd &lt;- as.integer(pe$educ == 16) 
pe &lt;- pe[,c(1,7,8,9,12,13)] 
distribsplit(cls,'pe',scramble=TRUE)
kout &lt;- caknn(cls,'pe[,3]',50,'pe[,-3]') 

## End(Not run)

stopCluster(cls)

</code></pre>


</div>