<div class="container">

<table style="width: 100%;"><tr>
<td>test_pe</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Test for Underestimated Processing Error Variance in Pooling Studies</h2>

<h3>Description</h3>

<p>In studies where a biomarker is measured in combined samples from multiple
subjects rather than for each individual, design parameters (e.g. optimal
pool size, sample size for 80% power) are very sensitive to the magnitude of
processing errors. This function provides a test that can be used midway
through data collection to test whether the processing error variance is
larger than initially assumed, in which case the pool size may need to be
adjusted.
</p>


<h3>Usage</h3>

<pre><code class="language-R">test_pe(xtilde, g, sigsq, sigsq_m = 0, multiplicative = FALSE,
  mu = NULL, alpha = 0.05, boots = 1000, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>xtilde</code></td>
<td>
<p>Numeric vector of pooled measurements.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>g</code></td>
<td>
<p>Numeric value specifying the pool size.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigsq</code></td>
<td>
<p>Numeric value specifying the variance of observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigsq_m</code></td>
<td>
<p>Numeric value specifying the variance of measurement errors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>multiplicative</code></td>
<td>
<p>Logical value for whether to assume multiplicative
rather than additive errors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>Numeric value specifying the mean of observations. Only used if
<code>multiplicative = TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>Numeric value specifying significance level for bootstrap
confidence interval.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>boots</code></td>
<td>
<p>Numeric value specifying the number of bootstrap samples to
take.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Numeric value specifying the random number seed, in case it is
important to be able to reproduce the lower bound.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The method is fully described in a manuscript currently under review.
Briefly, the test of interest is <code>H0: sigsq_p &lt;= c</code>, where
<code>sigsq_p</code> is the processing error variance and <code>c</code> is the value
assumed during study design. Under additive errors, a point estimate for
<code>sigsq_p</code> is given by:
</p>
<p><code>sigsq_p.hat = s2 - sigsq / g - sigsq_m</code>
</p>
<p>where <code>s2</code> is the sample variance of poolwise measurements, <code>g</code> is
the pool size, and <code>sigsq_m</code> is the measurement error variance which may
be 0 if the assay is known to be precise.
</p>
<p>Under multiplicative errors, the estimator is:
</p>
<p><code>sigsq_p.hat = [(s2 - sigsq / g) / (mu^2 + sigsq / g) - sigsq_m] /
(1 + sigsq_m)</code>.
</p>
<p>In either case, bootstrapping can be used to obtain a lower bound for a
one-sided confidence interval. If the lower bound is greater than <code>c</code>,
<code>H0</code> is rejected.
</p>


<h3>Value</h3>

<p>List containing point estimate and lower bound of confidence
interval.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Generate data for hypothetical study designed assuming sigsq_p = 0.1, but
# truly sigsq_p = 0.25. Have data collected for 40 pools of size 5, and wish
# to test H0: sigsq_p &lt;= 0.1. In this instance, a false negative occurs.
set.seed(123)
xtilde &lt;- replicate(n = 40, expr = mean(rnorm(5)) + rnorm(n = 1, sd = sqrt(0.25)))
(fit &lt;- test_pe(xtilde = xtilde, g = 5, sigsq = 1, sigsq_m = 0))


</code></pre>


</div>