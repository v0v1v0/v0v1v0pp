<div class="container">

<table style="width: 100%;"><tr>
<td>reperry</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Recompute resampling-based prediction error measures</h2>

<h3>Description</h3>

<p>Recompute prediction error measures for previously obtained objects that 
contain resampling-based prediction error results.  This is useful for 
computing a different measure of prediction loss.
</p>


<h3>Usage</h3>

<pre><code class="language-R">reperry(object, ...)

## S3 method for class 'perry'
reperry(object, cost = rmspe, ...)

## S3 method for class 'perrySelect'
reperry(object, cost = rmspe, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>an object inheriting from class <code>"perry"</code> or 
<code>"perrySelect"</code> that contains prediction error results.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>for the generic function, additional arguments to be passed 
down to methods.  For the methods,  additional arguments to be passed to the 
prediction loss function <code>cost</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cost</code></td>
<td>
<p>a cost function measuring prediction loss.  It should expect 
the observed values of the response to be passed as the first argument and 
the predicted values as the second argument, and must return either a 
non-negative scalar value, or a list with the first component containing 
the prediction error and the second component containing the standard 
error.  The default is to use the root mean squared prediction error 
(see <code>cost</code>).</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>An object similar to <code>object</code> containing the results for the 
new measure of prediction loss.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>See Also</h3>

<p><code>perryFit</code>, <code>perryTuning</code>, 
<code>perrySelect</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">library("perryExamples")
data("coleman")
set.seed(1234)  # set seed for reproducibility

## set up folds for cross-validation
folds &lt;- cvFolds(nrow(coleman), K = 5, R = 10)

## compare raw and reweighted LTS estimators for 50% and 75%
## subsets based on their RTMSPE with 25% trimming

# 50% subsets
fit50 &lt;- ltsReg(Y ~ ., data = coleman, alpha = 0.5)
cv50 &lt;- perry(fit50, splits = folds, fit = "both",
              cost = rtmspe, trim = 0.25)

# 75% subsets
fit75 &lt;- ltsReg(Y ~ ., data = coleman, alpha = 0.75)
cv75 &lt;- perry(fit75, splits = folds, fit = "both",
              cost = rtmspe, trim = 0.25)

# combine results into one object
cv &lt;- perrySelect("0.5" = cv50, "0.75" = cv75)
cv

## recompute the RTMSPE with 10% trimming
reperry(cv50, cost = rtmspe, trim = 0.1)
reperry(cv, cost = rtmspe, trim = 0.1)
</code></pre>


</div>