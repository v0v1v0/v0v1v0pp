<div class="container">

<table style="width: 100%;"><tr>
<td>pedmod_profile_prop</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Computes Profile Likelihood Based Confidence Intervals for the Proportion
of Variance</h2>

<h3>Description</h3>

<p>Constructs a likelihood ratio based confidence intervals for the
proportion of variance for one of the effects.
</p>


<h3>Usage</h3>

<pre><code class="language-R">pedmod_profile_prop(
  ptr,
  par,
  maxvls,
  minvls = -1L,
  alpha = 0.05,
  abs_eps,
  rel_eps,
  which_prof,
  indices = NULL,
  maxvls_start = max(100L, as.integer(ceiling(maxvls/5))),
  minvls_start = if (minvls &lt; 0) minvls else minvls/5,
  do_reorder = TRUE,
  use_aprx = FALSE,
  n_threads = 1L,
  cluster_weights = NULL,
  method = 0L,
  seed = 1L,
  verbose = FALSE,
  max_step = 15L,
  opt_func = NULL,
  use_tilting = FALSE,
  vls_scales = NULL,
  bound = c(0.01, 0.99),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>ptr</code></td>
<td>
<p>object from <code>pedigree_ll_terms</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>par</code></td>
<td>
<p>numeric vector with the maximum likelihood estimator e.g. from
<code>pedmod_opt</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxvls</code></td>
<td>
<p>maximum number of samples in the approximation for each
marginal likelihood term.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minvls</code></td>
<td>
<p>minimum number of samples for each
marginal likelihood term. Negative values provides a
default which depends on the dimension of the integration.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>numeric scalar with the confidence level required.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>abs_eps</code></td>
<td>
<p>absolute convergence threshold for
<code>eval_pedigree_ll</code> and <code>eval_pedigree_grad</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rel_eps</code></td>
<td>
<p>rel_eps convergence threshold for
<code>eval_pedigree_ll</code> and <code>eval_pedigree_grad</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>which_prof</code></td>
<td>
<p>the index of the random effect which proportion of
variance should be profiled.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>indices</code></td>
<td>
<p>zero-based vector with indices of which log marginal
likelihood terms to include. Use <code>NULL</code> if all indices should be
used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxvls_start, minvls_start</code></td>
<td>
<p>number of samples to use when finding the
initial values for the optimization.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>do_reorder</code></td>
<td>
<p><code>TRUE</code> if a heuristic variable reordering should
be used. <code>TRUE</code> is likely the best value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use_aprx</code></td>
<td>
<p><code>TRUE</code> if a less precise approximation of
<code>pnorm</code> and <code>qnorm</code> should be used. This may
reduce the computation time while not affecting the result much.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_threads</code></td>
<td>
<p>number of threads to use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cluster_weights</code></td>
<td>
<p>numeric vector with weights for each cluster. Use
<code>NULL</code> if all clusters have weight one.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>integer with the method to use. Zero yields randomized Korobov
lattice rules while one yields scrambled Sobol sequences.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>seed to pass to <code>set.seed</code> before each gradient and
function evaluation. Use <code>NULL</code> if the seed should not be fixed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>logical for whether output should be printed to the console
during the estimation of the profile likelihood curve.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_step</code></td>
<td>
<p>integer scalar with the maximum number of steps to take in
either directions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>opt_func</code></td>
<td>
<p>function to perform minimization with arguments like
<code>optim</code>. BFGS is used with <code>optim</code> if this argument
is <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use_tilting</code></td>
<td>
<p><code>TRUE</code> if the minimax tilting method suggested
by Botev (2017) should be used. See <a href="https://doi.org/10.1111/rssb.12162">doi:10.1111/rssb.12162</a>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vls_scales</code></td>
<td>
<p>can be a numeric vector with a positive scalar for each
cluster. Then <code>vls_scales[i] * minvls</code> and
<code>vls_scales[i] * maxvls</code> is used for cluster <code>i</code> rather than
<code>minvls</code> and <code>maxvls</code>. Set <code>vls_scales = NULL</code> if the latter
should be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bound</code></td>
<td>
<p>boundaries for the limits of the proportion. Has to be in
between <code class="reqn">(0,1)</code>. This is useful particularly if the optimization fails to
work on the default values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>arguments passed to <code>opt_func</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function is only useful when there is more than one type of random
effect. If not, then <code>pedmod_profile</code> can be used because of
the scale invariance of the likelihood ratio.
</p>


<h3>Value</h3>

<p>A list like <code>pedmod_profile</code>.
</p>


<h3>See Also</h3>

<p><code>pedmod_opt</code>, <code>pedmod_sqn</code>,
<code>pedmod_profile</code>, and <code>pedmod_profile_nleq</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# we simulate outcomes with an additive genetic effect and a childhood
# environment effect. The kinship matrix is the same for all families and
# given by
K &lt;- matrix(c(
  0.5  , 0    , 0.25 , 0   , 0.25 , 0   , 0.125 , 0.125 , 0.125 , 0.125 ,
  0    , 0.5  , 0.25 , 0   , 0.25 , 0   , 0.125 , 0.125 , 0.125 , 0.125 ,
  0.25 , 0.25 , 0.5  , 0   , 0.25 , 0   , 0.25  , 0.25  , 0.125 , 0.125 ,
  0    , 0    , 0    , 0.5 , 0    , 0   , 0.25  , 0.25  , 0     , 0     ,
  0.25 , 0.25 , 0.25 , 0   , 0.5  , 0   , 0.125 , 0.125 , 0.25  , 0.25  ,
  0    , 0    , 0    , 0   , 0    , 0.5 , 0     , 0     , 0.25  , 0.25  ,
  0.125, 0.125, 0.25 , 0.25, 0.125, 0   , 0.5   , 0.25  , 0.0625, 0.0625,
  0.125, 0.125, 0.25 , 0.25, 0.125, 0   , 0.25  , 0.5   , 0.0625, 0.0625,
  0.125, 0.125, 0.125, 0   , 0.25 , 0.25, 0.0625, 0.0625, 0.5   , 0.25  ,
  0.125, 0.125, 0.125, 0   , 0.25 , 0.25, 0.0625, 0.0625, 0.25  , 0.5
), 10)

# the scale matrix for the childhood environment effect is also the same and
# given by
C &lt;- matrix(c(
  1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
  0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
  0, 0, 1, 0, 1, 0, 0, 0, 0, 0,
  0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
  0, 0, 1, 0, 1, 0, 0, 0, 0, 0,
  0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
  0, 0, 0, 0, 0, 0, 1, 1, 0, 0,
  0, 0, 0, 0, 0, 0, 1, 1, 0, 0,
  0, 0, 0, 0, 0, 0, 0, 0, 1, 1,
  0, 0, 0, 0, 0, 0, 0, 0, 1, 1
), 10L)

# simulates a data set.
#
# Args:
#   n_fams: number of families.
#   beta: the fixed effect coefficients.
#   sig_sq: the scale parameters.
sim_dat &lt;- function(n_fams, beta = c(-1, 1, 2), sig_sq = c(3, 1)){
  # setup before the simulations
  Cmat &lt;- 2 * K
  n_obs &lt;- NROW(K)
  Sig &lt;- diag(n_obs) + sig_sq[1] * Cmat + sig_sq[2] * C
  Sig_chol &lt;- chol(Sig)

  # simulate the data
  out &lt;- replicate(
    n_fams, {
      # simulate covariates
      X &lt;- cbind(`(Intercept)` = 1, Continuous = rnorm(n_obs),
                 Binary = runif(n_obs) &gt; .5)

      # assign the linear predictor + noise
      eta &lt;- drop(X %*% beta) + drop(rnorm(n_obs) %*% Sig_chol)

      # return the list in the format needed for the package
      list(y = as.numeric(eta &gt; 0), X = X,
           scale_mats = list(genetic = Cmat, environment = C))
    }, simplify = FALSE)

  # add attributes with the true values and return
  attributes(out) &lt;- list(beta = beta, sig_sq = sig_sq)
  out
}

# simulate the data
set.seed(1)
dat &lt;- sim_dat(200L)

# fit the model
ptr &lt;- pedigree_ll_terms(dat, max_threads = 1L)
start &lt;- pedmod_start(ptr = ptr, data = dat, n_threads = 1L)
fit &lt;- pedmod_opt(ptr = ptr, par = start$par, n_threads = 1L, use_aprx = TRUE,
                  maxvls = 5000L, minvls = 1000L, abs_eps = 0, rel_eps = 1e-3)
fit$par # the estimate

# 90% likelihood ratio based confidence interval for the proportion of variance
# of the genetic effect
prof_out &lt;- pedmod_profile_prop(
  ptr = ptr, fit$par, maxvls = 5000L, minvls = 1000L, alpha = .1,
  which_prof = 1L, abs_eps = 0, rel_eps = 1e-3, verbose = TRUE)
prof_out$confs # the confidence interval for the proportion

# plot the log profile likelihood
keep &lt;- c(-1L, -length(prof_out$xs))
plot(prof_out$xs[keep], prof_out$p_log_Lik[keep], pch = 16,
     xlab = "proportion of variance", ylab = "log profile likelihood")
abline(v = prof_out$confs, lty = 2)


</code></pre>


</div>