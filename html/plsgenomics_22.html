<div class="container">

<table style="width: 100%;"><tr>
<td>mrpls.cv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Determination of the ridge regularization parameter and the number of PLS 
components to be used for classification with RPLS for categorical data</h2>

<h3>Description</h3>

<p>The function <code>mrpls.cv</code> determines the best ridge regularization parameter and the best 
number of PLS components to be used for classification for Fort et al. (2005) MRPLS algorithm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mrpls.cv(Ytrain, Xtrain, LambdaRange, ncompMax, NbIterMax=50, ncores=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Xtrain</code></td>
<td>
<p>a (ntrain x p) data matrix of predictors. <code>Xtrain</code> must be a matrix. 
Each row corresponds to an observation and each column to a predictor variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ytrain</code></td>
<td>
<p>a ntrain vector of responses. <code>Ytrain</code> must be a vector. 
<code>Ytrain</code> is a {0,...,c}-valued vector and contains the response variable for each
observation. c+1 is the number of classes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>LambdaRange</code></td>
<td>
<p>the vector of positive real value from which the best ridge regularization 
parameter has to be chosen by cross-validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncompMax</code></td>
<td>
<p>a positive integer. The best number of components is chosen from  
1,...,<code>ncompMax</code>. If <code>ncompMax</code>=0,then the Ridge regression is performed without 
reduction dimension. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>NbIterMax</code></td>
<td>
<p>a positive integer. <code>NbIterMax</code> is the maximal number of iterations in the 
Newton-Rapson parts.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncores</code></td>
<td>
<p>a positive integer. The number of cores to be used for parallel computing 
(if different from 1)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>A cross-validation procedure is used to determine the best ridge regularization parameter and 
number of PLS components to be used for classification with MRPLS for categorical data 
(for binary data see <code>rpls</code> and <code>rpls.cv</code>).
At each cross-validation run, <code>Xtrain</code> is split into a pseudo training
set (ntrain-1 samples) and a pseudo test set (1 sample) and the classification error rate is 
determined for each value of ridge regularization parameter and number of components. Finally, 
the function <code>mrpls.cv</code> returns the values of the ridge regularization parameter and 
bandwidth for which the mean classification error rate is minimal. 
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Lambda</code></td>
<td>
<p>the optimal regularization parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncomp</code></td>
<td>
<p>the optimal number of PLS components.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Sophie Lambert-Lacroix 
(<a href="http://membres-timc.imag.fr/Sophie.Lambert/">http://membres-timc.imag.fr/Sophie.Lambert/</a>). 
</p>


<h3>References</h3>

<p>G. Fort, S. Lambert-Lacroix and Julie Peyre (2005). Reduction de dimension dans les modeles 
lineaires generalises : application a la classification supervisee de donnees issues des biopuces.
Journal de la SFDS, tome 146, n1-2, 117-152. 
</p>


<h3>See Also</h3>

<p><code>mrpls</code>, <code>rpls</code>, <code>rpls.cv</code>.</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
## between 5~15 seconds
# load plsgenomics library
library(plsgenomics)

# load SRBCT data
data(SRBCT)
IndexLearn &lt;- c(sample(which(SRBCT$Y==1),10),sample(which(SRBCT$Y==2),4),
			sample(which(SRBCT$Y==3),7),sample(which(SRBCT$Y==4),9))

# Determine optimum ncomp and Lambda
nl &lt;- mrpls.cv(Ytrain=SRBCT$Y[IndexLearn]-1,Xtrain=SRBCT$X[IndexLearn,],
			LambdaRange=c(0.1,1),ncompMax=3)

# perform prediction by MRPLS
res &lt;- mrpls(Ytrain=SRBCT$Y[IndexLearn]-1,Xtrain=SRBCT$X[IndexLearn,],Lambda=nl$Lambda,
			ncomp=nl$ncomp,Xtest=SRBCT$X[-IndexLearn,])
sum(res$Ytest!=SRBCT$Y[-IndexLearn]-1)

## End(Not run)
</code></pre>


</div>