<div class="container">

<table style="width: 100%;"><tr>
<td>yale</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Face Recognition</h2>

<h3>Description</h3>

<p>This data set contains vectorised images of the faces of 10 different human subjects with different poses and lighting conditions. The images were compressed to 30x20 pixels.
</p>


<h3>Usage</h3>

<pre><code class="language-R">yale</code></pre>


<h3>Format</h3>

<p>A list with entries $x (a 2000x600 matrix with each row corresponding to an image) and $y (a vector of labels indicating the human subject).</p>


<h3>Source</h3>

<p>Yale Faces Database B. Compressed images (30x40) available from [https://cervisia.org/machine_learning_data.php/]. Further compression was performed by the package developers. In addition only the first 200 images of each subject are included.</p>


<h3>References</h3>

<p>Georghiades, A.S. and Belhumeur, P.N. and Kriegman, D.J. (2001) From Few to Many: Illumination Cone Models for Face Recognition under
Variable Lighting and Pose. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, <b>23</b>(6) pp. 643â€“660.
</p>


</div>