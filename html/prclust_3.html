<div class="container">

<table style="width: 100%;"><tr>
<td>GCV</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Calculate the Generalized Cross-Validation Statistic (GCV)</h2>

<h3>Description</h3>

<p>Calculate the generalized cross-validation statistic with generalized degrees of freedom.
</p>


<h3>Usage</h3>

<pre><code class="language-R">GCV(data,lambda1,lambda2,tau,sigma,B=100,
	loss.method = c("quadratic","lasso"),
	grouping.penalty = c("gtlp","L1","SCAD","MCP"), 
	algorithm = c("ADMM","Quadratic"), epsilon =0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>

<p>Numeric data matrix .
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda1</code></td>
<td>

<p>Tuning parameter or step size: lambda1, typically set at 1 for quadratic penalty based algorithm; 0.4 for revised ADMM.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda2</code></td>
<td>

<p>Tuning parameter: lambda2, the magnitude of grouping penalty.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tau</code></td>
<td>

<p>Tuning parameter: tau, related to grouping penalty.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma</code></td>
<td>

<p>The perturbation size.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>

<p>The Monte Carlo time. The defualt value is 100.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loss.method </code></td>
<td>

<p>character may be abbreviated. "lasso" stands for <code class="reqn">L_1</code> loss function, while "quadratic" stands for the quadratic loss function.  
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>grouping.penalty</code></td>
<td>

<p>character: may be abbreviated. "gtlp" means generalized group lasso is used for grouping penalty. "lasso" means lasso is used for grouping penalty. "SCAD" and "MCP" are two other non-convex penalty.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>algorithm</code></td>
<td>

<p>character: may be abbreviated. The algorithm will use for finding the solution. The default algorithm is "ADMM", which stands for the DC-ADMM.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsilon</code></td>
<td>
<p>The stopping critetion parameter. The default is 0.001.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>A bonus with the regression approach to clustering is the potential application of many existing model selection methods for regression or supervised learning to clustering. We propose using generalized cross-validation (GCV). GCV can be regarded as an approximation to leave-one-out cross-validation (CV). Hence, GCV provides an approximately unbiased estimate of the prediction error.
</p>
<p>We use the generalized degrees of freedom (GDF) to consider the data-adaptive nature in estimating the centroids of the observations.
</p>
<p>The chosen tuning parameters are the one giving the smallest GCV error.
</p>


<h3>Value</h3>

<p>Return value: the Generalized cross-validation statistic (GCV)
</p>


<h3>Author(s)</h3>

<p>Chong Wu, Wei Pan
</p>


<h3>References</h3>

<p>Pan, W., Shen, X., &amp; Liu, B. (2013). Cluster analysis: unsupervised learning via supervised learning with a non-convex penalty. <em>Journal of Machine Learning Research</em>, 14(1), 1865-1889.
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(1)
library("prclust")
data = matrix(NA,2,50)
data[1,1:25] = rnorm(25,0,0.33)
data[2,1:25] = rnorm(25,0,0.33)
data[1,26:50] = rnorm(25,1,0.33)
data[2,26:50] = rnorm(25,1,0.33)

#case 1
gcv1 = GCV(data,lambda1=1,lambda2=1,tau=0.5,sigma=0.25,B =10)
gcv1

#case 2
gcv2 = GCV(data,lambda1=1,lambda2=0.7,tau=0.3,sigma=0.25,B = 10)
gcv2

# Note that the combination of tuning parameters in case 1 are better than 
# the combination of tuning parameters in case 2 since the value of GCV in case 1 is
# less than the value in case 2.
</code></pre>


</div>