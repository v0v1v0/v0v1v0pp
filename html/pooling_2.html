<div class="container">

<table style="width: 100%;"><tr>
<td>cond_logreg</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Conditional Logistic Regression with Measurement Error in One Covariate</h2>

<h3>Description</h3>

<p>Compatible with individual or pooled measurements. Assumes a normal linear
model for exposure given other covariates, and additive normal errors.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cond_logreg(g = rep(1, length(xtilde1)), xtilde1, xtilde0, c1 = NULL,
  c0 = NULL, errors = "processing", approx_integral = TRUE,
  estimate_var = FALSE, start_nonvar_var = c(0.01, 1),
  lower_nonvar_var = c(-Inf, 1e-04), upper_nonvar_var = c(Inf, Inf),
  jitter_start = 0.01, hcubature_list = list(tol = 1e-08),
  nlminb_list = list(control = list(trace = 1, eval.max = 500, iter.max =
  500)), hessian_list = list(method.args = list(r = 4)),
  nlminb_object = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>g</code></td>
<td>
<p>Numeric vector with pool sizes, i.e. number of members in each pool.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xtilde1</code></td>
<td>
<p>Numeric vector (or list of numeric vectors, if some
observations have replicates) with Xtilde values for cases.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xtilde0</code></td>
<td>
<p>Numeric vector (or list of numeric vectors, if some
observations have replicates) with Xtilde values for controls.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>c1</code></td>
<td>
<p>Numeric matrix with precisely measured covariates for cases.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>c0</code></td>
<td>
<p>Numeric matrix with precisely measured covariates for controls.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>errors</code></td>
<td>
<p>Character string specifying the errors that X is subject to.
Choices are <code>"none"</code>, <code>"measurement"</code> for measurement error,
<code>"processing"</code> for processing error (only relevant for pooled data), and
<code>"both"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>approx_integral</code></td>
<td>
<p>Logical value for whether to use the probit
approximation for the logistic-normal integral, to avoid numerically
integrating X's out of the likelihood function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>estimate_var</code></td>
<td>
<p>Logical value for whether to return variance-covariance
matrix for parameter estimates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start_nonvar_var</code></td>
<td>
<p>Numeric vector of length 2 specifying starting value
for non-variance terms and variance terms, respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower_nonvar_var</code></td>
<td>
<p>Numeric vector of length 2 specifying lower bound for
non-variance terms and variance terms, respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>upper_nonvar_var</code></td>
<td>
<p>Numeric vector of length 2 specifying upper bound for
non-variance terms and variance terms, respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>jitter_start</code></td>
<td>
<p>Numeric value specifying standard deviation for mean-0
normal jitters to add to starting values for a second try at maximizing the
log-likelihood, should the initial call to <code>nlminb</code> result
in non-convergence. Set to <code>NULL</code> for no second try.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hcubature_list</code></td>
<td>
<p>List of arguments to pass to
<code>hcubature</code> for numerical integration. Only used if
<code>approx_integral = FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlminb_list</code></td>
<td>
<p>List of arguments to pass to <code>nlminb</code>
for log-likelihood maximization.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hessian_list</code></td>
<td>
<p>List of arguments to pass to
<code>hessian</code> for approximating the Hessian matrix. Only
used if <code>estimate_var = TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlminb_object</code></td>
<td>
<p>Object returned from <code>nlminb</code> in a
prior call. Useful for bypassing log-likelihood maximization if you just want
to re-estimate the Hessian matrix with different options.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>List containing:
</p>

<ol>
<li>
<p> Numeric vector of parameter estimates.
</p>
</li>
<li>
<p> Variance-covariance matrix (if <code>estimate_var = TRUE</code>).
</p>
</li>
<li>
<p> Returned <code>nlminb</code> object from maximizing the
log-likelihood function.
</p>
</li>
<li>
<p> Akaike information criterion (AIC).
</p>
</li>
</ol>
<h3>References</h3>

<p>Saha-Chaudhuri, P., Umbach, D.M. and Weinberg, C.R. (2011) "Pooled exposure
assessment for matched case-control studies." <em>Epidemiology</em>
<strong>22</strong>(5): 704–712.
</p>
<p>Schisterman, E.F., Vexler, A., Mumford, S.L. and Perkins, N.J. (2010) "Hybrid
pooled-unpooled design for cost-efficient measurement of biomarkers."
<em>Stat. Med.</em> <strong>29</strong>(5): 597–613.
</p>
<p>Weinberg, C.R. and Umbach, D.M. (1999) "Using pooled exposure assessment to
improve efficiency in case-control studies." <em>Biometrics</em> <strong>55</strong>:
718–726.
</p>
<p>Weinberg, C.R. and Umbach, D.M. (2014) "Correction to 'Using pooled exposure
assessment to improve efficiency in case-control studies' by Clarice R.
Weinberg and David M. Umbach; 55, 718–726, September 1999."
<em>Biometrics</em> <strong>70</strong>: 1061.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Load simulated data for 150 case pools and 150 control pools
data(dat_cond_logreg)
dat &lt;- dat_cond_logreg$dat
xtilde1 &lt;- dat_cond_logreg$xtilde1
xtilde0 &lt;- dat_cond_logreg$xtilde0

# Fit conditional logistic regression to estimate log-odds ratio for X and Y
# adjusted for C, using the precise poolwise summed exposure X. True log-OR
# for X is 0.5.
truth &lt;- cond_logreg(
  g = dat$g,
  xtilde1 = dat$x1,
  xtilde0 = dat$x0,
  c1 = dat$c1.model,
  c0 = dat$c0.model,
  errors = "neither"
)
truth$theta.hat

# Suppose X is subject to additive measurement error and processing error,
# and we observe Xtilde1 and Xtilde0 rather than X1 and X0. Fit model with
# Xtilde's, accounting for errors (numerical integration avoided by using
# probit approximation).
## Not run: 
corrected &lt;- cond_logreg(
  g = dat$g,
  xtilde1 = xtilde1,
  xtilde0 = xtilde0,
  c1 = dat$c1.model,
  c0 = dat$c0.model,
  errors = "both",
  approx_integral = TRUE
)
corrected$theta.hat

## End(Not run)


</code></pre>


</div>