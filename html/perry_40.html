<div class="container">

<table style="width: 100%;"><tr>
<td>perryTuning</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Resampling-based prediction error for tuning parameter selection</h2>

<h3>Description</h3>

<p>Select tuning parameters of a model by estimating the respective prediction
errors via (repeated) <code class="reqn">K</code>-fold cross-validation, (repeated) random
splitting (also known as random subsampling or Monte Carlo
cross-validation), or the bootstrap.  It is thereby possible to supply a
model fitting function or an unevaluated function call to a model fitting
function.
</p>


<h3>Usage</h3>

<pre><code class="language-R">perryTuning(object, ...)

## S3 method for class ''function''
perryTuning(
  object,
  formula,
  data = NULL,
  x = NULL,
  y,
  tuning = list(),
  args = list(),
  splits = foldControl(),
  predictFun = predict,
  predictArgs = list(),
  cost = rmspe,
  costArgs = list(),
  selectBest = c("min", "hastie"),
  seFactor = 1,
  final = FALSE,
  names = NULL,
  envir = parent.frame(),
  ncores = 1,
  cl = NULL,
  seed = NULL,
  ...
)

## S3 method for class 'call'
perryTuning(
  object,
  data = NULL,
  x = NULL,
  y,
  tuning = list(),
  splits = foldControl(),
  predictFun = predict,
  predictArgs = list(),
  cost = rmspe,
  costArgs = list(),
  selectBest = c("min", "hastie"),
  seFactor = 1,
  final = FALSE,
  names = NULL,
  envir = parent.frame(),
  ncores = 1,
  cl = NULL,
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>a function or an unevaluated function call for fitting
a model (see <code>call</code> for the latter).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments to be passed down.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>a <code>formula</code> describing the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>a data frame containing the variables required for fitting the
models.  This is typically used if the model in the function call is
described by a <code>formula</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a numeric matrix containing the predictor variables.  This is
typically used if the function call for fitting the models requires the
predictor matrix and the response to be supplied as separate arguments.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a numeric vector or matrix containing the response.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tuning</code></td>
<td>
<p>a list of arguments giving the tuning parameter values to be
evaluated.  The names of the list components should thereby correspond to
the argument names of the tuning parameters.  For each tuning parameter, a
vector of values can be supplied.  The prediction error is then estimated
for all possible combinations of tuning parameter values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>args</code></td>
<td>
<p>a list of additional arguments to be passed to the model
fitting function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>splits</code></td>
<td>
<p>an object of class <code>"cvFolds"</code> (as returned by
<code>cvFolds</code>) or a control object of class <code>"foldControl"</code>
(see <code>foldControl</code>) defining the folds of the data for
(repeated) <code class="reqn">K</code>-fold cross-validation, an object of class
<code>"randomSplits"</code> (as returned by <code>randomSplits</code>) or a
control object of class <code>"splitControl"</code> (see
<code>splitControl</code>) defining random data splits, or an object of
class <code>"bootSamples"</code> (as returned by <code>bootSamples</code>) or a
control object of class <code>"bootControl"</code> (see <code>bootControl</code>)
defining bootstrap samples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>predictFun</code></td>
<td>
<p>a function to compute predictions for the test data.  It
should expect the fitted model to be passed as the first argument and the test
data as the second argument, and must return either a vector or a matrix
containing the predicted values.  The default is to use the
<code>predict</code> method of the fitted model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>predictArgs</code></td>
<td>
<p>a list of additional arguments to be passed to
<code>predictFun</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cost</code></td>
<td>
<p>a cost function measuring prediction loss.  It should expect
the observed values of the response to be passed as the first argument and
the predicted values as the second argument, and must return either a
non-negative scalar value, or a list with the first component containing
the prediction error and the second component containing the standard
error.  The default is to use the root mean squared prediction error
(see <code>cost</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>costArgs</code></td>
<td>
<p>a list of additional arguments to be passed to the
prediction loss function <code>cost</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectBest</code></td>
<td>
<p>a character string specifying a criterion for selecting
the best model.  Possible values are <code>"min"</code> (the default) or
<code>"hastie"</code>.  The former selects the model with the smallest prediction
error.  The latter is useful for models with a tuning parameter controlling
the complexity of the model (e.g., penalized regression).  It selects the
most parsimonious model whose prediction error is no larger than
<code>seFactor</code> standard errors above the prediction error of the best
overall model.  Note that the models are thereby assumed to be ordered
from the most parsimonious one to the most complex one.  In particular
a one-standard-error rule is frequently applied.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seFactor</code></td>
<td>
<p>a numeric value giving a multiplication factor of the
standard error for the selection of the best model.  This is ignored if
<code>selectBest</code> is <code>"min"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>final</code></td>
<td>
<p>a logical indicating whether to fit the final model with the
optimal combination of tuning parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>names</code></td>
<td>
<p>an optional character vector giving names for the arguments
containing the data to be used in the function call (see “Details”).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>envir</code></td>
<td>
<p>the <code>environment</code> in which to evaluate the
function call for fitting the models (see <code>eval</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncores</code></td>
<td>
<p>a positive integer giving the number of processor cores to be
used for parallel computing (the default is 1 for no parallelization).  If
this is set to <code>NA</code>, all available processor cores are used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cl</code></td>
<td>
<p>a <span class="pkg">parallel</span> cluster for parallel computing as generated by
<code>makeCluster</code>.  If supplied, this is preferred over
<code>ncores</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>optional initial seed for the random number generator (see
<code>.Random.seed</code>).  Note that also in case of parallel computing,
resampling is performed on the manager process rather than the worker
processes. On the parallel worker processes, random number streams are
used and the seed is set via <code>clusterSetRNGStream</code> for
reproducibility in case the model fitting function involves randomness.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>(Repeated) <code class="reqn">K</code>-fold cross-validation is performed in the following
way.  The data are first split into <code class="reqn">K</code> previously obtained blocks of
approximately equal size (given by <code>folds</code>).  Each of the <code class="reqn">K</code> data
blocks is left out once to fit the model, and predictions are computed for
the observations in the left-out block with <code>predictFun</code>.  Thus a
prediction is obtained for each observation.  The response and the obtained
predictions for all observations are then passed to the prediction loss
function <code>cost</code> to estimate the prediction error.  For repeated
<code class="reqn">K</code>-fold cross-validation (as indicated by <code>splits</code>), this process
is replicated and the estimated prediction errors from all replications are
returned.
</p>
<p>(Repeated) random splitting is performed similarly.  In each replication,
the data are split into a training set and a test set at random.  Then the
training data are used to fit the model, and predictions are computed for
the test data.  Hence only the response values from the test data and the
corresponding predictions are passed to the prediction loss function
<code>cost</code>.
</p>
<p>For the bootstrap estimator, each bootstrap sample is used as training data
to fit the model.  The out-of-bag estimator uses the observations that do
not enter the bootstrap sample as test data and computes the prediction loss
function <code>cost</code> for those out-of-bag observations.  The 0.632 estimator
is computed as a linear combination of the out-of-bag estimator and the
prediction loss of the fitted values of the model computed from the full
sample.
</p>
<p>In any case, if the response is a vector but <code>predictFun</code> returns a
matrix, the prediction error is computed for each column.  A typical use
case for this behavior would be if <code>predictFun</code> returns predictions
from an initial model fit and stepwise improvements thereof.
</p>
<p>If <code>formula</code> or <code>data</code> are supplied, all variables required for
fitting the models are added as one argument to the function call, which is
the typical behavior of model fitting functions with a
<code>formula</code> interface.  In this case, the accepted values
for <code>names</code> depend on the method.  For the <code>function</code> method, a
character vector of length two should supplied, with the first element
specifying the argument name for the formula and the second element
specifying the argument name for the data (the default is to use
<code>c("formula", "data")</code>).  Note that names for both arguments should be
supplied even if only one is actually used.  For the <code>call</code> method,
which does not have a <code>formula</code> argument, a character string specifying
the argument name for the data should be supplied (the default is to use
<code>"data"</code>).
</p>
<p>If <code>x</code> is supplied, on the other hand, the predictor matrix and the
response are added as separate arguments to the function call.  In this
case, <code>names</code> should be a character vector of length two, with the
first element specifying the argument name for the predictor matrix and the
second element specifying the argument name for the response (the default is
to use <code>c("x", "y")</code>).  It should be noted that the <code>formula</code> or
<code>data</code> arguments take precedence over <code>x</code>.
</p>


<h3>Value</h3>

<p>If <code>tuning</code> is an empty list, <code>perryFit</code> is called to
return an object of class <code>"perry"</code>.
</p>
<p>Otherwise an object of class <code>"perryTuning"</code> (which inherits from class
<code>"perrySelect"</code>) with the following components is returned:
</p>

<dl>
<dt><code>pe</code></dt>
<dd>
<p>a data frame containing the estimated prediction errors
for all combinations of tuning parameter values.  In case of more than one
replication, those are average values over all replications.</p>
</dd>
<dt><code>se</code></dt>
<dd>
<p>a data frame containing the estimated standard errors of
the prediction loss for all combinations of tuning parameter values.</p>
</dd>
<dt><code>reps</code></dt>
<dd>
<p>a data frame containing the estimated prediction
errors from all replications for all combinations of tuning parameter
values.  This is only returned in case of more than one replication.</p>
</dd>
<dt><code>splits</code></dt>
<dd>
<p>an object giving the data splits used to estimate
the prediction error.</p>
</dd>
<dt><code>y</code></dt>
<dd>
<p>the response.</p>
</dd>
<dt><code>yHat</code></dt>
<dd>
<p>a list containing the predicted values for all
combinations of tuning parameter values.  Each list component is again a
list containing the corresponding predicted values from all replications.</p>
</dd>
<dt><code>best</code></dt>
<dd>
<p>an integer vector giving the indices of the optimal
combinations of tuning parameters.</p>
</dd>
<dt><code>selectBest</code></dt>
<dd>
<p>a character string specifying the criterion used
for selecting the best model.</p>
</dd>
<dt><code>seFactor</code></dt>
<dd>
<p>a numeric value giving the multiplication factor of
the standard error used for the selection of the best model.</p>
</dd>
<dt><code>tuning</code></dt>
<dd>
<p>a data frame containing the grid of tuning parameter
values for which the prediction error was estimated.</p>
</dd>
<dt><code>finalModel</code></dt>
<dd>
<p>the final model fit with the optimal combination
of tuning parameters.  This is only returned if argument <code>final</code> is
<code>TRUE</code>.</p>
</dd>
<dt><code>call</code></dt>
<dd>
<p>the matched function call.</p>
</dd>
</dl>
<h3>Note</h3>

<p>The same data splits are used for all combinations of tuning parameter
values for maximum comparability.
</p>
<p>If a final model with the optimal combination of tuning parameters is
computed, class <code>"perryTuning"</code> inherits the <code>coef()</code>,
<code>fitted()</code>, <code>predict()</code> and <code>residuals()</code> methods from
its component <code>finalModel</code>.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>References</h3>

<p>Hastie, T., Tibshirani, R. and Friedman, J. (2009) <em>The Elements of
Statistical Learning: Data Mining, Inference, and Prediction</em>.  Springer,
2nd edition.
</p>


<h3>See Also</h3>

<p><code>perryFit</code>, <code>perrySelect</code>,
<code>cvFolds</code>, <code>randomSplits</code>,
<code>bootSamples</code>, <code>cost</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">library("perryExamples")
data("coleman")

## evaluate MM regression models tuned for 85% and 95% efficiency
tuning &lt;- list(tuning.psi = c(3.443689, 4.685061))

## via model fitting function
# perform cross-validation
# note that the response is extracted from 'data' in
# this example and does not have to be supplied
perryTuning(lmrob, formula = Y ~ ., data = coleman,
            tuning = tuning, splits = foldControl(K = 5, R = 10),
            cost = rtmspe, costArgs = list(trim = 0.1), seed = 1234)

## via function call
# set up function call
call &lt;- call("lmrob", formula = Y ~ .)
# perform cross-validation
perryTuning(call, data = coleman, y = coleman$Y,
            tuning = tuning, splits = foldControl(K = 5, R = 10),
            cost = rtmspe, costArgs = list(trim = 0.1), seed = 1234)
</code></pre>


</div>