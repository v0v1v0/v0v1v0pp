<div class="container">

<table style="width: 100%;"><tr>
<td>selectPLMIX</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Bayesian selection criteria for mixtures of Plackett-Luce models</h2>

<h3>Description</h3>

<p>Compute Bayesian comparison criteria for mixtures of Plackett-Luce models with a different number of components.
</p>


<h3>Usage</h3>

<pre><code class="language-R">selectPLMIX(pi_inv, seq_G, MCMCsampleP = vector(mode = "list", length =
  length(seq_G)), MCMCsampleW = vector(mode = "list", length =
  length(seq_G)), MAPestP, MAPestW, deviance, post_est = "mean",
  parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>pi_inv</code></td>
<td>
<p>An object of class <code>top_ordering</code>, collecting the numeric <code class="reqn">N</code><code class="reqn">\times</code><code class="reqn">K</code> data matrix of partial orderings, or an object that can be coerced with <code>as.top_ordering</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seq_G</code></td>
<td>
<p>Numeric vector with the number of components of the Plackett-Luce mixtures to be compared.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MCMCsampleP</code></td>
<td>
<p>List of size <code>length(seq_G)</code>, whose generic element is a numeric <code class="reqn">L</code><code class="reqn">\times</code><code class="reqn">(G*K)</code> matrix with the MCMC samples of the component-specific support parameters. Default is list of <code>NULL</code> elements.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MCMCsampleW</code></td>
<td>
<p>List of size <code>length(seq_G)</code>, whose generic element is a numeric <code class="reqn">L</code><code class="reqn">\times</code><code class="reqn">G</code> matrix with the MCMC samples of the mixture weights. Default is list of <code>NULL</code> elements.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MAPestP</code></td>
<td>
<p>List of size <code>length(seq_G)</code>, whose generic element is a numeric <code class="reqn">G</code><code class="reqn">\times</code><code class="reqn">K</code> matrix with the MAP estimates of the component-specific support parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MAPestW</code></td>
<td>
<p>List of size <code>length(seq_G)</code>, whose generic element is a numeric vector with the MAP estimates of the <code class="reqn">G</code> mixture weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>deviance</code></td>
<td>
<p>List of size <code>length(seq_G)</code>, whose generic element is a numeric vector of posterior deviance values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>post_est</code></td>
<td>
<p>Character string indicating the  point estimates of the Plackett-Luce mixture parameters to be computed from the MCMC sample. This argument is ignored when MAP estimates are supplied in the <code>MAPestP</code> and <code>MAPestW</code> arguments. Default is <code>"mean"</code>. Alternatively, one can choose <code>"median"</code> (see 'Details').</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>
<p>Logical: whether parallelization should be used. Default is <code>FALSE</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The <code>selectPLMIX</code> function privileges the use of the MAP point estimates to compute the Bayesian model comparison criteria, since they are not affected by the label switching issue. By setting both the <code>MAPestP</code> and <code>MAPestW</code> arguments equal to NULL, the user can alternatively compute the selection measures by relying on a different posterior summary (<code>"mean"</code> or <code>"median"</code>) specified in the <code>post_est</code> argument. In the latter case, the MCMC samples for each Plackett-Luce mixture must be supplied in the lists <code>MCMCsampleP</code> and <code>MCMCsampleW</code>. The drawback when working with point estimates other than the MAP is that the possible presence of label switching has to be previously removed from the traces to obtain meaningful results. See the <code>label_switchPLMIX</code> function to perfom label switching adjustment of the MCMC samples.
</p>
<p>Several model selection criteria are returned. The two versions of DIC correspond to alternative ways of computing the effective number of parameters: DIC1 was proposed by Spiegelhalter et al. (2002) with penalty named <code>pD</code>, whereas DIC2 was proposed by Gelman et al. (2004) with penalty named <code>pV</code>. The latter coincides with the AICM introduced by Raftery et al. (2007), that is, the Bayesian counterpart of AIC. BPIC1 and BPIC2 are obtained from the two DIC by simply doubling the penalty term, as suggested by Ando (2007) to contrast DIC's tendency to overfitting. BICM1 is the Bayesian variant of the BIC, originally presented by Raftery et al. (2007) and entirely based on the MCMC sample. The BICM2, instead, involved the MAP estimate without the need of its approximation from the MCMC sample as for the BICM1.
</p>


<h3>Value</h3>

<p>A list of named objects:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>point_estP</code></td>
<td>
<p> List of size <code>length(seq_G)</code>, whose generic element is a numeric <code class="reqn">G</code><code class="reqn">\times</code><code class="reqn">K</code> matrix with the point estimates of the component-specific support parameters employed for the computation of the criteria.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>point_estW</code></td>
<td>
<p> List of size <code>length(seq_G)</code>, whose generic element is a numeric vector with the <code class="reqn">G</code> point estimates of the mixture weights employed for the computation of the criteria.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitting</code></td>
<td>
<p> Numeric <code>length(seq_G)</code><code class="reqn">\times</code><code class="reqn">2</code> matrix with the fitting terms of the comparison measures, given by the posterior expected deviance <code>D_bar</code> and the deviance <code>D_hat</code> evaluated at the point estimate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalties</code></td>
<td>
<p> Numeric <code>length(seq_G)</code><code class="reqn">\times</code><code class="reqn">2</code> matrix with the penalty terms <code>pD</code> and <code>pV</code> (effective number of parameters).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>criteria</code></td>
<td>
<p> Numeric <code>length(seq_G)</code><code class="reqn">\times</code><code class="reqn">6</code> matrix of Bayesian model selection criteria: <code>DIC1</code>, <code>DIC2</code>, <code>BPIC1</code>, <code>BPIC2</code>, <code>BICM1</code> and <code>BICM2</code> (see 'Details').</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Cristina Mollica and Luca Tardella
</p>


<h3>References</h3>

<p>Mollica, C. and Tardella, L. (2017). Bayesian Plackett-Luce mixture models for partially ranked data. <em>Psychometrika</em>, <b>82</b>(2), pages 442–458, ISSN: 0033-3123, DOI: 10.1007/s11336-016-9530-0.
</p>
<p>Ando, T. (2007). Bayesian predictive information criterion for the evaluation of hierarchical Bayesian and empirical Bayes models. <em>Biometrika</em>, <b>94</b>(2), pages 443–458.
</p>
<p>Raftery, A. E, Satagopan, J. M., Newton M. A. and Krivitsky, P. N. (2007). BAYESIAN STATISTICS 8. <em>Proceedings of the eighth Valencia International Meeting 2006</em>, pages 371–416. Oxford University Press.
</p>
<p>Gelman, A., Carlin, J. B., Stern, H. S. and Rubin, D. B. (2004). Bayesian data analysis. Chapman &amp; Hall/CRC, Second Edition, ISBN: 1-58488-388-X. New York.
</p>
<p>Spiegelhalter, D. J., Best, N. G., Carlin, B. P. and Van Der Linde, A. (2002). Bayesian measures of model complexity and fit. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>64</b>(4), pages 583–639.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(d_carconf)
K &lt;- ncol(d_carconf)

## Fit 1- and 2-component PL mixtures via MAP estimation 
MAP_1 &lt;- mapPLMIX_multistart(pi_inv=d_carconf, K=K, G=1, 
                                   n_start=2, n_iter=400*1)

MAP_2 &lt;- mapPLMIX_multistart(pi_inv=d_carconf, K=K, G=2, 
                                   n_start=2, n_iter=400*2)

mcmc_iter &lt;- 30
burnin &lt;- 10

## Fit 1- and 2-component PL mixtures via Gibbs sampling procedure
GIBBS_1 &lt;- gibbsPLMIX(pi_inv=d_carconf, K=K, G=1, n_iter=mcmc_iter, 
                      n_burn=burnin, init=list(p=MAP_1$mod$P_map,
                      z=binary_group_ind(MAP_1$mod$class_map,G=1)))
GIBBS_2 &lt;- gibbsPLMIX(pi_inv=d_carconf, K=K, G=2, n_iter=mcmc_iter, 
                      n_burn=burnin, init=list(p=MAP_2$mod$P_map,
                      z=binary_group_ind(MAP_2$mod$class_map,G=2)))
## Select the optimal number of components 
SELECT &lt;- selectPLMIX(pi_inv=d_carconf, seq_G=1:2, 
                      MAPestP=list(MAP_1$mod$P_map, MAP_2$mod$P_map), 
                      MAPestW=list(MAP_1$mod$W_map, MAP_2$mod$W_map), 
                      deviance=list(GIBBS_1$deviance, GIBBS_2$deviance))
SELECT$criteria

</code></pre>


</div>