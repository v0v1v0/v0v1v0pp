<div class="container">

<table style="width: 100%;"><tr>
<td>details_logistic_reg_gee</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Logistic regression via generalized estimating equations (GEE)</h2>

<h3>Description</h3>

<p><code>gee::gee()</code> uses generalized least squares to fit different types of models
with errors that are not independent.
</p>


<h3>Details</h3>

<p>For this engine, there is a single mode: classification
</p>


<h4>Tuning Parameters</h4>

<p>This model has no formal tuning parameters. It may be beneficial to
determine the appropriate correlation structure to use, but this
typically does not affect the predicted value of the model. It <em>does</em>
have an effect on the inferential results and parameter covariance
values.
</p>



<h4>Translation from parsnip to the original package</h4>

<p>The <strong>multilevelmod</strong> extension package is required to fit this model.
</p>
<div class="sourceCode r"><pre>library(multilevelmod)

logistic_reg() %&gt;% 
  set_engine("gee") %&gt;% 
  translate()
</pre></div>
<div class="sourceCode"><pre>## Logistic Regression Model Specification (classification)
## 
## Computational engine: gee 
## 
## Model fit template:
## multilevelmod::gee_fit(formula = missing_arg(), data = missing_arg(), 
##     family = binomial)
</pre></div>
<p><code>multilevelmod::gee_fit()</code> is a wrapper model around <code>gee::gee()</code>.
</p>



<h4>Preprocessing requirements</h4>

<p>There are no specific preprocessing needs. However, it is helpful to
keep the clustering/subject identifier column as factor or character
(instead of making them into dummy variables). See the examples in the
next section.
</p>



<h4>Other details</h4>

<p>The model cannot accept case weights.
</p>
<p>Both <code>gee:gee()</code> and <code>gee:geepack()</code> specify the id/cluster variable
using an argument <code>id</code> that requires a vector. parsnip doesn’t work that
way so we enable this model to be fit using a artificial function
<code>id_var()</code> to be used in the formula. So, in the original package, the
call would look like:
</p>
<div class="sourceCode r"><pre>gee(breaks ~ tension, id = wool, data = warpbreaks, corstr = "exchangeable")
</pre></div>
<p>With <code>parsnip</code>, we suggest using the formula method when fitting:
</p>
<div class="sourceCode r"><pre>library(tidymodels)
data("toenail", package = "HSAUR3")

logistic_reg() %&gt;% 
  set_engine("gee", corstr = "exchangeable") %&gt;% 
  fit(outcome ~ treatment * visit + id_var(patientID), data = toenail)
</pre></div>
<p>When using tidymodels infrastructure, it may be better to use a
workflow. In this case, you can add the appropriate columns using
<code>add_variables()</code> then supply the GEE formula when adding the model:
</p>
<div class="sourceCode r"><pre>library(tidymodels)

gee_spec &lt;- 
  logistic_reg() %&gt;% 
  set_engine("gee", corstr = "exchangeable")

gee_wflow &lt;- 
  workflow() %&gt;% 
  # The data are included as-is using:
  add_variables(outcomes = outcome, predictors = c(treatment, visit, patientID)) %&gt;% 
  add_model(gee_spec, formula = outcome ~ treatment * visit + id_var(patientID))

fit(gee_wflow, data = toenail)
</pre></div>
<p>The <code>gee::gee()</code> function always prints out warnings and output even
when <code>silent = TRUE</code>. The parsnip <code>"gee"</code> engine, by contrast, silences
all console output coming from <code>gee::gee()</code>, even if <code>silent = FALSE</code>.
</p>
<p>Also, because of issues with the <code>gee()</code> function, a supplementary call
to <code>glm()</code> is needed to get the rank and QR decomposition objects so
that <code>predict()</code> can be used.
</p>



<h4>Case weights</h4>

<p>The underlying model implementation does not allow for case weights.
</p>



<h4>References</h4>


<ul>
<li>
<p> Liang, K.Y. and Zeger, S.L. (1986) Longitudinal data analysis using
generalized linear models. <em>Biometrika</em>, 73 13–22.
</p>
</li>
<li>
<p> Zeger, S.L. and Liang, K.Y. (1986) Longitudinal data analysis for
discrete and continuous outcomes. <em>Biometrics</em>, 42 121–130.
</p>
</li>
</ul>
</div>