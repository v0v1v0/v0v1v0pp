<div class="container">

<table style="width: 100%;"><tr>
<td>p_ndfa</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Normal Discriminant Function Approach for Estimating Odds Ratio with Exposure
Measured in Pools and Potentially Subject to Additive Normal Errors</h2>

<h3>Description</h3>

<p>Assumes exposure given covariates and outcome is a normal-errors linear
regression. Pooled exposure measurements can be assumed precise or subject to
additive normal processing error and/or measurement error. Parameters are
estimated using maximum likelihood.
</p>


<h3>Usage</h3>

<pre><code class="language-R">p_ndfa(g, y, xtilde, c = NULL, constant_or = TRUE,
  errors = "processing", start_nonvar_var = c(0.01, 1),
  lower_nonvar_var = c(-Inf, 1e-04), upper_nonvar_var = c(Inf, Inf),
  jitter_start = 0.01, nlminb_list = list(control = list(trace = 1,
  eval.max = 500, iter.max = 500)), hessian_list = list(method.args =
  list(r = 4)), nlminb_object = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>g</code></td>
<td>
<p>Numeric vector of pool sizes, i.e. number of members in each pool.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Numeric vector of poolwise Y values (number of cases in each pool).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xtilde</code></td>
<td>
<p>Numeric vector (or list of numeric vectors, if some pools have
replicates) with Xtilde values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>c</code></td>
<td>
<p>Numeric matrix with poolwise <strong>C</strong> values (if any), with one
row for each pool. Can be a vector if there is only 1 covariate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>constant_or</code></td>
<td>
<p>Logical value for whether to assume a constant odds ratio
for X, which means that sigsq_1 = sigsq_0. If <code>NULL</code>, model is fit with
and without this assumption, and a likelihood ratio test is performed to test
it.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>errors</code></td>
<td>
<p>Character string specifying the errors that X is subject to.
Choices are <code>"neither"</code>, <code>"processing"</code> for processing error only,
<code>"measurement"</code> for measurement error only, and <code>"both"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start_nonvar_var</code></td>
<td>
<p>Numeric vector of length 2 specifying starting value
for non-variance terms and variance terms, respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower_nonvar_var</code></td>
<td>
<p>Numeric vector of length 2 specifying lower bound for
non-variance terms and variance terms, respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>upper_nonvar_var</code></td>
<td>
<p>Numeric vector of length 2 specifying upper bound for
non-variance terms and variance terms, respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>jitter_start</code></td>
<td>
<p>Numeric value specifying standard deviation for mean-0
normal jitters to add to starting values for a second try at maximizing the
log-likelihood, should the initial call to <code>nlminb</code> result
in non-convergence. Set to <code>NULL</code> for no second try.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlminb_list</code></td>
<td>
<p>List of arguments to pass to <code>nlminb</code>
for log-likelihood maximization.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hessian_list</code></td>
<td>
<p>List of arguments to pass to
<code>hessian</code> for approximating the Hessian matrix. Only
used if <code>estimate_var = TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlminb_object</code></td>
<td>
<p>Object returned from <code>nlminb</code> in a
prior call. Useful for bypassing log-likelihood maximization if you just want
to re-estimate the Hessian matrix with different options.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>List containing:
</p>

<ol>
<li>
<p> Numeric vector of parameter estimates.
</p>
</li>
<li>
<p> Variance-covariance matrix.
</p>
</li>
<li>
<p> Returned <code>nlminb</code> object from maximizing the
log-likelihood function.
</p>
</li>
<li>
<p> Akaike information criterion (AIC).
</p>
</li>
</ol>
<p>If <code>constant_or = NULL</code>, two such lists are returned (one under a
constant odds ratio assumption and one not), along with a likelihood ratio
test for <code>H0: sigsq_1 = sigsq_0</code>, which is equivalent to
<code>H0: odds ratio is constant</code>.
</p>


<h3>References</h3>

<p>Lyles, R.H., Van Domelen, D.R., Mitchell, E.M. and Schisterman, E.F. (2015)
"A discriminant function approach to adjust for processing and measurement
error When a biomarker is assayed in pooled samples."
<em>Int. J. Environ. Res. Public Health</em> <strong>12</strong>(11): 14723–14740.
</p>
<p>Schisterman, E.F., Vexler, A., Mumford, S.L. and Perkins, N.J. (2010) "Hybrid
pooled-unpooled design for cost-efficient measurement of biomarkers."
<em>Stat. Med.</em> <strong>29</strong>(5): 597–613.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Load data frame with (g, Y, X, Xtilde, C) values for 4,996 pools and list
# of Xtilde values where 25 subjects have replicates. Xtilde values are
# affected by processing error and measurement error. True log-OR = 0.5,
# sigsq = 1, sigsq_p = 0.5, sigsq_m = 0.1.
data(dat_p_ndfa)
dat &lt;- dat_p_ndfa$dat
reps &lt;- dat_p_ndfa$reps

# Unobservable truth estimator - use precise X's
fit.unobservable &lt;- p_ndfa(
  g = dat$g,
  y = dat$numcases,
  xtilde = dat$x,
  c = dat$c,
  errors = "neither"
)
fit.unobservable$estimates

# Naive estimator - use imprecise Xtilde's, but treat as precise
fit.naive &lt;- p_ndfa(
  g = dat$g,
  y = dat$numcases,
  xtilde = dat$xtilde,
  c = dat$c,
  errors = "neither"
)
fit.naive$estimates

# Corrected estimator - use Xtilde's and account for errors (not using
# replicates here)
## Not run: 
fit.noreps &lt;- p_ndfa(
  g = dat$g,
  y = dat$numcases,
  xtilde = dat$xtilde,
  c = dat$c,
  errors = "both"
)
fit.noreps$estimates

# Corrected estimator - use Xtilde's including 25 replicates
fit.reps &lt;- p_ndfa(
  g = dat$g,
  y = dat$numcases,
  xtilde = reps,
  c = dat$c,
  errors = "both"
)
fit.reps$estimates

# Same as previous, but allowing for non-constant odds ratio.
fit.nonconstant &lt;- p_ndfa(
  g = dat$g,
  y = dat$numcases,
  xtilde = reps,
  c = dat$c,
  constant_or = FALSE,
  errors = "both"
)
fit.nonconstant$estimates

# Visualize estimated log-OR vs. X based on previous model fit
p &lt;- plot_ndfa(
  estimates = fit.nonconstant$estimates,
  varcov = fit.nonconstant$theta.var,
  xrange = range(dat$xtilde[dat$g == 1]),
  cvals = mean(dat$c / dat$g)
)
p

# Likelihood ratio test for H0: odds ratio is constant.
test.constantOR &lt;- p_ndfa(
  g = dat$g,
  y = dat$numcases,
  xtilde = reps,
  c = dat$c,
  constant_or = NULL,
  errors = "both"
)
test.constantOR$lrt

## End(Not run)


</code></pre>


</div>