<div class="container">

<table style="width: 100%;"><tr>
<td>POMDP_example_files</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>POMDP Example Files</h2>

<h3>Description</h3>

<p>Some POMDP example files are shipped with the package.
</p>


<h3>Details</h3>

<p>Currently, the following POMDP example files are available:
</p>

<ul>
<li> <p><code>"light_maze.POMDP"</code>: a simple maze introduced in Littman (2009).
</p>
</li>
<li> <p><code>"shuttle_95.POMDP"</code>: Transport goods between two space
stations (Chrisman, 1992).
</p>
</li>
<li> <p><code>"tiger_aaai.POMDP"</code>: Tiger Problem introduced in Cassandra et al (1994).
</p>
</li>
</ul>
<p>More files can be found at https://www.pomdp.org/examples/
</p>


<h3>References</h3>

<p>Anthony R. Cassandra, Leslie P Kaelbling, and Michael L. Littman (1994).
Acting Optimally in Partially Observable Stochastic Domains.
<em>In Proceedings of the Twelfth National Conference on Artificial
Intelligence,</em> pp. 1023-1028.
</p>
<p>Lonnie Chrisman (1992), Reinforcement Learning with Perceptual Aliasing: The
<em>Proceedings of the AAAI Conference on Artificial Intelligence,</em>
10, AAAI-92.
</p>
<p>Michael L. Littman (2009), A tutorial on partially observable Markov decision processes,
<em>Journal of Mathematical Psychology,</em> Volume 53, Issue 3, June 2009, Pages 119-125.
<a href="https://doi.org/10.1016/j.jmp.2009.01.005">doi:10.1016/j.jmp.2009.01.005</a>
</p>


<h3>See Also</h3>

<p>Other POMDP_examples: 
<code>POMDP()</code>,
<code>RussianTiger</code>,
<code>Tiger</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">dir(system.file("examples/", package = "pomdp"))

model &lt;- read_POMDP(system.file("examples/light_maze.POMDP", 
  package = "pomdp"))
model
</code></pre>


</div>