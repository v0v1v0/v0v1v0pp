<div class="container">

<table style="width: 100%;"><tr>
<td>plsdof-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Degrees of Freedom and Statistical Inference for Partial Least Squares
Regression</h2>

<h3>Description</h3>

<p>The plsdof package provides Degrees of Freedom estimates for Partial Least
Squares (PLS) Regression.
</p>


<h3>Details</h3>

<p>Model selection for PLS is based on various information criteria (aic, bic,
gmdl) or on cross-validation. Estimates for the mean and covariance of the
PLS regression coefficients are available. They allow the construction of
approximate confidence intervals and the application of test procedures.
</p>
<p>Further, cross-validation procedures for Ridge Regression and Principal
Components Regression are available.
</p>

<table>
<tr>
<td style="text-align: left;"> Package: </td>
<td style="text-align: left;"> plsdof</td>
</tr>
<tr>
<td style="text-align: left;"> Type: </td>
<td style="text-align: left;"> Package</td>
</tr>
<tr>
<td style="text-align: left;"> Version: </td>
<td style="text-align: left;">
0.2-9</td>
</tr>
<tr>
<td style="text-align: left;"> Date: </td>
<td style="text-align: left;"> 2019-31-01</td>
</tr>
<tr>
<td style="text-align: left;"> License: </td>
<td style="text-align: left;"> GPL (&gt;=2)</td>
</tr>
<tr>
<td style="text-align: left;"> LazyLoad: </td>
<td style="text-align: left;">
yes</td>
</tr>
<tr>
<td style="text-align: left;"> </td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Nicole Kraemer, Mikio L. Braun
</p>
<p>Maintainer: Frederic Bertrand &lt;frederic.bertrand@utt.fr.fr&gt;
</p>


<h3>References</h3>

<p>Kraemer, N., Sugiyama M. (2011). "The Degrees of Freedom of Partial Least
Squares Regression". Journal of the American Statistical Association 106
(494) <a href="https://www.tandfonline.com/doi/abs/10.1198/jasa.2011.tm10107">https://www.tandfonline.com/doi/abs/10.1198/jasa.2011.tm10107</a>
</p>
<p>Kraemer, N., Braun, M.L. (2007) "Kernelizing PLS, Degrees of Freedom, and
Efficient Model Selection", Proceedings of the 24th International Conference
on Machine Learning, Omni Press, 441 - 448
</p>


<h3>See Also</h3>

<p><code>pls.model</code>, <code>pls.cv</code>, <code>pls.ic</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# Boston Housing data
data(Boston)
X&lt;-as.matrix(Boston[,-14])
y&lt;-as.vector(Boston[,14])

# compute PLS coefficients for the first 5 components and plot Degrees of Freedom

my.pls1&lt;-pls.model(X,y,m=5,compute.DoF=TRUE)

plot(0:5,my.pls1$DoF,pch="*",cex=3,xlab="components",ylab="DoF",ylim=c(0,14))

# add naive estimate
lines(0:5,1:6,lwd=3)

# model selection with the Bayesian Information criterion

mypls2&lt;-pls.ic(X,y,criterion="bic")

# model selection based on cross-validation. 
# returns the estimated covariance matrix of the regression coefficients

mypls3&lt;-pls.cv(X,y,compute.covariance=TRUE)
my.vcov&lt;-vcov(mypls3)
my.sd&lt;-sqrt(diag(my.vcov)) # standard deviation of the regression coefficients


</code></pre>


</div>