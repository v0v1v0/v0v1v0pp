<div class="container">

<table style="width: 100%;"><tr>
<td>GPois</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Fit a tilted Gaussian density via a Poisson GAM</h2>

<h3>Description</h3>

<p>This is a contrast method for <code>ProDenICA</code>. It fits a tilted
Gaussian density estimate by multiplying the Gaussian density by an
exponential tilt function using a cubic smoothing spline
</p>


<h3>Usage</h3>

<pre><code class="language-R">GPois(x, df = 6, B = 500, order = 1, widen = 1.2, density.return = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>vector of real values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>degrees of freedom for the smoothing-spline fit; default is 6</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>
<p>number of grid points for density estimate; default is 500</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>order</code></td>
<td>
<p>A robustness parameter to avoid responding to outliers in
<code>x</code>. The range of <code>x</code> is estimated by the  <code>order</code>th
and <code>n-order+1</code>th order statistics. Default is <code>order=1</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>widen</code></td>
<td>
<p>an expansion factor to widen the range of <code>x</code>;
default is <code>widen=1.2</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>density.return</code></td>
<td>
<p>logical variable, with default <code>FALSE</code>. If
<code>density.return=TRUE</code>, the estimated density is returned</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments to GAM;  typically not used</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>See Section 14.7.4
of 'Elements of Statistical Learning (Hastie, Tibshirani and Friedman,
2009, 2nd Edition)' for details</p>


<h3>Value</h3>

<p>a list with components
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Gs</code></td>
<td>
<p>estimated contrast function, which is the log of the tilting
function, evaluated at the original values of <code>x</code>. <code>mean(Gs)</code>
is measure of negentropy</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gs</code></td>
<td>
<p>estimated first derivative of <code>Gs</code> at <code>x</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gps</code></td>
<td>
<p>estimated second derivative of <code>Gs</code> at <code>x</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>density</code></td>
<td>
<p>if <code>density.return=TRUE</code>, a list with components
<code>$x</code> the grid of B values of <code>x</code>, and <code>$y</code> the estimated
density.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Trevor Hastie and Rob Tibshirani
</p>


<h3>References</h3>

<p>Hastie, T. and Tibshirani, R. (2003) <em>Independent Component Analysis
through Product Density Estimation</em> in <em>Advances in Neural Information
Processing Systems 15</em> (Becker, S. and Obermayer, K., eds), MIT Press,
Cambridge, MA. pp 649-656<br>
Hastie, T., Tibshirani, R. and Friedman, J. (2009) Elements of
Statistical Learning (2nd edition), Springer.<br><a href="https://hastie.su.domains/ElemStatLearn/printings/ESLII_print12_toc.pdf">https://hastie.su.domains/ElemStatLearn/printings/ESLII_print12_toc.pdf</a>
</p>


<h3>See Also</h3>

<p><code>ProDenICA</code>, <code>G1</code> and <code>G0</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">p=2
### Can use letters a-r below for dist
dist="n" 
N=1024
A0&lt;-mixmat(p)
s&lt;-scale(cbind(rjordan(dist,N),rjordan(dist,N)))
x &lt;- s %*% A0
fit=ProDenICA(x,Gfunc=GPois, whiten=TRUE, density=TRUE)
par(mfrow=c(2,1))
plot(fit)
</code></pre>


</div>