<div class="container">

<table style="width: 100%;"><tr>
<td>signifDiffs</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Obtains a list with the set of paired differences that are statistically
significant according to a p-value threshold
</h2>

<h3>Description</h3>

<p>This function receives as main argument the object resulting from a
call to the <code>pairedComparisons</code> function and produces a
list with the subset of the paired comparisons using the <em>t</em> test and
the <em>Wilcoxon Signed Rank</em> test that are statistically
significant given a certain <em>p</em> value limit.
</p>


<h3>Usage</h3>

<pre><code class="language-R">signifDiffs(ps, p.limit=0.05,
            metrics=names(ps),
            tasks=rownames(ps[[1]]$avgScores))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>ps</code></td>
<td>

<p>An object resulting from a call to the
<code>pairedComparisons</code> function. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.limit</code></td>
<td>

<p>A number indicating the maximum value of the confidence level
(p.value) of the statistical hypothesis test for a paired comparison
to be considered statistically significant (defaults to 0.05). All
paired comparisons with a <em>p</em> value below this limit will
appear in the results of this function.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metrics</code></td>
<td>

<p>A vector with the names of the metrics for which we want the results
(defaults to all metrics included in the paired comparison).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tasks</code></td>
<td>

<p>A vector with the names of the prediction tasks for which we want the results
(defaults to all tasks included in the paired comparison).
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function produces a list with as many components as the selected
metrics (defaulting to all metrics in the paired comparison). Each of
the components is another list with two components: i) one with the
results for the <em>t</em> tests; and ii) the other with the results for
the <em>Wilcoxon Signed Rank</em> test. Each of these two components is
an array with 3 dimensions, with the rows representing the workflows,
the columns a set of statistics and the thrid dimension being the
task. The first row of these arrays will contain the baseline workflow
against which all others are being compared (by either the <em>t</em>
test or through the <em>Wilcoxon Signed Rank</em> test). The remaining
rows will include the workflows whose comparison against this baseline
is statistically significant, i.e. whose <em>p</em> value of the paired
comparison is below the provided <em>p</em> limit.
</p>


<h3>Value</h3>

<p>The result of this function is a list (see the Details section).
</p>


<h3>Author(s)</h3>

<p> Luis Torgo <a href="mailto:ltorgo@dcc.fc.up.pt">ltorgo@dcc.fc.up.pt</a> </p>


<h3>References</h3>

<p> Torgo, L. (2014) <em>An Infra-Structure for Performance
Estimation and Experimental Comparison of Predictive Models in R</em>. arXiv:1412.0436 [cs.MS]
<a href="http://arxiv.org/abs/1412.0436">http://arxiv.org/abs/1412.0436</a>  
</p>


<h3>See Also</h3>

<p><code>pairedComparisons</code>,
<code>performanceEstimation</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
## Estimating MSE for 3 variants of both
## regression trees and SVMs, on  two data sets, using one repetition
## of 10-fold CV
library(e1071)
data(iris)
data(Satellite,package="mlbench")
data(LetterRecognition,package="mlbench")


## running the estimation experiment
res &lt;- performanceEstimation(
           c(PredTask(Species ~ .,iris),
             PredTask(classes ~ .,Satellite,"sat"),
             PredTask(lettr ~ .,LetterRecognition,"letter")),
           workflowVariants(learner="svm",
                 learner.pars=list(cost=1:4,gamma=c(0.1,0.01))),
           EstimationTask(metrics=c("err","acc"),method=CV()))

## now let us assume that we will choose "svm.v2" as our baseline
## carry out the paired comparisons
pres &lt;- pairedComparisons(res,"svm.v2")

## Obtaining the subset of differences that are significant
## with 99% confidence 
sds &lt;- signifDiffs(res,p.limit=0.01)


## End(Not run)
</code></pre>


</div>