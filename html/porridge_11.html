<div class="container">

<table style="width: 100%;"><tr>
<td>optPenaltyPrepEdiag.kCVauto</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Automatic search for optimal penalty parameters (for precision estimation of data with replicates).
</h2>

<h3>Description</h3>

<p>Function that performs an automatic search of the optimal penalty parameter for the <code>ridgePrepEdiag</code> call by employing either the Nelder-Mead or quasi-Newton 
method to calculate of the cross-validated (negative) log-likelihood score.
</p>


<h3>Usage</h3>

<pre><code class="language-R">optPenaltyPrepEdiag.kCVauto(Y, ids, lambdaInit, 
                            fold=nrow(Y), CVcrit, 
                            splitting="stratified",
                            targetZ=matrix(0, ncol(Y), ncol(Y)),
                            nInit=100, minSuccDiff=10^(-10))

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p> Data <code>matrix</code> with samples (including the repetitions) as rows and variates as columns. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ids</code></td>
<td>
<p> A <code>numeric</code> indicating which rows of <code>Y</code> belong to the same individal.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambdaInit</code></td>
<td>
<p> A <code>numeric</code> giving the initial (starting) values for the two penalty parameters. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fold</code></td>
<td>
<p> A <code>numeric</code> or <code>integer</code> specifying the number of folds to apply in the cross-validation. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>CVcrit</code></td>
<td>
<p> A <code>character</code> with the cross-validation criterion to applied. Either <code>CVcrit="LL"</code> (the loglikelihood) or <code>CVcrit="Qloss"</code> (the quadratic loss). </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>splitting</code></td>
<td>
<p> A <code>character</code>, either <code>splitting="replications"</code>, <code>splitting="samples"</code>, or <code>splitting="stratified"</code>, specifying either how the splits are to be formed: either  replications or samples are randomly divided over the <code>fold</code> splits (first two options, respectively), or samples are randomly divided over the <code>fold</code> splits but in stratified manner such that the total number of replications in each group is roughly comparable. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>targetZ</code></td>
<td>
<p> A semi-positive definite target <code>matrix</code> towards which the signal precision matrix estimate is shrunken. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nInit</code></td>
<td>
<p> A <code>numeric</code> specifying the number of iterations. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minSuccDiff</code></td>
<td>
<p> A <code>numeric</code>: minimum successive difference (in terms of the relative change in the absolute difference of the penalized loglikelihood) between two succesive estimates to be achieved. </p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The function returns an all-positive <code>numeric</code>, the cross-validated optimal penalty parameters.
</p>


<h3>Author(s)</h3>

<p>W.N. van Wieringen.
</p>


<h3>References</h3>

<p>van Wieringen, W.N., Chen, Y. (2021), "Penalized estimation of the Gaussian graphical model from data with replicates", <em>Statistics in Medicine</em>, 40(19), 4279-4293.
</p>


<h3>See Also</h3>

<p><code>ridgePrepEdiag</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># set parameters
p        &lt;- 10
Se       &lt;- diag(runif(p))
Sz       &lt;- matrix(3, p, p)
diag(Sz) &lt;- 4

# draw data
n &lt;- 100
ids &lt;- numeric()
Y   &lt;- numeric()
for (i in 1:n){
     Ki &lt;- sample(2:5, 1)
     Zi &lt;- mvtnorm::rmvnorm(1, sigma=Sz)
     for (k in 1:Ki){
          Y   &lt;- rbind(Y, Zi + mvtnorm::rmvnorm(1, sigma=Se))
          ids &lt;- c(ids, i)
     }
}

# find optimal penalty parameters
### optLambdas &lt;- optPenaltyPrepEdiag.kCVauto(Y, ids,             
###                                           lambdaInit=c(1,1),  
###                                           fold=nrow(Y),       
###                                           CVcrit="LL")        

# estimate the precision matrices
### Ps &lt;- ridgePrepEdiag(Y, ids, optLambdas[1], optLambdas[2])    
</code></pre>


</div>