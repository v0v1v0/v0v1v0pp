<div class="container">

<table style="width: 100%;"><tr>
<td>pdist</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Compute probabilistic divergence between two PST
</h2>

<h3>Description</h3>

<p>Compute probabilistic divergence between two PST
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S4 method for signature 'PSTf,PSTf'
pdist(x,y, method="cp", l, ns=5000, symetric=FALSE, output="all")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>a probabilistic suffix tree, i.e., an object of class <code>"PSTf"</code> as returned by the <code>pstree</code>, <code>prune</code> or <code>tune</code> function.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>a probabilistic suffix tree, i.e., an object of class <code>"PSTf"</code> as returned by the <code>pstree</code>, <code>prune</code> or <code>tune</code> function.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<p>character. Method for computing distances. So far only one method is available.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>l</code></td>
<td>

<p>integer. Length of the sequence(s) to generate.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ns</code></td>
<td>

<p>integer. Number sequences to generate.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>symetric</code></td>
<td>

<p>logical. If <code>TRUE</code>, the symetric version of the measure is returned, see details.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output</code></td>
<td>

<p>character. See <code>value</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function computes a probabilistic divergence measure between PST <code class="reqn">S_{A}</code> and <code class="reqn">S_{B}</code> based on the measure originally proposed in <cite>Juang-1985</cite> and <cite>Rabiner-1989</cite> for the comparison of two (hidden) Markov models <code class="reqn">S_{A}</code> and <code class="reqn">S_{B}</code>
</p>
<p style="text-align: center;"><code class="reqn">
d(S_{A}, S_{B})=\frac{1}{\ell} [\log P^{S_{A}}(x)-\log P^{S_{B}}(x)]=\frac{1}{\ell}\log \frac{P^{S_{A}}(x)}{P^{S_{B}}(x)}
</code>
</p>

<p>where <code class="reqn">x=x_{1}, \ldots, x_{\ell}</code> is a sequence generated by model <code class="reqn">S_{A}</code>, <code class="reqn">P^{S_{A}}(x)</code> is the probability of <code class="reqn">x</code> given model <code class="reqn">S_{A}</code> and <code class="reqn">P^{S_{B}}(x)</code> is the probability of <code class="reqn">x</code> given model <code class="reqn">S_{B}</code>. The ratio between the two sequence likelihoods measures how many times the sequence <code class="reqn">x</code> is more likely to have been generated by <code class="reqn">S_{A}</code> than by <code class="reqn">S_{2}</code>. 
</p>
<p>As the number <code class="reqn">n</code> of generated sequences on which the measure is computed (or the length of a single sequence) approaches infinity, the expected value of <code class="reqn">d(S_{A}, S_{B})</code> converges to <code class="reqn">d_{KL}(S_{A}, S_{B})</code> <cite>Falkhausen-1995, He-2000</cite>, the Kullback-Leibler (KL) divergence (also called information gain) used in information theory to measure the difference between two probability distributions.
</p>
<p>The <code>pdist</code> function uses the following procedure to compute the divergence between two PST:
</p>

<ul>
<li>
<p> generate a ransom sample of <code class="reqn">n</code> sequences (of length <code class="reqn">\ell</code>) with model <code class="reqn">S_{A}</code> using the <code>generate</code> method
</p>
</li>
<li>
<p> predict the sequences with <code class="reqn">S_{A}</code> and with <code class="reqn">S_{B}</code>
</p>
</li>
<li>
<p> compute 
</p>
<p style="text-align: center;"><code class="reqn">
d_{i}(S_{A}, S_{B})=\frac{1}{\ell} [\log P^{S_{A}}(x_{i})-\log P^{S_{B}}(x_{i}))], \; i=1, \ldots, n
</code>
</p>

</li>
<li>
<p> the expected value 
</p>
<p style="text-align: center;"><code class="reqn">
E(d(S_{A}, S_{B}))
</code>
</p>

<p>is the divergence between models <code class="reqn">S_{A}</code> and <code class="reqn">S_{B}</code> and is estimated as 
</p>
<p style="text-align: center;"><code class="reqn">
\hat{E}(d(S_{A}, S_{B}))=\frac{1}{n} \sum_{i=1}^{n} d_{i}(S_{A}, S_{B})
</code>
</p>

</li>
</ul>
<p>For more details, see <cite>Gabadinho 2016</cite>.
</p>


<h3>Value</h3>

<p>If <code>ouput="all"</code>, a vector containing the divergence value for each generated sequence, if <code>output="mean"</code>, the mean, i.e. expected value which is the divergence between models.
</p>


<h3>Author(s)</h3>

<p>Alexis gabadinho
</p>


<h3>References</h3>

<p>Gabadinho, A. &amp; Ritschard, G. (2016). Analyzing State Sequences with Probabilistic Suffix Trees: The PST R Package. <em>Journal of Statistical Software</em>, <b>72</b>(3), pp. 1-39.
</p>
<p>Juang, B. H. and Rabiner, L. R. (1985). A probabilistic distance measure for hidden Markov models. <em>ATT Technical Journal</em>, <b>64</b>(2), pp. 391-408.
</p>
<p>Rabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speech recognition. <em>Proceedings of the IEEE</em>, <b>77</b>(2), pp. 257-286.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## activity calendar for year 2000
## from the Swiss Household Panel
## see ?actcal
data(actcal)

## selecting individuals aged 20 to 59
actcal &lt;- actcal[actcal$age00&gt;=20 &amp; actcal$age00 &lt;60,]

## defining a sequence object
actcal.lab &lt;- c("&gt; 37 hours", "19-36 hours", "1-18 hours", "no work")
actcal.seq &lt;- seqdef(actcal,13:24,labels=actcal.lab)

## building a PST segmented by age group
gage10 &lt;- cut(actcal$age00, c(20,30,40,50,60), right=FALSE,
	labels=c("20-29","30-39", "40-49", "50-59"))

actcal.pstg &lt;- pstree(actcal.seq, nmin=2, ymin=0.001, group=gage10)

## pruning
C99 &lt;- qchisq(0.99,4-1)/2
actcal.pstg.opt &lt;- prune(actcal.pstg, gain="G2", C=C99)

## extracting PST for age group 20-39 and 30-39
g1.pst &lt;- subtree(actcal.pstg.opt, group=1)
g2.pst &lt;- subtree(actcal.pstg.opt, group=2)

## generating 5000 sequences with g1.pst 
## and computing 5000 distances
dist.g1_g2 &lt;- pdist(g1.pst, g2.pst, l=11)
hist(dist.g1_g2)

## the probabilistic distance is the mean
## of the 5000 distances
mean(dist.g1_g2)
</code></pre>


</div>