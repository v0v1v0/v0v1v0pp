<div class="container">

<table style="width: 100%;"><tr>
<td>details_bag_tree_C5.0</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Bagged trees via C5.0</h2>

<h3>Description</h3>

<p><code>baguette::bagger()</code> creates an collection of decision trees forming an
ensemble. All trees in the ensemble are combined to produce a final prediction.
</p>


<h3>Details</h3>

<p>For this engine, there is a single mode: classification
</p>


<h4>Tuning Parameters</h4>

<p>This model has 1 tuning parameters:
</p>

<ul><li> <p><code>min_n</code>: Minimal Node Size (type: integer, default: 2L)
</p>
</li></ul>
<h4>Translation from parsnip to the original package (classification)</h4>

<p>The <strong>baguette</strong> extension package is required to fit this model.
</p>
<div class="sourceCode r"><pre>library(baguette)

bag_tree(min_n = integer()) %&gt;% 
  set_engine("C5.0") %&gt;% 
  set_mode("classification") %&gt;% 
  translate()
</pre></div>
<div class="sourceCode"><pre>## Bagged Decision Tree Model Specification (classification)
## 
## Main Arguments:
##   cost_complexity = 0
##   min_n = integer()
## 
## Computational engine: C5.0 
## 
## Model fit template:
## baguette::bagger(x = missing_arg(), y = missing_arg(), weights = missing_arg(), 
##     minCases = integer(), base_model = "C5.0")
</pre></div>



<h4>Preprocessing requirements</h4>

<p>This engine does not require any special encoding of the predictors.
Categorical predictors can be partitioned into groups of factor levels
(e.g. <code style="white-space: pre;">⁠{a, c}⁠</code> vs <code style="white-space: pre;">⁠{b, d}⁠</code>) when splitting at a node. Dummy variables
are not required for this model.
</p>



<h4>Case weights</h4>

<p>This model can utilize case weights during model fitting. To use them,
see the documentation in case_weights and the examples
on <code>tidymodels.org</code>.
</p>
<p>The <code>fit()</code> and <code>fit_xy()</code> arguments have arguments called
<code>case_weights</code> that expect vectors of case weights.
</p>



<h4>References</h4>


<ul>
<li>
<p> Breiman, L. 1996. “Bagging predictors”. Machine Learning. 24 (2):
123-140
</p>
</li>
<li>
<p> Kuhn, M, and K Johnson. 2013. <em>Applied Predictive Modeling</em>. Springer.
</p>
</li>
</ul>
</div>