<div class="container">

<table style="width: 100%;"><tr>
<td>resample.indices</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Generation of indices for resampling Procedure</h2>

<h3>Description</h3>

<p>Generates training and test set indices for use in resampling estimation of prediction error, e.g. cross-validation or bootstrap (with and without replacement).
</p>


<h3>Usage</h3>

<pre><code class="language-R">resample.indices(n, sample.n = 100, method = c("no", "cv" ,"boot", "sub632"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>number of observations of the full data set.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sample.n</code></td>
<td>
<p>the number of bootstrap samples in case of <code>method="boot"</code> and the number of cross-validation subsets in case of <code>method="cv"</code>, e.g. 10 for 10-fold cross-validation. Not considered if <code>method="no"</code>, where number of samples is one (the full data set) by definition.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>by default, the training set indices are the same as the test set indices, i.e. the model is assessed in the same data as fitted (<code>"no"</code>). <code>"cv"</code>: Cross-validation, <code>"boot"</code>: Bootstrap (with replacement), <code>"sub632"</code>: Boostrap without replacement, also called subsampling. In the latter case, the number of observations in each sample equals <code>round(0.632 * n)</code>, see Details.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>As each bootstrap sample should be taken as if new data, complexity selection should be carried out in each bootstrap sample. Binder and Schumacher show that when bootstrap samples are drawn with replacement, often too complex models are obtained in high-dimensional data settings. They recommend to draw bootstrap samples without replacement, each of size <code>round(0.632 * n)</code>, which equals the expected number of unique observations in one bootstrap sample drawn with replacement, to avoid biased complexity selection and improve predictive power of the resulting models. 
</p>


<h3>Value</h3>

<p>A list containing two lists of length <code>sample.n</code>:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>sample.index</code></td>
<td>
<p>contains in each element the indices of observations of one training set.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>not.in.sample</code></td>
<td>
<p>contains in each element the indices of observations of one test set, corresponding to the training set in listelement <code>sample.index</code>.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Binder, H. and Schumacher, M. (2008) Adapting prediction error estimates for biased complexity selection in high-dimensional bootstrap samples. Statistical Applications in Genetics and Molecular Biology, 7:1.</p>


<h3>See Also</h3>

<p><code>peperr</code></p>


<h3>Examples</h3>

<pre><code class="language-R"># generate dataset: 100 patients, 20 covariates
data &lt;- matrix(rnorm(2000), nrow=100)

# generate indices for training and test data for 10-fold cross-validation
indices &lt;- resample.indices(n=100, sample.n = 10, method = "cv")

# create training and test data via indices
trainingsample1 &lt;- data[indices$sample.index[[1]],]
testsample1 &lt;- data[indices$not.in.sample[[1]],]
</code></pre>


</div>