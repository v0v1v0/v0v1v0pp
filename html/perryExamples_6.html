<div class="container">

<table style="width: 100%;"><tr>
<td>lasso</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Lasso with penalty parameter selection</h2>

<h3>Description</h3>

<p>Fit lasso models and select the penalty parameter by estimating the
respective prediction error via (repeated) <code class="reqn">K</code>-fold cross-validation,
(repeated) random splitting (also known as random subsampling or Monte Carlo
cross-validation), or the bootstrap.
</p>


<h3>Usage</h3>

<pre><code class="language-R">lasso(
  x,
  y,
  lambda = seq(1, 0, length.out = 50),
  mode = c("fraction", "lambda"),
  standardize = TRUE,
  intercept = TRUE,
  splits = foldControl(),
  cost = rmspe,
  selectBest = c("hastie", "min"),
  seFactor = 1,
  ncores = 1,
  cl = NULL,
  seed = NULL,
  ...
)

lasso.fit(
  x,
  y,
  lambda = seq(1, 0, length.out = 50),
  mode = c("fraction", "lambda"),
  standardize = TRUE,
  intercept = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a numeric matrix containing the predictor variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a numeric vector containing the response variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>for <code>lasso</code>, a numeric vector of non-negative values to
be used as penalty parameter.  For <code>lasso.fit</code>, a single non-negative
value to be used as penalty parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mode</code></td>
<td>
<p>a character string specifying the type of penalty parameter.  If
<code>"fraction"</code>, <code>lambda</code> gives the fractions of the smallest value
of the penalty parameter that sets all coefficients to 0 (hence all values
of <code>lambda</code> should be in the interval [0,1] in that case).  If
<code>"lambda"</code>, <code>lambda</code> gives the grid of values for the penalty
parameter directly.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standardize</code></td>
<td>
<p>a logical indicating whether the predictor variables
should be standardized to have unit variance (the default is <code>TRUE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>a logical indicating whether a constant term should be
included in the model (the default is <code>TRUE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>splits</code></td>
<td>
<p>an object giving data splits to be used for prediction error
estimation (see <code>perryTuning</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cost</code></td>
<td>
<p>a cost function measuring prediction loss (see
<code>perryTuning</code> for some requirements).  The
default is to use the root mean squared prediction error (see
<code>cost</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectBest, seFactor</code></td>
<td>
<p>arguments specifying a criterion for selecting
the best model (see <code>perryTuning</code>).  The default is to
use a one-standard-error rule.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncores, cl</code></td>
<td>
<p>arguments for parallel computing (see
<code>perryTuning</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>optional initial seed for the random number generator (see
<code>.Random.seed</code> and <code>perryTuning</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>for <code>lasso</code>, additional arguments to be passed to the
prediction loss function <code>cost</code>.  For <code>lasso.fit</code>, additional
arguments to be passed to <code>lars</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>For <code>lasso</code>, an object of class <code>"perryTuning"</code>, see
<code>perryTuning</code>).  It contains information on the
prediction error criterion, and includes the final model with the optimal
tuning paramter as component <code>finalModel</code>.
</p>
<p>For <code>lasso.fit</code>, an object of class <code>lasso</code> with the following
components:
</p>

<dl>
<dt><code>lambda</code></dt>
<dd>
<p>numeric; the value of the penalty parameter.</p>
</dd>
<dt><code>coefficients</code></dt>
<dd>
<p>a numeric vector containing the coefficient
estimates.</p>
</dd>
<dt><code>fitted.values</code></dt>
<dd>
<p>a numeric vector containing the fitted values.</p>
</dd>
<dt><code>residuals</code></dt>
<dd>
<p>a numeric vector containing the residuals.</p>
</dd>
<dt><code>standardize</code></dt>
<dd>
<p>a logical indicating whether the predictor
variables were standardized to have unit variance.</p>
</dd>
<dt><code>intercept</code></dt>
<dd>
<p>a logical indicating whether the model includes a
constant term.</p>
</dd>
<dt><code>muX</code></dt>
<dd>
<p>a numeric vector containing the means of the predictors.</p>
</dd>
<dt><code>sigmaX</code></dt>
<dd>
<p>a numeric vector containing the standard deviations of
the predictors.</p>
</dd>
<dt><code>mu</code></dt>
<dd>
<p>numeric; the mean of the response.</p>
</dd>
<dt><code>call</code></dt>
<dd>
<p>the matched function call.</p>
</dd>
</dl>
<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>References</h3>

<p>Tibshirani, R. (1996) Regression shrinkage and selection via the
lasso.  <em>Journal of the Royal Statistical Society, Series B</em>,
<b>58</b>(1), 267â€“288.
</p>


<h3>See Also</h3>

<p><code>perryTuning</code>, <code>lars</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## load data
data("Bundesliga")
Bundesliga &lt;- Bundesliga[, -(1:2)]
f &lt;- log(MarketValue) ~ Age + I(Age^2) + .
mf &lt;- model.frame(f, data=Bundesliga)
x &lt;- model.matrix(terms(mf), mf)[, -1]
y &lt;- model.response(mf)

## set up repeated random splits
splits &lt;- splitControl(m = 40, R = 10)

## select optimal penalty parameter
fit &lt;- lasso(x, y, splits = splits, seed = 2014)
fit

## plot prediction error results
plot(fit, method = "line")
</code></pre>


</div>