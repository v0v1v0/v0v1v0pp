<div class="container">

<table style="width: 100%;"><tr>
<td>add_fpsim</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Add dyadic foreign policy similarity measures to your data</h2>

<h3>Description</h3>

<p><code>add_fpsim()</code> allows you to add a variety of dyadic foreign policy
similarity measures to your (dyad-year, leader-dyad-year) data frame
</p>


<h3>Usage</h3>

<pre><code class="language-R">add_fpsim(data, keep)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>a data frame with appropriate <span class="pkg">peacesciencer</span> attributes</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keep</code></td>
<td>
<p>an optional parameter, specified as a character vector, about
what dyadic foreign policy similarity measure(s) the user wants returned
from this function. If <code>keep</code> is not specified, the function returns all
14 dyadic foreign policy similarity measures calculated by Haege (2011).
Otherwise, the function subsets the underlying data to just what the
user wants and merges in that.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>For the dyad-year (and leader-dyad-year) data, there must be some kind of
information loss in order to reduce the disk space data like these command.
In this case, all calculations are rounded to three decimal spots. I do
not think this to be terribly problematic, though I admit I do not like it.
If this is a problem for your research question (though I can't imagine it
would be), you may want to consider not using this function for dyad-year
or leader-dyad-year data.
</p>
<p>Be mindful that the data are fundamentally dyad-year and that extensions to
leader-level data should be understood as approximations for leaders-dyads
in a given dyad-year.
</p>
<p>The data this function uses are directed dyad-year and the merge is a
left-join, making this function agnostic about whether your dyad-year
(or leader-dyad-year) data are directed or non-directed.
</p>
<p>Haege's (2011) article reads at first glance as agnostic about which of
these particular measures you should consider a "preferred" or "default"
measure of dyadic foreign policy similarity. Indeed, the 2011
publication in <em>Political Analysis</em> mostly drives the point home that
<em>S</em> has important limitations and the multiple variants Haege calculates
are not substitutable. This means a user interested in measuring
dyadic foreign policy similarity might have to cycle through all
of them to assess their varying effects whereas a user interested
in this as just a control variable for the model can (probably)
get by with picking just one and not belaboring the measure
any further.
</p>


<h4>Suggested Defaults</h4>

<p>An evaluation of the data, the article, and an email exchange
with the author leads to the following points the user should
consider. What follows is a rationale for why users should think of
kappa as a default measure for dyadic foreign policy similarity, though
why the "valued" equivalent for the alliance data is an inadvisable
default. The example at the end of the document offers the operational
"nudge" for what the user should want from this function.
</p>

<ul>
<li>
<p> The choice of measure will in part depend on the temporal
domain. If the user has just a post-WWII sample, the UN voting measures
offer better coverage. We're all partial to the alliance data, though,
because of its 19th century coverage.
</p>
</li>
<li>
<p> Haege implores the use of chance-corrected measures, like Cohen's (1960)
kappa or Scott's (1955) pi. Of the two, Haege suggests kappa over pi. The
rationale is the user would need to build in a very strong assumption that
the baseline propensity of forming a tie in the dyad is the same for
both members of the dyad to make Scott's (1955) pi as appropriate an estimate
as Cohen's (1960) kappa even as both have the important chance correction.
</p>
</li>
<li>
<p> The choice of squared versus absolute distances is arbitrary. Users
probably do not think about the differences, or know about the differences.
<em>S</em> was usually calculated with absolute differences in software packages,
though this was never usually belabored to the user. Comparability with <em>S</em>
might be an argument in favor of absolute distance as a default, but keep
in mind that squared distances are much more commonly used in most other
types of distance and association metrics.
</p>
</li>
<li>
<p> The choice of binary or valued is also a design choice for the user to
consider on the full merits, though the practice of valuing alliance ties
on a quantitative scale builds in strong assumptions about the scale of
alliance strength as presented in something like the Correlates of War
or ATOP typology. <em>S</em> has traditionally done this by default, which is
another reason its application in a lot of quantitative peace science
research is suspect.
</p>
</li>
</ul>
<h3>Value</h3>

<p><code>add_fpsim()</code> takes a (dyad-year, leader-dyad-year) data frame and
adds information about the dyadic foreign policy similarity, based on
several measures calculated and offered by Frank Haege.
</p>


<h3>Author(s)</h3>

<p>Steven V. Miller
</p>


<h3>References</h3>



<h4>The Main Source of the Data</h4>

<p>For any use of these data whatsoever (except for Tau-b), please cite
Haege (2011). Data are version 2.0.
</p>

<ul><li>
<p> Haege, Frank M. 2011. "Choice or Circumstance? Adjusting Measures of
Foreign Policy Similarity for Chance Agreement."
<em>Political Analysis</em> 19(3): 287-305.
</p>
</li></ul>
<p>Tau-b is calculated by me and not Haege, and no additional citation (beyond
citing the package) is necessary.
</p>



<h4>Citations for the Particular Similarity Measure You Choose</h4>

<p>Additional citations depend on what particular measure of similarity you're
using, whether Kendall's (1938) Tau-b, Signorino and Ritter's (1999) <em>S</em>,
Cohen's (1960) kappa and Scott's (1955) pi. Haege (2011) is part of a chorus
arguing against the use of <em>S</em>, though <em>S</em> measures are included in these
data if you elect to ignore the chorus and use this measure. Likewise, Tau-b
is in here, though it is not a good measure of dyadic foreign policy
similarity for reasons that Signorino and Ritter (1999) mention.
Haege (2011) argues for a chance-corrected measure of dyadic foreign policy
similarity, either Cohen's (1960) kappa or Scott's (1955) pi.
</p>

<ul>
<li>
<p> Cohen, Jacob. 1960. "A Coefficient of Agreement for Nominal Scales."
<em>Educational and Psychological Measurement</em> 20(1): 37-46.
</p>
</li>
<li>
<p> Kendall, M.G. 1938. "A New Measure of Rank Correlation."
<em>Biometrika</em> 30(1/2): 81–93.
</p>
</li>
<li>
<p> Scott, William A. 1955. "Reliability of Content Analysis: The Case of
Nominal Scale Coding." <em>Public Opinion Quarterly</em> 19(3): 321–5.
</p>
</li>
<li>
<p> Signorino, Curtis S. and Jeffrey M. Ritter. "Tau-b or Not Tau-B: Measuring
the Similarity of Foreign Policy Positions." 43(1): 115–44.
</p>
</li>
</ul>
<h4>Citations for the Underlying Data Informing the Similarity Measure</h4>

<p>Haege (2011) also suggests you cite the underlying data informing the
similarity measure, whether it is UN voting or alliances. In his case,
he recommended a Voeten citation from 2013 and the alliance data proper.
In the case of the alliances, I know Gibler's (2009) book is recommended
even if the alliance data have since been updated (and reflected in this
measure). In the UN voting data, my understanding is the 2017 paper in
<em>Journal of Conflict Resolution</em> is also the preferred citation.
</p>

<ul>
<li>
<p> Bailey, Michael A., Anton Strezhnev, and Erik Voeten. 2017.
"Estimating the Dynamic State Preferences from United Nations Voting Data."
<em>Journal of Conflict Resolution</em> 61(2): 430–456.
</p>
</li>
<li>
<p> Gibler, Douglas M. 2009. <em>International Military Alliances, 1648-2008</em>.
Washington DC: CQ Press.
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
# just call `library(tidyverse)` at the top of the your script.
library(magrittr)
# The function below works, but depends on
# running `download_extdata()` beforehand.
cow_ddy %&gt;% add_fpsim()

# Select just the two kappa measures that are suggested defaults.
# `kappaba`: kappa for binary alliance data if you have pre-WWII data.
# `kappavv`: kappa for UN voting data if you just post-WWII data.
cow_ddy %&gt;% add_fpsim(keep=c("kappaba", "kappavv"))


## End(Not run)
</code></pre>


</div>