<div class="container">

<table style="width: 100%;"><tr>
<td>bedrock_create_model_invocation_job</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Creates a batch inference job to invoke a model on multiple prompts</h2>

<h3>Description</h3>

<p>Creates a batch inference job to invoke a model on multiple prompts. Format your data according to <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-data.html">Format your inference data</a> and upload it to an Amazon S3 bucket. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference.html">Process multiple prompts with batch inference</a>.
</p>
<p>See <a href="https://www.paws-r-sdk.com/docs/bedrock_create_model_invocation_job/">https://www.paws-r-sdk.com/docs/bedrock_create_model_invocation_job/</a> for full documentation.
</p>


<h3>Usage</h3>

<pre><code class="language-R">bedrock_create_model_invocation_job(
  jobName,
  roleArn,
  clientRequestToken = NULL,
  modelId,
  inputDataConfig,
  outputDataConfig,
  timeoutDurationInHours = NULL,
  tags = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>jobName</code></td>
<td>
<p>[required] A name to give the batch inference job.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>roleArn</code></td>
<td>
<p>[required] The Amazon Resource Name (ARN) of the service role with permissions to
carry out and manage batch inference. You can use the console to create
a default service role or follow the steps at <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/batch-iam-sr.html">Create a service role for batch inference</a>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>clientRequestToken</code></td>
<td>
<p>A unique, case-sensitive identifier to ensure that the API request
completes no more than one time. If this token matches a previous
request, Amazon Bedrock ignores the request, but does not return an
error. For more information, see <a href="https://docs.aws.amazon.com/ec2/latest/devguide/ec2-api-idempotency.html">Ensuring idempotency</a>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>modelId</code></td>
<td>
<p>[required] The unique identifier of the foundation model to use for the batch
inference job.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>inputDataConfig</code></td>
<td>
<p>[required] Details about the location of the input to the batch inference job.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>outputDataConfig</code></td>
<td>
<p>[required] Details about the location of the output of the batch inference job.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>timeoutDurationInHours</code></td>
<td>
<p>The number of hours after which to force the batch inference job to time
out.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tags</code></td>
<td>
<p>Any tags to associate with the batch inference job. For more
information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/tagging.html">Tagging Amazon Bedrock resources</a>.</p>
</td>
</tr>
</table>
</div>