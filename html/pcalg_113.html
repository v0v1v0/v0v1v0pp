<div class="container">

<table style="width: 100%;"><tr>
<td>r.gauss.pardag</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Generate a Gaussian Causal Model Randomly</h2>

<h3>Description</h3>

<p>Generate a random Gaussian causal model.  Parameters specifying the
connectivity as well as coefficients and error terms of the corresponding
linear structural equation model can be specified.  The observational
expectation value of the generated model is always 0, meaning that no
interception terms are drawn.
</p>


<h3>Usage</h3>

<pre><code class="language-R">r.gauss.pardag(p, prob, top.sort = FALSE, normalize = FALSE,
               lbe = 0.1, ube = 1, neg.coef = TRUE, labels = as.character(1:p),
               lbv = 0.5, ubv = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>the number of nodes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prob</code></td>
<td>
<p>probability of connecting a node to another node.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>top.sort</code></td>
<td>
<p><code>logical</code> indicating whether the output graph should be
topologically sorted, meaning that arrows always point from lower
to higher node indices.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>normalize</code></td>
<td>
<p><code>logical</code> indicating whether weights and error variances
should be normalized such that the diagonal of the corresponding
observational covariance matrix is 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lbe, ube</code></td>
<td>
<p>lower and upper bounds of the absolute values of edge
weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>neg.coef</code></td>
<td>
<p>logical indicating whether negative edge weights are also
admissible.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>labels</code></td>
<td>
<p>(optional) character vector of variable (or “node”) names.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lbv, ubv</code></td>
<td>
<p>lower and upper bound on error variances of the noise terms
in the structural equations.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The underlying directed acyclic
graph (DAG) is generated by drawing an undirected graph from an Erdős-Rényi
model orienting the edges according to a random topological ordering drawn
uniformly from the set of permutations of <code>p</code> variables. This means that
any two nodes are connected with (the same) probability <code>prob</code>, and that
the connectivity of different pairs of nodes is independent.
</p>
<p>A Gaussian causal model can be represented as a set of linear structural
equations.  The regression coefficients of the model can be represented as
"edge weights" of the DAG.  Edge weights are drawn uniformly and
independently from the interval between <code>lbe</code> and <code>ube</code>; if
<code>neg.coef = TRUE</code>, their sign is flipped with probability 0.5.  Error
variances are drawn uniformly and independently from the interval between
<code>lbv</code> and <code>ubv</code>.
</p>
<p>If <code>normalize = TRUE</code>, the edge weights and error variances are
normalized <em>in the end</em> to ensure that the diagonal elements of the
observational covariance matrix are all 1; the procedure used is described in
Hauser and Bühlmann (2012).  Note that in this case the error variances and
edge weights are no longer guaranteed to lie in the specified intervals
<em>after normalization</em>.
</p>


<h3>Value</h3>

<p>An object of class <code>"GaussParDAG"</code>.
</p>


<h3>Author(s)</h3>

<p>Alain Hauser (<a href="mailto:alain.hauser@bfh.ch">alain.hauser@bfh.ch</a>)
</p>


<h3>References</h3>

<p>P. Erdős and A. Rényi (1960).  On the evolution of random graphs.
<em>Publications of the Mathematical Institute of the Hungarian Academy of
Sciences</em> <b>5</b>, 17–61.
</p>
<p>A. Hauser and P. Bühlmann (2012).  Characterization and greedy learning of
interventional Markov equivalence classes of directed acyclic graphs.
<em>Journal of Machine Learning Research</em> <b>13</b>, 2409–2464.
</p>


<h3>See Also</h3>

<p><code>GaussParDAG</code>, <code>randomDAG</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(307)

## Plot some random DAGs
if (require(Rgraphviz)) {
  ## Topologically sorted random DAG
  myDAG &lt;- r.gauss.pardag(p = 10, prob = 0.2, top.sort = TRUE)
  plot(myDAG)

  ## Unsorted DAG
  myDAG &lt;- r.gauss.pardag(p = 10, prob = 0.2, top.sort = FALSE)
  plot(myDAG)
}

## Without normalization, edge weigths and error variances lie within the
## specified borders
set.seed(307)
myDAG &lt;- r.gauss.pardag(p = 10, prob = 0.4,
  lbe = 0.1, ube = 1, lbv = 0.5, ubv = 1.5, neg.coef = FALSE)
B &lt;- myDAG$weight.mat()
V &lt;- myDAG$err.var()
any((B &gt; 0 &amp; B &lt; 0.1) | B &gt; 1)
any(V &lt; 0.5 | V &gt; 1.5)

## After normalization, edge weights and error variances are not necessarily
## within the specified range, but the diagonal of the observational covariance
## matrix consists of ones only
set.seed(308)
myDAG &lt;- r.gauss.pardag(p = 10, prob = 0.4, normalize = TRUE,
  lbe = 0.1, ube = 1, lbv = 0.5, ubv = 1.5, neg.coef = FALSE)
B &lt;- myDAG$weight.mat()
V &lt;- myDAG$err.var()
any((B &gt; 0 &amp; B &lt; 0.1) | B &gt; 1)
any(V &lt; 0.5 | V &gt; 1.5)
diag(myDAG$cov.mat())
</code></pre>


</div>