<div class="container">

<table style="width: 100%;"><tr>
<td>pfa</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> 

Estimates False Discovery Proportion Under Arbitrary Covariance Dependence
</h2>

<h3>Description</h3>


<p>This package contains functions for performing multiple testing and estimating the false discovery proportion (FDP). <code>pfa.test(X,...)</code> finds the false nulls
in p hypotheses; <code>pfa.test(X,Y,...)</code> tests the difference of two multiple-dimensional population means; <code>pfa.gwas(X,Y,...)</code> performs the genome-wise association study(GWAS).
</p>


<h3>Usage</h3>

<pre><code class="language-R">pfa.test(X,Y,tval,Sigma,reg="L2",K,e=0.05,gamma,mat_est="poet",plot="-log")
pfa.gwas(X,Y,tval,v,reg="L1",e=0.05,gamma,K,plot="-log")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X,Y</code></td>
<td>
<p>In <code>pfa.test</code>, either X and Y are data matrices of two different samples, or X is a vector of test statistics and Y is missing. In <code>pfa.gwas</code>, X is the design matrix and Y contains observations of the response variable.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Sigma</code></td>
<td>
<p>the covariance matrix.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>v</code></td>
<td>
<p>standard deviation of noises. By default, it is estimated by refitted cross-validation.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tval</code></td>
<td>
<p> a sequence of thresholding level for p-values. By default, <code>tval</code> is chosen automatically.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reg</code></td>
<td>
<p>method used to estimate factors. If reg="L1", the method is least absolute value regression; if reg="L2", the method is least-squares (with large outliers filtered out). Default is "L1".

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p> number of factors. By default, given the covariance matrix, K is the smallest integer such that the sum of squares of the smallest (p-K) eigenvalues is no larger than e=0.01 times its trace.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>e</code></td>
<td>
<p> a parameter used to choose the number of factors in PFA. Default value is 0.01.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>
<p> a parameter used to estimate the true Null proportion: pi0 = (percentage of (p-values &gt; gamma))  /(1- gamma). By default, it is chosen automatically.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mat_est</code></td>
<td>
<p>method used to estimate the covariance matrix. If mat_est="sample", the estimate is the (pooled) sample covariance matrix; if mat_est="poet", the estimate comes from the <code>poet</code> package. Default is "poet".
</p>
</td>
</tr>
</table>
<table><tr style="vertical-align: top;">
<td><code>plot</code></td>
<td>
<p> plotting mode. If plot="-log", in the FDP plot, the x axis is -log(t); if plot="log", the x axis is log(t); if plot="linear", the x axis is t; if plot="none", no graph is generated. Default is "-log".

</p>
</td>
</tr></table>
<h3>Details</h3>


<p><code>pfa.test(X,Sigma=Sigma,...)</code>: X is a vector of test statistics. Suppose it has a multivariate Gaussian distribution <code>N(mu, Sigma)</code>. 
We would like to test: <code>mu(i)=0, i=1,...,p</code>. Given a threshold <code>t</code>, we reject hypothesis <code>i</code> if and only if <code>P(i)=X(i)/sqrt(Sigma(i,i))&lt;t</code>,<code>i=1,...,p</code>. We apply the PFA method [Fan, Han and Gu (2012)] to estimate the false discovery proportion (FDP) for arbitrary thresholds.
In this case, the covariance matrix <code>Sigma</code> is required. 
</p>
<p><code>pfa.test(X,...)</code>: X is an n-by-p matrix containing i.i.d. samples of the multivariate Gaussian distrubtion <code>N(mu, Sigma)</code>. Again, we would like to test: <code>mu(i)=0</code>, i=1,...,p. 
The test statistics is the vector of sample mean. When <code>Sigma</code> is unknown, we instead use the sample covariance matrix or the estimate from POET-PFA method [Fan and Han (2016)]. The number of factors determined for POET and for PFA is based on the eigenvalue ratio test in Ahn and Horenstein (2013). 
</p>
<p><code>pfa.test(X,Y,...)</code>: X and Y are i.i.d. samples from the distributions <code>N(mu1, Sigma)</code> and <code>N(mu2, Sigma)</code>. We would like to test: <code>mu1(i)=mu2(i)</code>, i=1,...,p. The test statistics
is the vector of sample mean difference. When <code>Sigma</code> is unknown, we instead use the pooled sample covariance matrix or the estimate from POET-PFA method.
</p>
<p><code>pfa.gwas(X,Y,...)</code>: X is the data matrix of <code>p</code> covariates (e.g. SNP measurements) and Y is the data vector of response variables (e.g. indicator of a trait).
We would like to test: whether covariate <code>i</code> is marginally associated with the response, <code>i=1,...,p</code>. The test statistics is the maginal regression coefficients. 
We suppose <code>Y=X_1*beta_1+...+X_p*beta_p+epsilon</code>, where <code>epsilon</code>'s are i.i.d. samples from <code>N(0,sigma^2)</code>. Then the 
covariane matrix of the test statistics is nothing but the sample covariance matrix of X. 
</p>


<h3>Value</h3>

 
<p>Four graphs will be generated for each of the functions: one histogram of p-values; number of total rejections, number of false rejections, and FDPs all indexed by t. 
</p>
<p>It returns an object of class <code>PDFresults</code>, which is a list containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Pvalue</code></td>
<td>
<p>Sorted p-values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adjPvalue</code></td>
<td>
<p>Sorted adjusted p-values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>FDP</code></td>
<td>
<p>Estimated FDPs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pi0</code></td>
<td>
<p>Estimated true null proportion.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>Number of factors used in the PFA method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma</code></td>
<td>
<p>Estimated standard deviation of noises. This component is NULL except in the return of <code>pfaRegress</code>.</p>
</td>
</tr>
</table>
<h3>Note</h3>


<p>1. The estimated FDP does not necessarily decrease as the threshold <code>t</code> increases (although the number of total rejections and estimated false rejections both decrease as <code>t</code> increases). 
As a result, the estimated FDP curve is sometimes zigzag. Moreover, two values of <code>t</code> can yield to different estimated FDP values even if they give exactly the same rejections.
</p>
<p>2. In <code>pfa.gwas</code>, when the standard deviation of noises, <code>v</code>, is not provided, we apply refitted cross validation [Fan,Guo and Hao (2012)] 
to estimate <code>v</code>. This may take some time (especially when the dimension p is large), and the results can be different at each running, due to random data splits.
An input of <code>v</code> is suggested in this case.
</p>
<p>3. Sometimes people want to use the sequence of obtained p-values as the sequence of thresholds. This can be implemented by setting <code>tval</code>="pval", see Example 4 below.
</p>
<p>4. It is generally better to use the factor-adjusted p-values, but there is no universal conclusion on which is better. One way is to plot both histograms and see, if ignoring 
a neighborhood of 0, which one is closer to the uniform distribution. 
</p>


<h3>Author(s)</h3>

<p>Jianqing Fan, Tracy Ke, Sydney Li and Lucy Xia.
</p>
<p>Maintainer: Tracy Ke &lt;zke@galton.uchicago.edu&gt;, Lucy Xia &lt;lucyxia@stanford.edu&gt;.

</p>


<h3>References</h3>


<p>Fan, Han and Gu (2012) "Estimating False Discovery Proportion Under Arbitrary Covariance Dependence" (with discussion) JASA.
</p>
<p>Fan and Han (2016) "Estimation of False Discovery Proportion with Unknown Dependence", Manuscript.
</p>


<h3>See Also</h3>

<p>Ahn and Horestein (2013) "Eigenvalue Ratio Test for the Number of Factors", Econometrica. 	
</p>
<p>Fan, Guo and Hao (2012)"Variance Estimation Using Refitted Cross-Validation in Ultrahigh Dimensional Regression" JRSSB.
</p>
<p>Fan, Liao and Mincheva (2013) "Large Covariance Estimation by Thresholding Principal Orthogonal Complements", JRSSB .

</p>


<h3>Examples</h3>

<pre><code class="language-R"># Example 1: multiple testing with known covariance

require(MASS)
p &lt;- 100
Sigma &lt;- matrix(0.4,p,p)
diag(Sigma)&lt;- 1
mu &lt;- as.vector(c(rep(3,5), rep(0, p-5)))
Z &lt;- mvrnorm(1, mu, Sigma)
RE1 &lt;- pfa.test(Z, Sigma=Sigma,reg="L1")
summary(RE1)

# Example 2: multiple testing with unknown covariance 

n &lt;- 200
p &lt;- 300
K &lt;- 3
mu &lt;- as.vector(c(rep(2,10),rep(0,p-10)))
B &lt;- matrix(runif(K*p, min=-1, max=1), nrow=K)
f &lt;- matrix(rnorm(K*n), nrow=n)
Bf &lt;- f %*% B
X &lt;- matrix(rep(0, n*p), nrow=n)
for (i in 1:n) 
   X[i,] &lt;- mu + Bf[i,] + rnorm(p)
## Not run: RE2 &lt;- pfa.test(X, tval="pval")
## Not run: summary(RE2)

# Example 3: testing the marginal regression coefficients

n &lt;- 100
p &lt;- 300
beta &lt;- as.matrix(c(rep(2, 10), rep(0, p-10)))
X &lt;- matrix(rep(0, n*p), nrow=n)
X[,1:10] &lt;- matrix(rnorm(n*10), nrow=n)
z &lt;- as.matrix(rnorm(n))
y &lt;- as.matrix(rnorm(n))
X[,11:p] &lt;- as.matrix(rnorm(n*(p-10)), nrow=n)
for (i in 11:p) {
    rho1 &lt;- runif(1,min=-0.2,max=0.2)
    rho2 &lt;- runif(1,min=-0.2,max=0.2)
    X[,i] &lt;- X[,i] + z*rho1 + y*rho2 
}
eps &lt;- as.matrix(rnorm(n))
Y &lt;- X %*% beta + eps
## Not run: RE3 &lt;- pfa.gwas(X,Y)
## Not run: summary(RE3)

# Example 4: GWAS on the CCT8 gene

data(CEU)
## Not run: RE4 &lt;- pfa.gwas(CEU$x, CEU$y, t=exp(-seq(1.8,3.6,0.1)), reg="L2")
## Not run: summary(RE4)

</code></pre>


</div>