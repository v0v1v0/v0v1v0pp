<div class="container">

<table style="width: 100%;"><tr>
<td>solve_SARSOP</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Solve a POMDP Problem using SARSOP</h2>

<h3>Description</h3>

<p>This function uses the C++ implementation of the SARSOP algorithm
by Kurniawati, Hsu and Lee (2008) interfaced in
package <span class="pkg">sarsop</span>
to solve infinite horizon problems that are formulated as partially observable Markov
decision processes (POMDPs). The result is an optimal or approximately
optimal policy.
</p>


<h3>Usage</h3>

<pre><code class="language-R">solve_SARSOP(
  model,
  horizon = Inf,
  discount = NULL,
  terminal_values = NULL,
  method = "sarsop",
  digits = 7,
  parameter = NULL,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>a POMDP problem specification created with <code>POMDP()</code>.
Alternatively, a POMDP file or the URL for a POMDP file can be specified.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>horizon</code></td>
<td>
<p>SARSOP only supports <code>Inf</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>discount</code></td>
<td>
<p>discount factor in range <code class="reqn">[0, 1]</code>. If <code>NULL</code>, then the
discount factor specified in <code>model</code> will be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>terminal_values</code></td>
<td>
<p><code>NULL</code>. SARSOP does not use terminal values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>string; there is only one method available called <code>"sarsop"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p>precision used when writing POMDP files (see
<code>write_POMDP()</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parameter</code></td>
<td>
<p>a list with parameters passed on to
the function <code>sarsop::pomdpsol()</code> in package <span class="pkg">sarsop</span>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>logical, if set to <code>TRUE</code>, the function provides the
output of the solver in the R console.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The solver returns an object of class POMDP which is a list with the
model specifications (<code>'model'</code>), the solution (<code>'solution'</code>), and the
solver output (<code>'solver_output'</code>).
</p>


<h3>Author(s)</h3>

<p>Michael Hahsler
</p>


<h3>References</h3>

<p>Carl Boettiger, Jeroen Ooms and Milad Memarzadeh (2020). sarsop:
Approximate POMDP Planning Software. R package version 0.6.6.
https://CRAN.R-project.org/package=sarsop
</p>
<p>H. Kurniawati, D. Hsu, and W.S. Lee (2008). SARSOP: Efficient point-based POMDP planning by approximating optimally reachable belief spaces. In Proc. Robotics: Science and Systems.
</p>


<h3>See Also</h3>

<p>Other policy: 
<code>estimate_belief_for_nodes()</code>,
<code>optimal_action()</code>,
<code>plot_belief_space()</code>,
<code>plot_policy_graph()</code>,
<code>policy()</code>,
<code>policy_graph()</code>,
<code>projection()</code>,
<code>reward()</code>,
<code>solve_POMDP()</code>,
<code>value_function()</code>
</p>
<p>Other solver: 
<code>solve_MDP()</code>,
<code>solve_POMDP()</code>
</p>
<p>Other POMDP: 
<code>MDP2POMDP</code>,
<code>POMDP()</code>,
<code>accessors</code>,
<code>actions()</code>,
<code>add_policy()</code>,
<code>plot_belief_space()</code>,
<code>projection()</code>,
<code>reachable_and_absorbing</code>,
<code>regret()</code>,
<code>sample_belief_space()</code>,
<code>simulate_POMDP()</code>,
<code>solve_POMDP()</code>,
<code>transition_graph()</code>,
<code>update_belief()</code>,
<code>value_function()</code>,
<code>write_POMDP()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
# Solving the simple infinite-horizon Tiger problem with SARSOP
# You need to install package "sarsop"
data("Tiger")
Tiger

sol &lt;- solve_SARSOP(model = Tiger)
sol

# look at solver output
sol$solver_output

# policy (value function (alpha vectors), optimal action and observation dependent transitions)
policy(sol)

# value function
plot_value_function(sol, ylim = c(0,20))

# plot the policy graph
plot_policy_graph(sol)

# reward of the optimal policy
reward(sol)

# Solve a problem specified as a POMDP file. The timeout is set to 10 seconds.
sol &lt;- solve_SARSOP("http://www.pomdp.org/examples/cheese.95.POMDP", parameter = list(timeout = 10))
sol

## End(Not run)

</code></pre>


</div>