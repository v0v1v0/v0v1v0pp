<div class="container">

<table style="width: 100%;"><tr>
<td>error_modelSel</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compute error in model selection with Approximate Bayesian Computation</h2>

<h3>Description</h3>

<p>This function calculates the confusion matrix and the mean misclassification
probabilities of models from the output of the <code>sim_modelSel()</code> function.
</p>


<h3>Usage</h3>

<pre><code class="language-R">error_modelSel(object, threshold = NA, print = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>a list created by the <code>sim_modelSel()</code> function, containing
results of a simulation study to evaluate the quality of model selection
with Approximate Bayesian Computation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threshold</code></td>
<td>
<p>numeric value between 0 and 1 representing the minimum
posterior probability of assignment.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>print</code></td>
<td>
<p>logical, if TRUE (default), then this function prints the mean
models probabilities.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>It is also possible to define a <code>threshold</code> for the posterior model
probabilities. This threshold sets the minimum posterior probability of
assignment. Thus, a simulation where the posterior probability of any model
is below the threshold will not be assigned to a model and will instead be
classified as "unclear".
</p>


<h3>Value</h3>

<p>apart from directly displaying the results if print is TRUE, the
output object of this function is a list with the following elements:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>confusion.matrix</code></td>
<td>
<p>the confusion matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>probs</code></td>
<td>
<p>the mean model misclassification probabilities.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>postmeans</code></td>
<td>
<p>the mean model misclassification probabilities when each
model is correctly or incorrectly estimated.</p>
</td>
</tr>
</table>
<h3>Examples</h3>

<pre><code class="language-R"># load the matrix with simulated parameter values
data(sumstats)

# select a random simulation to act as target just to test the function
target &lt;- sumstats[10 ,]

# create a "fake" vector of model indices
# this assumes that half the simulations were from one model and the other half from other model
# this is not true but serves as an example of how to use this function
index &lt;- c(rep("model1", nrow(sumstats)/2), rep("model2", nrow(sumstats)/2))

# perform a leave-one-out cross validation of model selection
mysim &lt;- sim_modelSel(index = index, sumstats = sumstats, nval = 10, tol = 0.1)

# compute the confusion matrix and the mean misclassification probabilities
error_modelSel(object = mysim)

</code></pre>


</div>