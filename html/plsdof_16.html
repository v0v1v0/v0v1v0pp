<div class="container">

<table style="width: 100%;"><tr>
<td>pcr.cv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Model selection for Princinpal Components regression based on
cross-validation</h2>

<h3>Description</h3>

<p>This function computes the optimal model parameter using cross-validation.
Mdel selection is based on mean squared error and correlation to the
response, respectively.
</p>


<h3>Usage</h3>

<pre><code class="language-R">pcr.cv(
  X,
  y,
  k = 10,
  m = min(ncol(X), nrow(X) - 1),
  groups = NULL,
  scale = TRUE,
  eps = 1e-06,
  plot.it = FALSE,
  compute.jackknife = TRUE,
  method.cor = "pearson",
  supervised = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>matrix of predictor observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>vector of response observations. The length of <code>y</code> is the same
as the number of rows of <code>X</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>number of cross-validation splits. Default is 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m</code></td>
<td>
<p>maximal number of principal components. Default is
<code>m=min(ncol(X),nrow(X)-1)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>groups</code></td>
<td>
<p>an optional vector with the same length as <code>y</code>. It
encodes a partitioning of the data into distinct subgroups. If <code>groups</code>
is provided, <code>k=10</code> is ignored and instead, cross-validation is
performed based on the partioning. Default is <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>Should the predictor variables be scaled to unit variance?
Default is <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>precision. Eigenvalues of the correlation matrix of <code>X</code> that
are smaller than <code>eps</code> are set to 0. The default value is
<code>eps=10^{-6}.</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot.it</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the function plots the
cross-validation-error as a function of the number of components. Default is
<code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>compute.jackknife</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the regression
coefficients on each of the cross-validation splits is stored. Default is
<code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method.cor</code></td>
<td>
<p>How should the correlation to the response be computed?
Default is ”pearson”.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>supervised</code></td>
<td>
<p>Should the principal components be sorted by decreasing
squared correlation to the response? Default is FALSE.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function computes the principal components on the scaled predictors.
Based on the regression coefficients <code>coefficients.jackknife</code> computed
on the cross-validation splits, we can estimate their mean and their
variance using the jackknife. We remark that under a fixed design and the
assumption of normally distributed <code>y</code>-values, we can also derive the
true distribution of the regression coefficients.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>cv.error.matrix</code></td>
<td>
<p>matrix of cross-validated errors based on
mean squared error. A row corresponds to one cross-validation split.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv.error</code></td>
<td>
<p>vector of cross-validated errors based on mean squared
error</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m.opt</code></td>
<td>
<p>optimal number of components based on mean squared
error</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>intercept of the optimal model, based on mean
squared error</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coefficients</code></td>
<td>
<p>vector of regression coefficients of the
optimal model, based on mean squared error</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cor.error.matrix</code></td>
<td>
<p>matrix
of cross-validated errors based on correlation. A row corresponds to one
cross-validation split.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cor.error</code></td>
<td>
<p>vector of cross-validated errors
based on correlation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m.opt.cor</code></td>
<td>
<p>optimal number of components based on
correlation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept.cor</code></td>
<td>
<p>intercept of the optimal model, based on
correlation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coefficients.cor</code></td>
<td>
<p>vector of regression coefficients of
the optimal model, based on correlation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coefficients.jackknife</code></td>
<td>
<p>Array of the regression coefficients on each
of the cross-validation splits, if <code>compute.jackknife=TRUE</code>. In this
case, the dimension is <code>ncol(X) x (m+1) x k</code>.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Nicole Kraemer, Mikio L. Braun
</p>


<h3>See Also</h3>

<p><code>pls.model</code>, <code>pls.ic</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
n&lt;-500 # number of observations
p&lt;-5 # number of variables
X&lt;-matrix(rnorm(n*p),ncol=p)
y&lt;-rnorm(n)

# compute PCR 
pcr.object&lt;-pcr.cv(X,y,scale=FALSE,m=3)
pcr.object1&lt;-pcr.cv(X,y,groups=sample(c(1,2,3),n,replace=TRUE),m=3)

</code></pre>


</div>