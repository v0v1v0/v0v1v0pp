<div class="container">

<table style="width: 100%;"><tr>
<td>item.exam</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Item Analysis </h2>

<h3>Description</h3>

<p>Conducts an item level analysis. Provides item-total correlations, Standard deviation in items,
difficulty, discrimination, and reliability and validity indices.</p>


<h3>Usage</h3>

<pre><code class="language-R">item.exam(x, y = NULL, discrim = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p> matrix or  data.frame of items </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p> Criterion variable </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>discrim</code></td>
<td>
<p> Whether or not the discrimination of item is to be computed</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If someone is interested in examining the items of a dataset contained in data.frame x, and 
the criterion measure is also in data.frame x, one must parse the matrix or data.frame and specify
each part into the function. See example below. Otherwise, one must be sure that x and y are properly 
merged/matched. If one is not interested in assessing item-criterion relationships, simply leave out 
that portion of the call. The function does not check whether the items are dichotomously coded, 
this is user specified. As such, one can specify that items are binary when in fact they are not. This
has the effect of computing the discrimination index for continuously coded variables. <br>
The difficulty index (p) is simply the mean of the item. When dichotomously coded, p reflects the
proportion endorsing the item. However, when continuously coded, p has a different interpretation.</p>


<h3>Value</h3>

<p>A table with rows representing each item and columns repsenting :
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Sample.SD </code></td>
<td>
<p> Standard deviation of the item</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Item.total </code></td>
<td>
<p> Correlation of the item with the total test score </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Item.Tot.woi</code></td>
<td>
<p> Correlation of item with total test score (scored without item)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Difficulty </code></td>
<td>
<p> Mean of the item (p) </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Discrimination </code></td>
<td>
<p> Discrimination of the item (u-l)/n </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Item.Criterion </code></td>
<td>
<p> Correlation of the item with the Criterion (y)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Item.Reliab </code></td>
<td>
<p> Item reliability index</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Item.Rel.woi </code></td>
<td>
<p> Item reliability index (scored without item) </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Item.Validity </code></td>
<td>
<p> Item validity index </p>
</td>
</tr>
</table>
<h3>Warning </h3>

<p> Be cautious when using data with missing values or small data sets. <br></p>
<p>Listwise deletion is employed for both X (matrix of items to be analyzed) and Y (criterion). 
When the datasets are small, such listwise deletion can make a big impact. Further, since the 
upper and lower groups are defined as the upper and lower 1/3, the stability of this division of 
examinees is greatly increased with larger N.</p>


<h3>Note</h3>

<p> Most all text books suggest the point-biserial correlation for the item-total. 
Since the point-biserial is equivalent to the Pearson r, the <code>cor</code> function is used 
to render the Pearson r for each item-total. However, it might be suggested that the 
polyserial is more appropriate. For practical purposes, the Pearson is sufficient and is
used here. <br></p>
<p>If discrim = TRUE, then the discrimination index is computed and returned EVEN IF the items 
are not dichotomously coded. The interpretation of the discrimination index is then suspect. 
<code>discrim</code> computes the number of correct responses in the upper and lower groups by
summation of the '1s' (correct responses). When data are continuous, the discrimination index
represents the difference in the sum of the scores divided by number in each group (1/3*N).</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Allen, M. J. &amp; Yen, W. M. (1979). <em>Introduction to measurement theory.</em> Monterey, CA: Brooks/Cole.
</p>


<h3>See Also</h3>

  <p><code>alpha</code>, <code>discrim</code> </p>


<h3>Examples</h3>

<pre><code class="language-R">
data(TestScores)
# Look at the data
TestScores
# Examine the items
item.exam(TestScores[,1:10], y = TestScores[,11], discrim=TRUE)

</code></pre>


</div>