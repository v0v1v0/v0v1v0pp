<div class="container">

<table style="width: 100%;"><tr>
<td>get_policy_actions</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Get Policy Actions</h2>

<h3>Description</h3>

<p><code>get_policy_actions()</code> extract the actions dictated by the
(learned and possibly cross-fitted) policy a every stage.
</p>


<h3>Usage</h3>

<pre><code class="language-R">get_policy_actions(object)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>Object of class policy_eval.</p>
</td>
</tr></table>
<h3>Value</h3>

<p>data.table::data.table with keys <code>id</code> and <code>stage</code> and action variable
<code>d</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">### Two stages:
d &lt;- sim_two_stage(5e2, seed=1)
pd &lt;- policy_data(d,
                  action = c("A_1", "A_2"),
                  covariates = list(L = c("L_1", "L_2"),
                                    C = c("C_1", "C_2")),
                  utility = c("U_1", "U_2", "U_3"))
pd

# defining a policy learner based on cross-fitted doubly robust Q-learning:
pl &lt;- policy_learn(type = "drql",
                   control = control_drql(qv_models = list(q_glm(~C_1), q_glm(~C_1+C_2))),
                   full_history = TRUE,
                   L = 2) # number of folds for cross-fitting

# evaluating the policy learner using 2-fold cross fitting:
pe &lt;- policy_eval(type = "dr",
                   policy_data = pd,
                   policy_learn = pl,
                   q_models = q_glm(),
                   g_models = g_glm(),
                   M = 2) # number of folds for cross-fitting

# Getting the cross-fitted actions dictated by the fitted policy:
head(get_policy_actions(pe))
</code></pre>


</div>