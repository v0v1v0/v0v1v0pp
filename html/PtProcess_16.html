<div class="container">

<table style="width: 100%;"><tr>
<td>logLik</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Log Likelihood of a Point Process Model</h2>

<h3>Description</h3>

<p>Calculates the log-likelihood of a point process. Provides methods for the generic function <code>logLik</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'mpp'
logLik(object, SNOWcluster=NULL, ...)
## S3 method for class 'linksrm'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>an object with class <code>"mpp"</code> or <code>"linksrm"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>SNOWcluster</code></td>
<td>
<p>an object of class <code>"cluster"</code> created by the package <span class="pkg">parallel</span>; default is <code>NULL</code>. Enables parallel processing if not <code>NULL</code>. See “Parallel Processing” below for further details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>other arguments.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Value of the log-likelihood.
</p>


<h3>Parallel Processing</h3>

<p>Parallel processing can be enabled to calculate the term <code class="reqn">\sum_i \log \lambda_g(t_i|{\cal H}_{t_i})</code>. Generally, the amount of computational work involved in calculating <code class="reqn">\lambda_g(t|{\cal H}_t)</code> is much greater if there are more events in the process history prior to <code class="reqn">t</code> than in the case where there are fewer events. Given <code class="reqn">m</code> nodes, the required evaluation points are divided into <code class="reqn">m</code> groups, taking into account the amount of “history” prior to each event and the CPU speed of the node (see below).
</p>
<p>We have assumed that communication between nodes is fairly slow, and hence it is best to allocate the work in large chunks and minimise communication. If the dataset is small, then the time taken to allocate the work to the various nodes may in fact take more time than simply using one processor to perform all of the calculations.
</p>
<p>The required steps in initiating parallel processing are as follows.
</p>
<pre>
#   load the "parallel" package
library(parallel)

#   define the SNOW cluster object, e.g. a SOCK cluster
#   where each node has the same R installation.
cl &lt;- makeSOCKcluster(c("localhost", "horoeka.localdomain", 
                        "horoeka.localdomain", "localhost"))

#   A more general setup: Totara is Fedora, Rimu is Debian:
#   Use 2 processors on Totara, 1 on Rimu:
totara  &lt;- list(host="localhost",
                rscript="/usr/lib/R/bin/Rscript",
                snowlib="/usr/lib/R/library")
rimu    &lt;- list(host="rimu.localdomain",
                rscript="/usr/lib/R/bin/Rscript",
                snowlib="/usr/local/lib/R/site-library")
cl &lt;- makeCluster(list(totara, totara, rimu), type="SOCK")

#   NOTE: THE STATEMENTS ABOVE WERE APPROPRIATE FOR THE snow PACKAGE.
#   I HAVE NOT YET TESTED THEM USING THE parallel PACKAGE.

#   Relative CPU speeds of the nodes can be added as an attribute
#   Say rimu runs at half the speed of totara
#   (default assumes all run at same speed)
attr(cl, "cpu.spd") &lt;- c(1, 1, 0.5)

#   then define the required model object, e.g. see topic "mpp"
#   say the model object is called x

#   then calculate the log-likelihood as
print(logLik(x, SNOWcluster=cl))

#   stop the R jobs on the slave machines
stopCluster(cl)
</pre>
<p>Note that the communication method does not need to be <code>SOCKS</code>; see the <span class="pkg">parallel</span> package documentation, topic <code>makeCluster</code>, for other options. Further, if some nodes are on other machines, the firewalls may need to be tweaked. The master machine initiates the <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> jobs on the slave machines by communicating through port 22 (use of security keys are needed rather than passwords), and subsequent communications use random ports. This port can be fixed, see <code>makeCluster</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">#    SRM: magnitude iid exponential with bvalue=1

TT &lt;- c(0, 1000)
bvalue &lt;- 1
params &lt;- c(-2.5, 0.01, 0.8, bvalue*log(10))

#   calculate log-likelihood excluding the mark density term
x1 &lt;- mpp(data=NULL,
          gif=srm_gif,
          marks=list(NULL, rexp_mark),
          params=params,
          gmap=expression(params[1:3]),
          mmap=expression(params[4]),
          TT=TT)
x1 &lt;- simulate(x1, seed=5)
print(logLik(x1))

#   calculate log-likelihood including the mark density term
x2 &lt;- mpp(data=x1$data,
          gif=srm_gif,
          marks=list(dexp_mark, rexp_mark),
          params=params,
          gmap=expression(params[1:3]),
          mmap=expression(params[4]),
          TT=TT)
print(logLik(x2))

#  contribution from magnitude marks
print(sum(dexp(x1$data$magnitude, rate=bvalue*log(10), log=TRUE)))
</code></pre>


</div>