<div class="container">

<table style="width: 100%;"><tr>
<td>pcal</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Lower Bounds on the Posterior Probabilities of Point Null Hypotheses</h2>

<h3>Description</h3>

<p>Calibrate p-values under a robust perspective so that they can be interpreted as either lower bounds on the posterior probabilities of point null hypotheses or as lower bounds on the probabilities of type I errors.
</p>


<h3>Usage</h3>

<pre><code class="language-R">pcal(p, prior_prob = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>A numeric vector with values in the [0,1] interval.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior_prob</code></td>
<td>
<p>A numeric vector with values in the [0,1] interval. If <code>length(p) == 1</code> then <code>prior_prob</code> can be of any positive <code>length</code>, but if <code>length(p) &gt; 1</code> then the <code>length</code> of <code>prior_prob</code> can only be <code>1</code> or equal to the <code>length</code> of <code>p</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Sellke et al. (2001) developed a calibration of p-values into lower bounds for the posterior probabilities of point null hypotheses or lower bounds for the probabilities of type I errors for the case when both the null and the alternative hypotheses have 0.5 prior probability. <code>pcal</code> generalizes the aforementioned calibration for prior probabilities other than 0.5.
</p>
<p><code>pcal</code> starts by transforming the values in <code>p</code> into lower bounds on Bayes factors using bcal and then uses bfactor_to_prob together with prior probabilities <code>prior_prob</code> to turn those Bayes factors into posterior probabilities. For each element of <code>p</code>, <code>pcal</code> returns an  approximation of the smallest posterior probability of the null hypothesis that is found by changing the prior distribution of the parameter of interest (under the alternative hypothesis) over wide classes of distributions.
</p>
<p>The <code>prior_prob</code> argument is optional and is set to 0.5 by default, implying prior equiprobability of hypotheses. <code>prior_prob</code> can only be of <code>length</code> equal to  the <code>length</code> of <code>p</code>, in which case each prior probability in <code>prior_prob</code> is used in the calibration of the corresponding element of <code>p</code>, or of <code>length</code> <code>1</code>, in which case it will be recycled (if <code>length(p) &gt; 1</code>) and the same <code>prior_prob</code> value is used in the calibration of all the elements of <code>p</code>.
</p>
<p>The output of <code>pcal</code> can also be interpreted as lower bounds on the probabilities of type I errors. Note that the output of this calibration has both Bayesian and Frequentist interpretations. Sellke et al. (2001) noted that a scenario in which they definitely recommend this calibration is when investigating fit to the null model with no explicit alternative in mind. Pericchi and Torres (2011) warn that despite the usefulness and appropriateness of this p-value calibration it does not depend on sample size, and hence the lower bounds obtained with large samples may be conservative.
</p>


<h3>Value</h3>

<p>If <code>length(p) &gt; 1</code> then <code>pcal</code> returns a numeric vector with the same <code>length</code> as <code>p</code>, otherwise it returns a numeric vector with the same <code>length</code> as <code>prior_prob</code>.
</p>


<h3>References</h3>

<p>Pericchi L, Torres D (2011).
“Quick anomaly detection by the Newcomb—Benford law, with applications to electoral processes data from the USA, Puerto Rico and Venezuela.”
<em>Statistical Science</em>, <b>26</b>(4), 502–516.<br><br> Sellke T, Bayarri MJ, Berger JO (2001).
“Calibration of p values for testing precise null hypotheses.”
<em>The American Statistician</em>, <b>55</b>(1), 62–71.
</p>


<h3>See Also</h3>


<ul><li> <p>bcal for a p-value calibration that returns lower bounds on Bayes factors in favor of point null hypotheses.
</p>
</li></ul>
<h3>Examples</h3>

<pre><code class="language-R"># Calibration of a typical "threshold" p-value:
pcal(.05)

# Calibration of typical "threshold" p-values:
pcal(c(.1, .05, .01, .005, .001))

# Application: chi-squared goodness-of-fit test,
# lower bound on the posterior probability of the null hypothesis:
x &lt;- matrix(c(12, 41, 25, 33), ncol = 2)
pcal(chisq.test(x)[["p.value"]])

</code></pre>


</div>