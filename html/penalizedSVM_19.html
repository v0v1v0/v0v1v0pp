<div class="container">

<table style="width: 100%;"><tr>
<td>lpsvm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fit L1-norm SVM </h2>

<h3>Description</h3>

<p>SVM with variable selection (clone selection) using L1-norm penalty. 
( a fast Newton algorithm NLPSVM from Fung and Mangasarian ) 
</p>


<h3>Usage</h3>

<pre><code class="language-R">lpsvm(A, d, k = 5, nu = 0, output = 1, delta = 10^-3, epsi = 10^-4, 
seed = 123, maxIter=700)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>A</code></td>
<td>
<p> n-by-d data matrix to train (n chips/patients, d clones/genes).  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>d</code></td>
<td>
<p> vector of class labels  -1 or 1's (for n chips/patiens ). </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>  k-fold for cv, default k=5.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nu</code></td>
<td>
<p> weighted parameter, 1 - easy estimation,
0  - hard estimation, any other value - used as nu by the algorithm.
Default : 0. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output</code></td>
<td>
<p> 0 - no output, 1 - produce output, default is 0. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta</code></td>
<td>
<p> some small value, default: <code class="reqn">10^-3</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsi</code></td>
<td>
<p> tuning parameter.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p> seed. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxIter</code></td>
<td>
<p> maximal iterations, default: 700. </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>k: k-fold for cv, is a way to divide the data set into test and training set.<br>
if k = 0: simply run the algorithm without any correctness
calculation, this is the default. <br>
if k = 1: run the algorithm and calculate correctness on
the whole data set. <br>
if k = any value less than the number of rows in the data set:
divide up the data set into test and training
using k-fold method. <br>
if k = number of rows in the data set: use the 'leave one out' (loo) method
</p>


<h3>Value</h3>

<p>a list of 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>w </code></td>
<td>
<p> coefficients of the hyperplane </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b </code></td>
<td>
<p> intercept of the hyperplane</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xind </code></td>
<td>
<p> the index of the selected features (genes) in the data matrix. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsi </code></td>
<td>
<p> optimal tuning parameter epsilon  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code> iter </code></td>
<td>
<p> number of iterations </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code> k </code></td>
<td>
<p>  k-fold for cv</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code> trainCorr </code></td>
<td>
<p> for cv: average train correctness </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code> testCorr </code></td>
<td>
<p> for cv: average test correctness </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code> nu </code></td>
<td>
<p> weighted parameter </p>
</td>
</tr>
</table>
<h3>Note</h3>

<p> Adapted from MATLAB code  http://www.cs.wisc.edu/dmi/svm/lpsvm/
</p>


<h3>Author(s)</h3>

<p> Natalia Becker </p>


<h3>References</h3>

 
<p>Fung, G. and Mangasarian, O. L. (2004). A feature selection newton method for 
support vector machine classification. <em>Computational Optimization and Applications Journal 28(2)  pp. 185-202</em>. 
</p>


<h3>See Also</h3>

  <p><code>sim.data</code>  </p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(123)
train&lt;-sim.data(n = 20, ng = 100, nsg = 10, corr=FALSE, seed=12)
print(str(train)) 
	
# train data	
model &lt;- lpsvm(A=t(train$x), d=train$y, k=5, nu=0,output=0, delta=10^-3, epsi=0.001, seed=12)
print(model)


</code></pre>


</div>