<div class="container">

<table style="width: 100%;"><tr>
<td>partial.r</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Find the partial correlations for a set (x) of variables with set (y) removed. </h2>

<h3>Description</h3>

<p>A straightforward application of matrix algebra to remove the effect of the variables in the y set from the x set. Input may be either a data matrix or a correlation matrix.  Variables in x and y are specified by location.  If x and y are not specified, then the effect of all variables are partialled from all the other correlations.  May also be done using formula input which is more convenient when comparing results to regression models.  Also has the option to find part (aka semi-partial) correlations.
</p>


<h3>Usage</h3>

<pre><code class="language-R">partial.r(data, x, y, use="pairwise",method="pearson",part=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A data or correlation matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>The variable names or locations associated with the X set (or formula input) </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>The variable  names or locations associated with the Y set to be partialled from the X set</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use</code></td>
<td>
<p>How should we treat missing data? The default is pairwise complete.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>Which method of correlation should we use, the default is pearson.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>part</code></td>
<td>
<p>Find the part correlation (aka semi-partial) , defaults to finding partial correlations</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>There are two ways to use <code>partial.r</code>.  One is to find the complete partial correlation matrix (that is, partial all the other variables out of each variable).  This may be done by simply specifying the raw data or correlation matrix.  (In the case of raw data, correlations will be found according to use and method.)  In this case, just specify the data matrix. 
</p>
<p>Alternatively, if we think of the data as an X matrix and Y matrix, then (D = X + Y) with correlations R.  Then the partial correlations of the X predictors with the Y variables partialled out are just the last column of R^(-1). See the <code>Tal.Or</code> example below.
</p>
<p>The second usage is to partial a set of variables(y) out of another set (x). It is sometimes convenient to partial the effect of a number of variables (e.g., sex, age, education) out of the correlations of another set of variables.  This could be done laboriously by finding the residuals of various multiple correlations, and then correlating these residuals.  The matrix algebra alternative is to do it directly. 
To find the confidence intervals and "significance" of the correlations, use the <code>corr.p</code> function with n = n - s where s is the number of covariates. 
</p>
<p>A perhaps easier format is to use formula input compatible with that used in <code>lmCor</code>. If using formula input,we specify X and Y with the partialled variables specified by subtraction.    That is X ~ Y - z,
This is useful in the case of multiple regression using  which uses this notation.
</p>
<p>Following a thoughtful request from Fransisco Wilheim, I just find the correlations of the variables specified in the call (previously I  had found the entire correlation matrix, which is a waste of time and breaks if some variables are non-numeric).)
</p>
<p>In the case of non-positive definite matrices, find the Pinv (pseudo inverse) of the matrix.
</p>


<h3>Value</h3>

<p>The matrix of partial correlations.</p>


<h3>Author(s)</h3>

<p> William Revelle </p>


<h3>References</h3>

<p> Revelle, W. (in prep) An introduction to psychometric theory with applications in R. To be published by Springer.  (working draft available at  <a href="https://personality-project.org/r/book/">https://personality-project.org/r/book/</a> 
</p>


<h3>See Also</h3>

 <p><code>lmCor</code> for a similar application for regression. <code>lowerMat</code> to neatly show a correlation matrix, and <code>corr.p</code> to find the confidence intervals of a correlation. </p>


<h3>Examples</h3>

<pre><code class="language-R">jen &lt;- make.hierarchical()    #make up a correlation matrix 
lowerMat(jen[1:5,1:5])
par.r &lt;- partial.r(jen,c(1,3,5),c(2,4))
lowerMat(par.r)
#or
R &lt;- jen[1:5,1:5]
par.r &lt;- partial.r(R, y = cs(V2,V4))
lowerMat(par.r)
cp &lt;- corr.p(par.r,n=98)  #assumes the jen data based upon n =100.
print(cp,short=FALSE)  #show the confidence intervals as well
 #partial all from all correlations.
lowerMat(partial.r(jen)) 


#Consider the Tal.Or data set.
lowerCor(Tal.Or)
#partial gender and age from these relations (they hardly change)
partial.r(Tal.Or,1:4,cs(gender,age))
#find the partial correlations between the first three variables and the DV (reaction)
round(partial.r(Tal.Or[1:4])[4,1:3],2) #The partial correlations with the criterion

#Consider the eminence data set from Del Giudice.
if(require("psychTools")) {
data(eminence)
partial.r(reputation ~ works + citations - birth.year, data=eminence)
#now do a part correlation
partial.r(reputation ~ works + citations - birth.year, data=eminence, part=TRUE) 
}


</code></pre>


</div>