<div class="container">

<table style="width: 100%;"><tr>
<td>Control Forest Hyper Parameters</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Control for Conditional Tree Forests </h2>

<h3>Description</h3>

<p>Various parameters that control aspects of the ‘cforest’ fit via
its ‘control’ argument.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cforest_unbiased(...)
cforest_classical(...)
cforest_control(teststat = "max",
                testtype = "Teststatistic",
                mincriterion = qnorm(0.9),
                savesplitstats = FALSE,
                ntree = 500, mtry = 5, replace = TRUE,
                fraction = 0.632, trace = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>teststat</code></td>
<td>
<p> a character specifying the type of the test statistic
to be applied. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>testtype</code></td>
<td>
<p> a character specifying how to compute the distribution of
the test statistic. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mincriterion</code></td>
<td>
<p> the value of the test statistic (for <code>testtype == "Teststatistic"</code>),
or 1 - p-value (for other values of <code>testtype</code>) that
must be exceeded in order to implement a split. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mtry</code></td>
<td>
<p> number of input variables randomly sampled as candidates 
at each node for random forest like algorithms. Bagging, as special case 
of a random forest without random input variable sampling, can 
be performed by setting <code>mtry</code> either equal to <code>NULL</code> or 
manually equal to the number of input variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>savesplitstats</code></td>
<td>
<p> a logical determining whether the process of standardized
two-sample statistics for split point estimate
is saved for each primary split.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ntree</code></td>
<td>
<p> number of trees to grow in a forest.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>replace</code></td>
<td>
<p> a logical indicating whether sampling of observations is 
done with or without replacement.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fraction</code></td>
<td>
<p> fraction of number of observations to draw without 
replacement (only relevant if <code>replace = FALSE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>
<p> a logical indicating if a progress bar shall be printed
while the forest grows.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p> additional arguments to be passed to 
<code>ctree_control</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>All three functions return an object of class <code>ForestControl-class</code>
defining hyper parameters to be specified via the <code>control</code> argument
of <code>cforest</code>.
</p>
<p>The arguments <code>teststat</code>, <code>testtype</code> and <code>mincriterion</code>
determine how the global null hypothesis of independence between all input
variables and the response is tested (see <code>ctree</code>). The 
argument <code>nresample</code> is the number of Monte-Carlo replications to be
used when <code>testtype = "MonteCarlo"</code>.
</p>
<p>A split is established when the sum of the weights in both daugther nodes
is larger than <code>minsplit</code>, this avoids pathological splits at the
borders. When <code>stump = TRUE</code>, a tree with at most two terminal nodes
is computed.
</p>
<p>The <code>mtry</code> argument regulates a random selection of <code>mtry</code> input 
variables in each node. Note that here <code>mtry</code> is fixed to the value 5 by 
default for merely technical reasons, while in <code>randomForest</code> 
the default values for classification and regression vary with the number of input 
variables. Make sure that <code>mtry</code> is defined properly before using <code>cforest</code>.
</p>
<p>It might be informative to look at scatterplots of input variables against
the standardized two-sample split statistics, those are available when
<code>savesplitstats = TRUE</code>. Each node is then associated with a vector
whose length is determined by the number of observations in the learning
sample and thus much more memory is required.
</p>
<p>The number of trees <code>ntree</code> can be increased for large numbers of input variables.
</p>
<p>Function <code>cforest_unbiased</code> returns the settings suggested 
for the construction of unbiased random forests (<code>teststat = "quad", testtype = "Univ", 
    replace = FALSE</code>) by Strobl et al. (2007)
and is the default since version 0.9-90.
Hyper parameter settings mimicing the behaviour of
<code>randomForest</code> are available in
<code>cforest_classical</code> which have been used as default up to
version 0.9-14. 
</p>
<p>Please note that <code>cforest</code>, in contrast to 
<code>randomForest</code>, doesn't grow trees of
maximal depth. To grow large trees, set <code>mincriterion = 0</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>ForestControl-class</code>.
</p>


<h3>References</h3>

<p>Carolin Strobl, Anne-Laure Boulesteix, Achim Zeileis and Torsten Hothorn (2007).
Bias in Random Forest Variable Importance Measures: Illustrations, Sources and  
a Solution. <em>BMC Bioinformatics</em>, <b>8</b>, 25. DOI: 10.1186/1471-2105-8-25
</p>


</div>