<div class="container">

<table style="width: 100%;"><tr>
<td>perryReshape</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Reshape resampling-based prediction error results</h2>

<h3>Description</h3>

<p>Reshape resampling-based prediction error results into an object of class
<code>"perrySelect"</code> with only one column of results.
</p>


<h3>Usage</h3>

<pre><code class="language-R">perryReshape(
  x,
  selectBest = c("min", "hastie"),
  seFactor = 1,
  tuning = list(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>an object inheriting from class <code>"perry"</code> or
<code>"perrySelect"</code> that contains prediction error results.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectBest</code></td>
<td>
<p>a character string specifying a criterion for selecting
the best model.  Possible values are <code>"min"</code> (the default) or
<code>"hastie"</code>.  The former selects the model with the smallest prediction
error.  The latter is useful for nested models or for models with a tuning
parameter controlling the complexity of the model (e.g., penalized
regression).  It selects the most parsimonious model whose prediction error
is no larger than <code>seFactor</code> standard errors above the prediction error
of the best overall model.  Note that the models are thereby assumed to be
ordered from the most parsimonious one to the most complex one.  In
particular a one-standard-error rule is frequently applied.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seFactor</code></td>
<td>
<p>a numeric value giving a multiplication factor of the
standard error for the selection of the best model.  This is ignored if
<code>selectBest</code> is <code>"min"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tuning</code></td>
<td>
<p>a list of tuning parameter values that correspond to the
different prediction error results.  The names of the list components should
thereby correspond to the argument names of the tuning parameters.  For each
tuning parameter, a vector of values can be supplied.  A data frame
containing all possible combinations of tuning parameter values is then
added to the reshaped prediction error results.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments to be passed down.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>An object of class <code>"perrySelect"</code> (subclass
<code>"perryTuning"</code> if a list of tuning parameters is supplied) with the
following components:
</p>

<dl>
<dt><code>pe</code></dt>
<dd>
<p>a data frame containing the estimated prediction errors
for the models.  In case of more than one resampling replication, those
are average values over all replications.</p>
</dd>
<dt><code>se</code></dt>
<dd>
<p>a data frame containing the estimated standard errors of
the prediction loss for the models.</p>
</dd>
<dt><code>reps</code></dt>
<dd>
<p>a data frame containing the estimated prediction errors
for the models from all replications.  This is only returned in case of
more than one resampling replication.</p>
</dd>
<dt><code>splits</code></dt>
<dd>
<p>an object giving the data splits used to estimate the
prediction error.</p>
</dd>
<dt><code>y</code></dt>
<dd>
<p>the response.</p>
</dd>
<dt><code>yHat</code></dt>
<dd>
<p>a list containing the predicted values for the
models.  Each list component is again a list containing the corresponding
predicted values from all replications.</p>
</dd>
<dt><code>best</code></dt>
<dd>
<p>an integer giving the index of the model with the best
prediction performance.</p>
</dd>
<dt><code>selectBest</code></dt>
<dd>
<p>a character string specifying the criterion used for
selecting the best model.</p>
</dd>
<dt><code>seFactor</code></dt>
<dd>
<p>a numeric value giving the multiplication factor of
the standard error used for the selection of the best model.</p>
</dd>
<dt><code>tuning</code></dt>
<dd>
<p>a data frame containing the grid of tuning parameter
values that correspond to the different prediction error results (only
subclass <code>"perryTuning"</code>).</p>
</dd>
</dl>
<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>References</h3>

<p>Hastie, T., Tibshirani, R. and Friedman, J. (2009) <em>The Elements of
Statistical Learning: Data Mining, Inference, and Prediction</em>.  Springer,
2nd edition.
</p>


<h3>See Also</h3>

<p><code>perryFit</code>, <code>perrySelect</code>,
<code>perryTuning</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">library("perryExamples")
data("coleman")

# perform cross-validation for an LTS regression model
fit &lt;- ltsReg(Y ~ ., data = coleman)
folds &lt;- foldControl(K = 5, R = 10)
cv &lt;- perry(fit, splits = folds, fit = "both",
            cost = rtmspe, trim = 0.1, seed = 1234)

# compare original and reshaped object
cv
perryReshape(cv)
</code></pre>


</div>