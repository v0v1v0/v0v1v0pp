<div class="container">

<table style="width: 100%;"><tr>
<td>compare_distributions</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Vuong's test for non-nested models</h2>

<h3>Description</h3>

<p>Since it is possible to fit power law models to any data set,
it is recommended that alternative distributions are considered.
A standard technique is to use Vuong's test.
This is a likelihood ratio test for model selection using the
Kullback-Leibler criteria.
The test statistic, <code>R</code>, is the ratio of the
log-likelihoods of the data between the two competing models.
The sign of <code>R</code> indicates which model is better.
Since the value of <code>R</code> is esimated,
we use the method proposed by Vuong, 1989 to select the model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">compare_distributions(d1, d2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>d1</code></td>
<td>
<p>A distribution object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>d2</code></td>
<td>
<p>A distribution object</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function compares two models.
The null hypothesis is that both classes of distributions are
equally far from the true distribution.  If this is true, the
log-likelihood ratio should (asymptotically) have a Normal distribution
with mean zero. The test statistic is the sample average of the
log-likelihood ratio, standardized by a consistent estimate of its standard
deviation.
If the null hypothesis is false, and one class of distributions is
closer to the "truth", the test statistic goes to +/-infinity
with probability 1, indicating the better-fitting class of distributions.
</p>


<h3>Value</h3>

<p>This function returns
</p>

<dl>
<dt><code>test_statistic</code></dt>
<dd>
<p>The test statistic.</p>
</dd>
<dt><code>p_one_sided</code></dt>
<dd>
<p>A one-sided p-value, which is an upper limit
on getting that small a log-likelihood ratio if the
first distribution, <code>d1</code>, is actually true.</p>
</dd>
<dt><code>p_two_sided</code></dt>
<dd>
<p>A two-sided p-value, which is the probability
of getting a log-likelihood ratio which deviates that much from zero
in either direction, if the two distributions are actually equally good.</p>
</dd>
<dt><code>ratio</code></dt>
<dd>
<p>A data frame with two columns. The first column is
the <code>x</code> value and second column is the difference in
log-likelihoods.</p>
</dd>
</dl>
<h3>Note</h3>

<p>Code initially based on R code developed by
Cosma Rohilla Shalizi (<a href="http://bactra.org/">http://bactra.org/</a>).
Also see Appendix C in Clauset et al, 2009.
</p>


<h3>References</h3>

<p>Vuong, Quang H. (1989):
"Likelihood Ratio Tests for Model Selection and Non-Nested Hypotheses",
Econometrica 57: 307â€“333.
</p>


<h3>Examples</h3>

<pre><code class="language-R">########################################################
# Example data                                         #
########################################################
x = rpldis(100, xmin=2, alpha=3)

########################################################
##Continuous power law                                 #
########################################################
m1 = conpl$new(x)
m1$setXmin(estimate_xmin(m1))

########################################################
##Exponential
########################################################
m2 = conexp$new(x)
m2$setXmin(m1$getXmin())
est2 = estimate_pars(m2)
m2$setPars(est2$pars)

########################################################
##Vuong's test                                         #
########################################################
comp = compare_distributions(m1, m2)
plot(comp)
</code></pre>


</div>