<div class="container">

<table style="width: 100%;"><tr>
<td>rpls</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Ridge Partial Least Square for binary data</h2>

<h3>Description</h3>

<p>The function <code>mrpls</code> performs prediction using Fort and Lambert-Lacroix (2005) RPLS 
algorithm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">rpls(Ytrain,Xtrain,Lambda,ncomp,Xtest=NULL,NbIterMax=50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Xtrain</code></td>
<td>
<p>a (ntrain x p) data matrix of predictors. <code>Xtrain</code> must be a matrix. 
Each row corresponds to an observation and each column to a predictor variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ytrain</code></td>
<td>
<p>a ntrain vector of responses. <code>Ytrain</code> must be a vector. 
<code>Ytrain</code> is a {0,1}-valued vector and contains the response variable for each
observation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xtest</code></td>
<td>
<p>a (ntest x p) matrix containing the predictors for the test data
set. <code>Xtest</code> may also be a vector of length p (corresponding to only one 
test observation).If <code>Xtest</code> is not equal to NULL, then the prediction 
step is made for these new predictor variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Lambda</code></td>
<td>
<p>a positive real value. <code>Lambda</code> is the ridge regularization parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncomp</code></td>
<td>
<p>a positive integer. <code>ncomp</code> is the number of PLS components. 
If <code>ncomp</code>=0,then the Ridge regression is performed without reduction 
dimension. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>NbIterMax</code></td>
<td>
<p>a positive integer. <code>NbIterMax</code> is the maximal number of iterations in the 
Newton-Rapson parts.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The columns of the data matrices <code>Xtrain</code> and <code>Xtest</code> may not be standardized, 
since standardizing is performed by the function <code>rpls</code> as a preliminary step
before the algorithm is run. 
</p>
<p>The procedure described in Fort and Lambert-Lacroix (2005) is used to determine
latent components to be used for classification and when <code>Xtest</code> 
is not equal to NULL, the procedure predicts the labels for these new 
predictor variables.  
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Coefficients</code></td>
<td>
<p>the (p+1) vector containing the coefficients weighting the 
design matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hatY</code></td>
<td>
<p>the ntrain vector containing the estimated {0,1}-valued labels for the 
observations from <code>Xtrain</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hatYtest</code></td>
<td>
<p>the ntest vector containing the predicted {0,1}-valued labels for the 
observations from <code>Xtest</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>proba</code></td>
<td>
<p>the ntrain vector containing the estimated probabilities for the 
observations from <code>Xtrain</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>proba.test</code></td>
<td>
<p>the ntest vector containing the predicted probabilities for the 
observations from <code>Xtest</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DeletedCol</code></td>
<td>
<p>the vector containing the column number of <code>Xtrain</code> when the 
variance of the corresponding predictor variable is null. Otherwise <code>DeletedCol</code>=NULL</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hatYtest_k</code></td>
<td>
<p>If <code>ncomp</code> is greater than 1, <code>hatYtest_k</code> is a {0,1}-valued matrix of 
size ntest x ncomp in such a way that the kth column corresponds to the predicted label 
obtained with k PLS components.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Sophie Lambert-Lacroix 
(<a href="http://membres-timc.imag.fr/Sophie.Lambert/">http://membres-timc.imag.fr/Sophie.Lambert/</a>). 
</p>


<h3>References</h3>

<p>G. Fort and S. Lambert-Lacroix (2005). Classification using Partial Least Squares with 
Penalized Logistic Regression, Bioinformatics, vol 21,  n 8, 1104-1111. 
</p>


<h3>See Also</h3>

<p><code>rpls.cv</code>, <code>mrpls</code>, <code>mrpls.cv</code>.</p>


<h3>Examples</h3>

<pre><code class="language-R"># load plsgenomics library
library(plsgenomics)

# load Colon data
data(Colon)
IndexLearn &lt;- c(sample(which(Colon$Y==2),12),sample(which(Colon$Y==1),8))

# preprocess data
res &lt;- preprocess(Xtrain= Colon$X[IndexLearn,], Xtest=Colon$X[-IndexLearn,],
                    Threshold = c(100,16000),Filtering=c(5,500),
                    log10.scale=TRUE,row.stand=TRUE)
# the results are given in res$pXtrain and res$pXtest

# perform prediction by RPLS
resrpls &lt;- rpls(Ytrain=Colon$Y[IndexLearn]-1,Xtrain=res$pXtrain,Lambda=0.6,ncomp=1,Xtest=res$pXtest)
resrpls$hatY
sum(resrpls$Ytest!=Colon$Y[-IndexLearn])

# prediction for another sample
Xnew &lt;- res$pXtest[1,]
# Compute the linear predictor for each classes expect class 0
eta &lt;- c(1,Xnew) %*% resrpls$Coefficients
Ypred &lt;- which.max(c(0,eta))
Ypred+1



</code></pre>


</div>