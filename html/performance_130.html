<div class="container">

<table style="width: 100%;"><tr>
<td>icc</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Intraclass Correlation Coefficient (ICC)</h2>

<h3>Description</h3>

<p>This function calculates the intraclass-correlation coefficient (ICC) -
sometimes also called <em>variance partition coefficient</em> (VPC) or
<em>repeatability</em> - for mixed effects models. The ICC can be calculated for all
models supported by <code>insight::get_variance()</code>. For models fitted with the
<strong>brms</strong>-package, <code>icc()</code> might fail due to the large variety of
models and families supported by the <strong>brms</strong>-package. In such cases, an
alternative to the ICC is the <code>variance_decomposition()</code>, which is based
on the posterior predictive distribution (see 'Details').
</p>


<h3>Usage</h3>

<pre><code class="language-R">icc(
  model,
  by_group = FALSE,
  tolerance = 1e-05,
  ci = NULL,
  iterations = 100,
  ci_method = NULL,
  null_model = NULL,
  approximation = "lognormal",
  model_component = NULL,
  verbose = TRUE,
  ...
)

variance_decomposition(model, re_formula = NULL, robust = TRUE, ci = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>A (Bayesian) mixed effects model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>by_group</code></td>
<td>
<p>Logical, if <code>TRUE</code>, <code>icc()</code> returns the variance components
for each random-effects level (if there are multiple levels). See 'Details'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tolerance</code></td>
<td>
<p>Tolerance for singularity check of random effects, to decide
whether to compute random effect variances or not. Indicates up to which
value the convergence result is accepted. The larger tolerance is, the
stricter the test will be. See <code>performance::check_singularity()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci</code></td>
<td>
<p>Confidence resp. credible interval level. For <code>icc()</code>, <code>r2()</code>, and
<code>rmse()</code>, confidence intervals are based on bootstrapped samples from the
ICC, R2 or RMSE value. See <code>iterations</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iterations</code></td>
<td>
<p>Number of bootstrap-replicates when computing confidence
intervals for the ICC, R2, RMSE etc.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci_method</code></td>
<td>
<p>Character string, indicating the bootstrap-method. Should
be <code>NULL</code> (default), in which case <code>lme4::bootMer()</code> is used for bootstrapped
confidence intervals. However, if bootstrapped intervals cannot be calculated
this way, try <code>ci_method = "boot"</code>, which falls back to <code>boot::boot()</code>. This
may successfully return bootstrapped confidence intervals, but bootstrapped
samples may not be appropriate for the multilevel structure of the model.
There is also an option <code>ci_method = "analytical"</code>, which tries to calculate
analytical confidence assuming a chi-squared distribution. However, these
intervals are rather inaccurate and often too narrow. It is recommended to
calculate bootstrapped confidence intervals for mixed models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>null_model</code></td>
<td>
<p>Optional, a null model to compute the random effect variances,
which is passed to <code>insight::get_variance()</code>. Usually only required if
calculation of r-squared or ICC fails when <code>null_model</code> is not specified. If
calculating the null model takes longer and you already have fit the null
model, you can pass it here, too, to speed up the process.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>approximation</code></td>
<td>
<p>Character string, indicating the approximation method
for the distribution-specific (observation level, or residual) variance. Only
applies to non-Gaussian models. Can be <code>"lognormal"</code> (default), <code>"delta"</code> or
<code>"trigamma"</code>. For binomial models, the default is the <em>theoretical</em>
distribution specific variance, however, it can also be
<code>"observation_level"</code>. See <em>Nakagawa et al. 2017</em>, in particular supplement
2, for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_component</code></td>
<td>
<p>For models that can have a zero-inflation component,
specify for which component variances should be returned. If <code>NULL</code> or
<code>"full"</code> (the default), both the conditional and the zero-inflation component
are taken into account. If <code>"conditional"</code>, only the conditional component is
considered.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Arguments passed down to <code>lme4::bootMer()</code> or <code>boot::boot()</code>
for bootstrapped ICC, R2, RMSE etc.; for <code>variance_decomposition()</code>,
arguments are passed down to <code>brms::posterior_predict()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>re_formula</code></td>
<td>
<p>Formula containing group-level effects to be considered in
the prediction. If <code>NULL</code> (default), include all group-level effects.
Else, for instance for nested models, name a specific group-level effect
to calculate the variance decomposition for this group-level. See 'Details'
and <code>?brms::posterior_predict</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>robust</code></td>
<td>
<p>Logical, if <code>TRUE</code>, the median instead of mean is used to
calculate the central tendency of the variances.</p>
</td>
</tr>
</table>
<h3>Details</h3>



<h4>Interpretation</h4>

<p>The ICC can be interpreted as "the proportion of the variance explained by
the grouping structure in the population". The grouping structure entails
that measurements are organized into groups (e.g., test scores in a school
can be grouped by classroom if there are multiple classrooms and each
classroom was administered the same test) and ICC indexes how strongly
measurements in the same group resemble each other. This index goes from 0,
if the grouping conveys no information, to 1, if all observations in a group
are identical (<em>Gelman and Hill, 2007, p. 258</em>). In other word, the ICC -
sometimes conceptualized as the measurement repeatability - "can also be
interpreted as the expected correlation between two randomly drawn units
that are in the same group" <em>(Hox 2010: 15)</em>, although this definition might
not apply to mixed models with more complex random effects structures. The
ICC can help determine whether a mixed model is even necessary: an ICC of
zero (or very close to zero) means the observations within clusters are no
more similar than observations from different clusters, and setting it as a
random factor might not be necessary.
</p>



<h4>Difference with R2</h4>

<p>The coefficient of determination R2 (that can be computed with <code>r2()</code>)
quantifies the proportion of variance explained by a statistical model, but
its definition in mixed model is complex (hence, different methods to compute
a proxy exist). ICC is related to R2 because they are both ratios of
variance components. More precisely, R2 is the proportion of the explained
variance (of the full model), while the ICC is the proportion of explained
variance that can be attributed to the random effects. In simple cases, the
ICC corresponds to the difference between the <em>conditional R2</em> and the
<em>marginal R2</em> (see <code>r2_nakagawa()</code>).
</p>



<h4>Calculation</h4>

<p>The ICC is calculated by dividing the random effect variance,
σ<sup>2</sup><sub>i</sub>, by
the total variance, i.e. the sum of the random effect variance and the
residual variance, σ<sup>2</sup><sub>ε</sub>.
</p>



<h4>Adjusted and unadjusted ICC</h4>

<p><code>icc()</code> calculates an adjusted and an unadjusted ICC, which both take all
sources of uncertainty (i.e. of <em>all random effects</em>) into account. While
the <em>adjusted ICC</em> only relates to the random effects, the <em>unadjusted ICC</em>
also takes the fixed effects variances into account, more precisely, the
fixed effects variance is added to the denominator of the formula to
calculate the ICC (see <em>Nakagawa et al. 2017</em>). Typically, the <em>adjusted</em>
ICC is of interest when the analysis of random effects is of interest.
<code>icc()</code> returns a meaningful ICC also for more complex random effects
structures, like models with random slopes or nested design (more than two
levels) and is applicable for models with other distributions than Gaussian.
For more details on the computation of the variances, see
<code>?insight::get_variance</code>.
</p>



<h4>ICC for unconditional and conditional models</h4>

<p>Usually, the ICC is calculated for the null model ("unconditional model").
However, according to <em>Raudenbush and Bryk (2002)</em> or
<em>Rabe-Hesketh and Skrondal (2012)</em> it is also feasible to compute the
ICC for full models with covariates ("conditional models") and compare how
much, e.g., a level-2 variable explains the portion of variation in the
grouping structure (random intercept).
</p>



<h4>ICC for specific group-levels</h4>

<p>The proportion of variance for specific levels related to the overall model
can be computed by setting <code>by_group = TRUE</code>. The reported ICC is
the variance for each (random effect) group compared to the total
variance of the model. For mixed models with a simple random intercept,
this is identical to the classical (adjusted) ICC.
</p>



<h4>Variance decomposition for brms-models</h4>

<p>If <code>model</code> is of class <code>brmsfit</code>, <code>icc()</code> might fail due to the large
variety of models and families supported by the <strong>brms</strong> package. In such
cases, <code>variance_decomposition()</code> is an alternative ICC measure. The function
calculates a variance decomposition based on the posterior predictive
distribution. In this case, first, the draws from the posterior predictive
distribution <em>not conditioned</em> on group-level terms
(<code>posterior_predict(..., re_formula = NA)</code>) are calculated as well as draws
from this distribution <em>conditioned</em> on <em>all random effects</em> (by default,
unless specified else in <code>re_formula</code>) are taken. Then, second, the variances
for each of these draws are calculated. The "ICC" is then the ratio between
these two variances. This is the recommended way to analyse
random-effect-variances for non-Gaussian models. It is then possible to
compare variances across models, also by specifying different group-level
terms via the <code>re_formula</code>-argument.
</p>
<p>Sometimes, when the variance of the posterior predictive distribution is
very large, the variance ratio in the output makes no sense, e.g. because
it is negative. In such cases, it might help to use <code>robust = TRUE</code>.
</p>



<h3>Value</h3>

<p>A list with two values, the adjusted ICC and the unadjusted ICC. For
<code>variance_decomposition()</code>, a list with two values, the decomposed
ICC as well as the credible intervals for this ICC.
</p>


<h3>Supported models and model families</h3>

<p>The single variance components that are required to calculate the marginal
and conditional r-squared values are calculated using the <code>insight::get_variance()</code>
function. The results are validated against the solutions provided by
<em>Nakagawa et al. (2017)</em>, in particular examples shown in the Supplement 2
of the paper. Other model families are validated against results from the
<strong>MuMIn</strong> package. This means that the r-squared values returned by <code>r2_nakagawa()</code>
should be accurate and reliable for following mixed models or model families:
</p>

<ul>
<li>
<p> Bernoulli (logistic) regression
</p>
</li>
<li>
<p> Binomial regression (with other than binary outcomes)
</p>
</li>
<li>
<p> Poisson and Quasi-Poisson regression
</p>
</li>
<li>
<p> Negative binomial regression (including nbinom1 and nbinom2 families)
</p>
</li>
<li>
<p> Gaussian regression (linear models)
</p>
</li>
<li>
<p> Gamma regression
</p>
</li>
<li>
<p> Tweedie regression
</p>
</li>
<li>
<p> Beta regression
</p>
</li>
<li>
<p> Ordered beta regression
</p>
</li>
</ul>
<p>Following model families are not yet validated, but should work:
</p>

<ul>
<li>
<p> Zero-inflated and hurdle models
</p>
</li>
<li>
<p> Beta-binomial regression
</p>
</li>
<li>
<p> Compound Poisson regression
</p>
</li>
<li>
<p> Generalized Poisson regression
</p>
</li>
<li>
<p> Log-normal regression
</p>
</li>
</ul>
<p>Extracting variance components for models with zero-inflation part is not
straightforward, because it is not definitely clear how the distribution-specific
variance should be calculated. Therefore, it is recommended to carefully
inspect the results, and probably validate against other models, e.g. Bayesian
models (although results may be only roughly comparable).
</p>
<p>Log-normal regressions (e.g. <code>lognormal()</code> family in <strong>glmmTMB</strong> or <code>gaussian("log")</code>)
often have a very low fixed effects variance (if they were calculated as
suggested by <em>Nakagawa et al. 2017</em>). This results in very low ICC or
r-squared values, which may not be meaningful.
</p>


<h3>References</h3>


<ul>
<li>
<p> Hox, J. J. (2010). Multilevel analysis: techniques and applications
(2nd ed). New York: Routledge.
</p>
</li>
<li>
<p> Nakagawa, S., Johnson, P. C. D., and Schielzeth, H. (2017). The
coefficient of determination R2 and intra-class correlation coefficient
from generalized linear mixed-effects models revisited and expanded.
Journal of The Royal Society Interface, 14(134), 20170213.
</p>
</li>
<li>
<p> Rabe-Hesketh, S., and Skrondal, A. (2012). Multilevel and longitudinal
modeling using Stata (3rd ed). College Station, Tex: Stata Press
Publication.
</p>
</li>
<li>
<p> Raudenbush, S. W., and Bryk, A. S. (2002). Hierarchical linear models:
applications and data analysis methods (2nd ed). Thousand Oaks: Sage
Publications.
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">
model &lt;- lme4::lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
icc(model)

# ICC for specific group-levels
data(sleepstudy, package = "lme4")
set.seed(12345)
sleepstudy$grp &lt;- sample(1:5, size = 180, replace = TRUE)
sleepstudy$subgrp &lt;- NA
for (i in 1:5) {
  filter_group &lt;- sleepstudy$grp == i
  sleepstudy$subgrp[filter_group] &lt;-
    sample(1:30, size = sum(filter_group), replace = TRUE)
}
model &lt;- lme4::lmer(
  Reaction ~ Days + (1 | grp / subgrp) + (1 | Subject),
  data = sleepstudy
)
icc(model, by_group = TRUE)

</code></pre>


</div>