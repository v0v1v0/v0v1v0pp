<div class="container">

<table style="width: 100%;"><tr>
<td>smote</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
SMOTE algorithm for unbalanced classification problems
</h2>

<h3>Description</h3>

<p>This function handles unbalanced classification problems using the SMOTE
method. Namely, it can generate a new "SMOTEd" data set that addresses
the class unbalance problem. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">smote(form, data, perc.over = 2, k = 5, perc.under = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>form</code></td>
<td>

<p>A formula describing the prediction problem
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>

<p>A data frame containing the original (unbalanced) data set
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>perc.over</code></td>
<td>

<p>A number that drives the decision of how many extra cases from the
minority class are generated (known as over-sampling).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>

<p>A number indicating the number of nearest neighbours that are used to
generate the new examples of the minority class.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>perc.under</code></td>
<td>

<p>A number that drives the decision of how many extra cases from the
majority classes are selected for each case generated from the
minority class (known as under-sampling)
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Unbalanced classification problems cause problems to many learning
algorithms. These problems are characterized by  the uneven proportion
of cases that are available for each class of the problem.
</p>
<p>SMOTE (Chawla et. al. 2002) is a well-known algorithm to fight this
problem. The general idea of this method is to artificially generate
new examples of the minority class using the nearest neighbors of
these cases. Furthermore, the majority class examples are also
under-sampled, leading to a more balanced dataset. 
</p>
<p>The parameters <code>perc.over</code> and <code>perc.under</code> control the amount
of over-sampling of the minority class and under-sampling of the
majority classes, respectively. <code>perc.over</code> will tipically be a
number above 1. With this type of values, for each case in the orginal
data set belonging to the minority class, <code>perc.over</code> new
examples of that class will be created. If <code>perc.over</code> is a value
below 1 than a single case will be generated for a randomly selected
proportion (given by <code>perc.over</code>) of the cases belonging to the
minority class on the original data set. The parameter <code>perc.under</code>
controls the proportion of cases of the majority class that will be
randomly selected for the final "balanced" data set. This proportion is
calculated with respect to the number of newly generated minority class
cases. For instance, if 200 new examples were generated for the minority
class, a value of <code>perc.under</code> of 1 will randomly select exactly 200 cases
belonging to the majority classes from the original data set to belong
to the final data set. Values above 1 will select more examples from
the majority classes. 
</p>
<p>The parameter <code>k</code> controls the way the new examples are
created. For each currently existing minority class example X new
examples will be created (this is controlled by the parameter
<code>perc.over</code> as mentioned above). These examples will be generated
by using the information from the <code>k</code> nearest neighbours of each
example of the minority class. The parameter <code>k</code> controls how many
of these neighbours are used.
</p>


<h3>Value</h3>

<p>The function returns a data frame with
the new data set resulting from the application of the SMOTE
algorithm. 
</p>


<h3>Author(s)</h3>

<p> Luis Torgo <a href="mailto:ltorgo@dcc.fc.up.pt">ltorgo@dcc.fc.up.pt</a> </p>


<h3>References</h3>

<p>Chawla, N. V., Bowyer, K. W., Hall, L. O., and Kegelmeyer, W. P. (2002).
<em>Smote: Synthetic minority over-sampling technique</em>. Journal of Artificial
Intelligence Research, 16:321-357.
</p>
<p>Torgo, L. (2010) <em>Data Mining using R: learning with case studies</em>,
CRC Press (ISBN: 9781439810187).
<a href="http://www.dcc.fc.up.pt/~ltorgo/DataMiningWithR">http://www.dcc.fc.up.pt/~ltorgo/DataMiningWithR</a> 
</p>
<p>Torgo, L. (2014) <em>An Infra-Structure for Performance
Estimation and Experimental Comparison of Predictive Models in R</em>. arXiv:1412.0436 [cs.MS]
<a href="http://arxiv.org/abs/1412.0436">http://arxiv.org/abs/1412.0436</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## A small example with a data set created artificially from the IRIS
## data 
data(iris)
data &lt;- iris[, c(1, 2, 5)]
data$Species &lt;- factor(ifelse(data$Species == "setosa","rare","common")) 
## checking the class distribution of this artificial data set
table(data$Species)

## now using SMOTE to create a more "balanced problem"
newData &lt;- smote(Species ~ ., data, perc.over = 6,perc.under=1)
table(newData$Species)

## Checking visually the created data
## Not run: 
par(mfrow = c(1, 2))
plot(data[, 1], data[, 2], pch = 19 + as.integer(data[, 3]),
     main = "Original Data")
plot(newData[, 1], newData[, 2], pch = 19 + as.integer(newData[,3]),
     main = "SMOTE'd Data")

## End(Not run)

</code></pre>


</div>