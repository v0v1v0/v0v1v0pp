<div class="container">

<table style="width: 100%;"><tr>
<td>convert_tokens</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Ability to tokenize words.</h2>

<h3>Description</h3>

<p>Ability to tokenize words.
</p>


<h3>Usage</h3>

<pre><code class="language-R">convert_tokens(x, path = FALSE, split_pdf = FALSE,
  remove_hyphen = TRUE, token_function = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>The text of the pdf file. This can be specified directly 
or the pdftools package is used to read the pdf file from a file path. 
To use the pdftools, the path argument must be set to TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>path</code></td>
<td>
<p>An optional path designation for the location of the pdf to be 
converted to text. The pdftools package is used for this conversion.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>split_pdf</code></td>
<td>
<p>TRUE/FALSE indicating whether to split the pdf using white 
space. This would be most useful with multicolumn pdf files. 
The split_pdf function attempts to recreate the column layout of the text 
into a single column starting with the left column and proceeding to the 
right.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>remove_hyphen</code></td>
<td>
<p>TRUE/FALSE indicating whether hyphenated words should
be adjusted to combine onto a single line. Default is TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>token_function</code></td>
<td>
<p>This is a function from the tokenizers package. Default
is the tokenize_words function.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list of character vectors containing the tokens. More detail can 
be found looking at the documentation of the tokenizers package.
</p>


<h3>Examples</h3>

<pre><code class="language-R"> file &lt;- system.file('pdf', '1610.00147.pdf', package = 'pdfsearch')
 convert_tokens(file, path = TRUE) 

</code></pre>


</div>