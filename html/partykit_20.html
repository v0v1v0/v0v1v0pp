<div class="container">

<table style="width: 100%;"><tr>
<td>ctree_control</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Control for Conditional Inference Trees </h2>

<h3>Description</h3>

<p>Various parameters that control aspects of the ‘ctree’ fit.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ctree_control(teststat = c("quadratic", "maximum"),
    splitstat = c("quadratic", "maximum"),
    splittest = FALSE,
    testtype = c("Bonferroni", "MonteCarlo", "Univariate", "Teststatistic"),
    pargs = GenzBretz(),
    nmax = c(yx = Inf, z = Inf), alpha = 0.05, mincriterion = 1 - alpha,
    logmincriterion = log(mincriterion), minsplit = 20L, minbucket = 7L,
    minprob = 0.01, stump = FALSE, maxvar = Inf, lookahead = FALSE, 
    MIA = FALSE, nresample = 9999L,
    tol = sqrt(.Machine$double.eps),maxsurrogate = 0L, numsurrogate = FALSE,
    mtry = Inf, maxdepth = Inf,
    multiway = FALSE, splittry = 2L, intersplit = FALSE, majority = FALSE,
    caseweights = TRUE, applyfun = NULL, cores = NULL, saveinfo = TRUE,
    update = NULL, splitflavour = c("ctree", "exhaustive"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>teststat</code></td>
<td>
<p> a character specifying the type of the test statistic
to be applied for variable selection. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>splitstat</code></td>
<td>
<p> a character specifying the type of the test statistic
to be applied for splitpoint selection. Prior to
version 1.2-0, <code>maximum</code> was implemented only.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>splittest</code></td>
<td>
<p> a logical changing linear (the default <code>FALSE</code>) to
maximally selected statistics for
variable selection. Currently needs <code>testtype = "MonteCarlo"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>testtype</code></td>
<td>
<p> a character specifying how to compute the distribution of
the test statistic. The first three options refer to
p-values as criterion, <code>Teststatistic</code> uses the raw
statistic as criterion. <code>Bonferroni</code> and
<code>Univariate</code> relate to p-values from the asymptotic
distribution (adjusted or unadjusted).
Bonferroni-adjusted Monte-Carlo p-values are computed
when both <code>Bonferroni</code> and <code>MonteCarlo</code> are
given.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pargs</code></td>
<td>
<p> control parameters for the computation of multivariate
normal probabilities, see <code>GenzBretz</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nmax</code></td>
<td>
<p> an integer of length two defining the number of bins each variable
(in the response <code>yx</code> and the partitioning variables
<code>z</code>)) and is divided into prior to tree building. The default <code>Inf</code>
does not apply any binning. Highly experimental, use at your own
risk.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p> a double, the significance level for variable selection.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mincriterion</code></td>
<td>
<p> the value of the test statistic or 1 - p-value that
must be exceeded in order to implement a split. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logmincriterion</code></td>
<td>
<p> the value of the test statistic or 1 - p-value that
must be exceeded in order to implement a split on
the log-scale. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minsplit</code></td>
<td>
<p> the minimum sum of weights in a node in order to be considered
for splitting. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minbucket</code></td>
<td>
<p> the minimum sum of weights in a terminal node. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minprob</code></td>
<td>
<p> proportion of observations needed to establish a terminal node.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stump</code></td>
<td>
<p> a logical determining whether a stump (a tree with a maximum of three
nodes only) is to be computed. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxvar</code></td>
<td>
<p> maximum number of variables the tree is allowed to split in.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lookahead</code></td>
<td>
<p> a logical determining whether a split is implemented only
after checking if tests in both daughter nodes can be performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MIA</code></td>
<td>
<p> a logical determining the treatment of <code>NA</code> as a category in split,
see Twala et al. (2008).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nresample</code></td>
<td>
<p> number of permutations for <code>testtype = "MonteCarlo"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>tolerance for zero variances.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxsurrogate</code></td>
<td>
<p> number of surrogate splits to evaluate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>numsurrogate</code></td>
<td>
<p> a logical for backward-compatibility with party. If
<code>TRUE</code>, only at least ordered variables are considered for surrogate splits.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mtry</code></td>
<td>
<p> number of input variables randomly sampled as candidates
at each node for random forest like algorithms. The default
<code>mtry = Inf</code> means that no random selection takes place.
If <code>ctree_control</code> is used in <code>cforest</code>
this argument is ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxdepth</code></td>
<td>
<p> maximum depth of the tree. The default <code>maxdepth = Inf</code>
means that no restrictions are applied to tree sizes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>multiway</code></td>
<td>
<p> a logical indicating if multiway splits for all factor levels
are implemented for unordered factors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>splittry</code></td>
<td>
<p> number of variables that are inspected for admissible splits
if the best split doesn't meet the sample size constraints.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intersplit</code></td>
<td>
<p> a logical indicating if splits in numeric variables
are simply <code>x &lt;= a</code> (the default) or interpolated
<code>x &lt;= (a + b) / 2</code>. The latter feature is experimental, see
Galili and Meilijson (2016).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>majority</code></td>
<td>
<p> if <code>FALSE</code> (the default), observations which can't be classified to a
daughter node because of missing information are randomly
assigned (following the node distribution). If <code>TRUE</code>,
they go with the majority (the default in the first
implementation <code>ctree</code>) in package
party.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>caseweights</code></td>
<td>
<p> a logical interpreting <code>weights</code> as case weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>applyfun</code></td>
<td>
<p>an optional <code>lapply</code>-style function with arguments
<code>function(X, FUN, ...)</code>. It is used for computing the variable selection criterion.
The default is to use the basic <code>lapply</code>
function unless the <code>cores</code> argument is specified (see below).
If <code>ctree_control</code> is used in <code>cforest</code>
this argument is ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cores</code></td>
<td>
<p>numeric. If set to an integer the <code>applyfun</code> is set to
<code>mclapply</code> with the desired number of <code>cores</code>.
If <code>ctree_control</code> is used in <code>cforest</code>
this argument is ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>saveinfo</code></td>
<td>
<p>logical. Store information about variable selection
procedure in <code>info</code> slot of each <code>partynode</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>update</code></td>
<td>
<p>logical. If <code>TRUE</code>, the data transformation is updated
in every node. The default always was and still is not to
update unless <code>ytrafo</code> is a function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>splitflavour</code></td>
<td>
<p>use exhaustive search over splits instead of maximally
selected statistics (<code>ctree</code>). This feature may change.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The arguments <code>teststat</code>, <code>testtype</code> and <code>mincriterion</code>
determine how the global null hypothesis of independence between all input
variables and the response is tested (see <code>ctree</code>).
The variable with most extreme p-value or test statistic is selected
for splitting. If this isn't possible due to sample size constraints
explained in the next paragraph, up to <code>splittry</code> other variables
are inspected for possible splits.
</p>
<p>A split is established when all of the following criteria are met:
1) the sum of the weights in the current node
is larger than <code>minsplit</code>, 2) a fraction of the sum of weights of more than
<code>minprob</code> will be contained in all daughter nodes, 3) the sum of
the weights in all daughter nodes exceeds <code>minbucket</code>, and 4)
the depth of the tree is smaller than <code>maxdepth</code>.
This avoids pathological splits deep down the tree.
When <code>stump = TRUE</code>, a tree with at most two terminal nodes is computed.
</p>
<p>The argument <code>mtry &gt; 0</code> means that a random forest like 'variable
selection', i.e., a random selection of <code>mtry</code> input variables, is
performed in each node.
</p>
<p>In each inner node, <code>maxsurrogate</code> surrogate splits are computed
(regardless of any missing values in the learning sample). Factors
in test samples whose levels were empty in the learning sample
are treated as missing when computing predictions (in contrast
to <code>ctree</code>. Note also the different behaviour of
<code>majority</code> in the two implementations.
</p>


<h3>Value</h3>

<p>A list.
</p>


<h3>References</h3>

<p>B. E. T. H. Twala, M. C. Jones, and D. J. Hand (2008),
Good Methods for Coping with Missing Data in Decision Trees,
<em>Pattern Recognition Letters</em>, <b>29</b>(7), 950–956.
</p>
<p>Tal Galili, Isaac Meilijson (2016), Splitting Matters: How
Monotone Transformation of Predictor Variables May Improve the
Predictions of Decision Tree Models, <a href="https://arxiv.org/abs/1611.04561">https://arxiv.org/abs/1611.04561</a>.
</p>


</div>