<div class="container">

<table style="width: 100%;"><tr>
<td>.plot.EPSGO.parms</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Plot Interval Search Plot Visited Points and the Q Values. </h2>

<h3>Description</h3>

<p>For interval search plot visited points and the Q values (=Ytrain) exclude: for D=1 make  an additional plot: skip values for empty model, for example: Ytrain.exclude=10^16.
</p>


<h3>Usage</h3>

<pre><code class="language-R">.plot.EPSGO.parms(Xtrain, Ytrain,bounds, Ytrain.exclude=10^16, plot.name=NULL )
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Xtrain</code></td>
<td>
<p>X points to train</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ytrain</code></td>
<td>
<p>Y points to train</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bounds</code></td>
<td>
<p> bounds for parameters, see examples</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ytrain.exclude</code></td>
<td>
<p>If exclude for Ytrain exists, skip those  points. Defaults to 10^16.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot.name</code></td>
<td>
<p>Defaults to <code>NULL</code></p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The code source was adopted from MATLAB originals, special thanks to Holger Froehlich.
</p>


<h3>Value</h3>

<p>None, only graphs are created.
</p>


<h3>Author(s)</h3>

<p>Natalia Becker<br><a href="mailto:natalie_becker@gmx.de">natalie_becker@gmx.de</a>
</p>


<h3>References</h3>

<p>Froehlich, H. and Zell, A. (2005) "Effcient parameter selection for support vector
machines in classification and regression via model-based global optimization"
<em>In Proc. Int. Joint Conf. Neural Networks,  1431-1438 </em>.
</p>


<h3>See Also</h3>

 <p><code>svmfs</code>   </p>


<h3>Examples</h3>

<pre><code class="language-R">
	
	seed &lt;- 123
			
	train&lt;-sim.data(n = 200, ng = 100, nsg = 10, corr=FALSE, seed=seed )
	print(str(train)) 
			
	Q.func&lt;- ".calc.scad"
	
	bounds=t(data.frame(log2lambda1=c(-10, 10)))
							colnames(bounds)&lt;-c("lower", "upper")	
			
	print("start interval search")
	# computation intensive; 
	# for demostration reasons only for the first 100 features 
	# and only for 10 iterations maxIter=10, default maxIter=700
	system.time(fit&lt;-EPSGO(Q.func, bounds=bounds, parms.coding="log2", fminlower=0, 
		 show='none', N=21,  maxevals=500, 
		 pdf.name=NULL,  seed=seed,  
		 verbose=FALSE,
		 # Q.func specific parameters:
		 x.svm=t(train$x)[,1:100], y.svm=train$y,
		 inner.val.method="cv",
		 cross.inner=5, maxIter=10 ))
									 
	print(paste("minimal 5-fold cv error:", fit$fmin, "by log2(lambda1)=", fit$xmin))
		
	print(" all lambdas with the same minimum? ")
	print(fit$ points.fmin) 
			
	print(paste(fit$neval, "visited points"))
			
			
	print(" overview: over all visitied points in tuning parameter space 
				with corresponding cv errors")
	print(data.frame(Xtrain=fit$Xtrain, cv.error=fit$Ytrain))

	# create  3 plots om one screen: 
	# 1st plot: distribution of initial points in tuning parameter space
	# 2nd plot: visited lambda points vs. cv errors
	# 3rd plot: the same as the 2nd plot, Ytrain.exclude points are excluded. 
	#    The value cv.error = 10^16 stays for the cv error for an empty model ! 
	.plot.EPSGO.parms (fit$Xtrain, fit$Ytrain,bound=bounds, 
				Ytrain.exclude=10^16, plot.name=NULL )
	 # end of \donttest
</code></pre>


</div>