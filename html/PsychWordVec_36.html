<div class="container">

<table style="width: 100%;"><tr>
<td>text_unmask</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>&lt;Deprecated&gt; Fill in the blank mask(s) in a query (sentence).</h2>

<h3>Description</h3>

<p><em>Note</em>: This function has been deprecated and will not be updated
since I have developed new package
<a href="https://psychbruce.github.io/FMAT/">FMAT</a>
as the integrative toolbox of <em>Fill-Mask Association Test</em> (FMAT).
</p>
<p>Predict the probably correct masked token(s) in a sequence,
based on the Python module <code>transformers</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">text_unmask(query, model, targets = NULL, topn = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>query</code></td>
<td>
<p>A query (sentence/prompt) with masked token(s) <code>[MASK]</code>.
Multiple queries are also supported. See examples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>Model name at <a href="https://huggingface.co/models">HuggingFace</a>.
See <code>text_model_download</code>.
If the model has not been downloaded, it would automatically download the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>targets</code></td>
<td>
<p>Specific target word(s) to be filled in the blank <code>[MASK]</code>.
Defaults to <code>NULL</code> (i.e., return <code>topn</code>).
If specified, then <code>topn</code> will be ignored (see examples).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>topn</code></td>
<td>
<p>Number of the most likely predictions to return.
Defaults to <code>5</code>. If <code>targets</code> is specified,
then it will automatically change to the length of <code>targets</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Masked language modeling is the task of masking some of the words in a sentence
and predicting which words should replace those masks.
These models are useful when we want to get a statistical understanding of
the language in which the model is trained in.
See <a href="https://huggingface.co/tasks/fill-mask">https://huggingface.co/tasks/fill-mask</a> for details.
</p>


<h3>Value</h3>

<p>A <code>data.table</code> of query results:
</p>

<dl>
<dt>
<code>query_id</code> (if there are more than one <code>query</code>)</dt>
<dd>
<p><code>query</code> ID (indicating multiple queries)</p>
</dd>
<dt>
<code>mask_id</code> (if there are more than one <code>[MASK]</code> in <code>query</code>)</dt>
<dd>
<p><code>[MASK]</code> ID (position in sequence, indicating multiple masks)</p>
</dd>
<dt><code>prob</code></dt>
<dd>
<p>Probability of the predicted token in the sequence</p>
</dd>
<dt><code>token_id</code></dt>
<dd>
<p>Predicted token ID (to replace <code>[MASK]</code>)</p>
</dd>
<dt><code>token</code></dt>
<dd>
<p>Predicted token (to replace <code>[MASK]</code>)</p>
</dd>
<dt><code>sequence</code></dt>
<dd>
<p>Complete sentence with the predicted token</p>
</dd>
</dl>
<h3>See Also</h3>

<p><code>text_init</code>
</p>
<p><code>text_model_download</code>
</p>
<p><code>text_model_remove</code>
</p>
<p><code>text_to_vec</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
# text_init()  # initialize the environment

model = "distilbert-base-cased"

text_unmask("Beijing is the [MASK] of China.", model)

# multiple [MASK]s:
text_unmask("Beijing is the [MASK] [MASK] of China.", model)

# multiple queries:
text_unmask(c("The man worked as a [MASK].",
              "The woman worked as a [MASK]."),
            model)

# specific targets:
text_unmask("The [MASK] worked as a nurse.", model,
            targets=c("man", "woman"))

## End(Not run)

</code></pre>


</div>