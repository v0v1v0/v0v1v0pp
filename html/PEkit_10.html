<div class="container">

<table style="width: 100%;"><tr>
<td>tMarLab</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Marginally predicted labels of the test data given training data classification.</h2>

<h3>Description</h3>

<p>Classifies the test data <code>x</code> based on the training data object.
The test data is considered i.i.d., so each
data point is classified one by one.
</p>


<h3>Usage</h3>

<pre><code class="language-R">tMarLab(training, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>training</code></td>
<td>
<p>A training data object from the function <code>classifier.fit()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Test data vector or matrix with rows as data points and columns as features.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Independently assigns a class label for each test data point according to a
<code class="reqn">maximum \, a \, posteriori</code> rule. The predictive probability of data point
<code class="reqn">x_i</code> arising from class <code class="reqn">c</code> assuming the training data of size <code class="reqn">m_c</code> in the class
arises from a Poisson-Dirichlet(<code class="reqn">\hat{\psi}_c</code>) distribution is:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\psi}_c / (m_c + \hat{\psi}_c),</code>
</p>

<p>if no value equal to <code class="reqn">x_i</code> exists in the training data of class <code class="reqn">c</code>, and
</p>
<p style="text-align: center;"><code class="reqn">m_{ci} / (m_c + \hat{\psi}_c),</code>
</p>

<p>if there does, where <code class="reqn">m_{ci}</code> is the frequency of the value of <code class="reqn">x_i</code>
in the training data.
</p>


<h3>Value</h3>

<p>A vector of predicted labels for test data x.
</p>


<h3>References</h3>

<p>Amiryousefi A. Asymptotic supervised predictive classifiers under
partition exchangeability. . 2021. <a href="https://arxiv.org/abs/2101.10950">https://arxiv.org/abs/2101.10950</a>.
</p>
<p>Corander, J., Cui, Y., Koski, T., and Siren, J.: Have I seen you before?
Principles of Bayesian predictive classification revisited. Springer, Stat.
Comput. 23, (2011), 59â€“73, (&lt;doi: <a href="https://doi.org/10.1007/s11222-011-9291-7">10.1007/s11222-011-9291-7</a>&gt;).
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Create random samples x from Poisson-Dirichlet distributions with different
## psis, treating each sample as coming from a class of its own:
set.seed(111)
x1&lt;-rPD(10500,10)
x2&lt;-rPD(10500,1000)
test.ind1&lt;-sample.int(10500,500) # Sample test datasets from the
test.ind2&lt;-sample.int(10500,500) # original samples
x&lt;-c(x1[-test.ind1],x2[-test.ind2])
## create training data labels:
y1&lt;-rep("1", 10000)
y2&lt;-rep("2", 10000)
y&lt;-c(y1,y2)

## Test data t, with first half belonging to class "1", second have in "2":
t1&lt;-x1[test.ind1]
t2&lt;-x2[test.ind2]
t&lt;-c(t1,t2)

fit&lt;-classifier.fit(x,y)

## Run the classifier, which returns
tM&lt;-tMarLab(fit, t)

##With multidimensional x:
set.seed(111)
x1&lt;-cbind(rPD(5500,10),rPD(5500,50))
x2&lt;-cbind(rPD(5500,100),rPD(5500,500))
test.ind1&lt;-sample.int(5500,500)
test.ind2&lt;-sample.int(5500,500)
x&lt;-rbind(x1[-test.ind1,],x2[-test.ind2,])
y1&lt;-rep("1", 5000)
y2&lt;-rep("2", 5000)
y&lt;-c(y1,y2)
fit&lt;-classifier.fit(x,y)
t1&lt;-x1[test.ind1,]
t2&lt;-x2[test.ind2,]
t&lt;-rbind(t1,t2)

tM&lt;-tMarLab(fit, t)
</code></pre>


</div>