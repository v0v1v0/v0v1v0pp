<div class="container">

<table style="width: 100%;"><tr>
<td>bkmodel</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
EM algorithm for the <code class="reqn">\beta_{k}</code> (m=3) Poisson GLM mixture.
</h2>

<h3>Description</h3>

<p>This function applies EM algorithm for estimating a <code class="reqn">K</code>-component mixture of Poisson GLM's, using parameterization <code class="reqn">m=3</code>, that is the <code class="reqn">\beta_{k}</code> model. Initialization can be done using two different intialization schemes. The first one is a one-step small EM procedure. The second  one is  a random splitting small EM procedure based on results of a mixture with less components. Output of the function is the updates of the parameters at each iteration of the EM algorithm, the estimate of <code class="reqn">\gamma</code>, the estimated clusters and conditional probabilities of the observations, as well as the values of the BIC, ICL and loglikelihood of the model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">bkmodel(reference, response, L, m, K, nr, maxnr, t2, m2, 
        prev.z, prev.clust, start.type, prev.alpha, prev.beta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>reference</code></td>
<td>

<p>a numeric array of dimension <code class="reqn">n\times V</code> containing the <code class="reqn">V</code> covariates for each of the <code class="reqn">n</code> observations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>response</code></td>
<td>

<p>a numeric array of count data with dimension <code class="reqn">n\times d</code> containing the <code class="reqn">d</code> response variables for each of the <code class="reqn">n</code> observations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>L</code></td>
<td>
<p>numeric vector of positive integers containing the partition of the <code class="reqn">d</code> response variables into <code class="reqn">J\leq d</code> blocks, with <code class="reqn">\sum_{j=1}^{J}L_j=d</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m</code></td>
<td>
<p>positive integer denoting the maximum number of EM iterations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>positive integer denoting the number of mixture components.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nr</code></td>
<td>
<p>negative number denoting the tolerance for the convergence of the Newton Raphson iterations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxnr</code></td>
<td>
<p>positive integer denoting the maximum number of Newton Raphson iterations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>t2</code></td>
<td>
<p>positive integer denoting the number of different runs of the small EM used by Initialization 1 (<code>init1.k</code>).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m2</code></td>
<td>
<p>positive integer denoting the number of iterations for each call of the small EM iterations used by Initialization 1 (<code>init1.k</code>).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prev.z</code></td>
<td>
<p>numeric array of dimension <code class="reqn">n\times(K-1)</code> containing the estimates of the posterior probabilities according to the previous run of EM. This is used when Initialization 2 is adopted.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prev.clust</code></td>
<td>
<p>numeric vector of length <code class="reqn">n</code> containing the estimated clusters according to the MAP rule obtained by the previous run of EM. This is used when Initialization 2 is adopted.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start.type</code></td>
<td>
<p>binary variable (1 or 2) indicating the type of initialization (1 for initialization 1 and 2 for initialization 2).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prev.alpha</code></td>
<td>
<p>numeric array of dimension <code class="reqn">J\times (K-1)</code> containing the matrix of the ML estimates of the regression constants <code class="reqn">\alpha_{jk}</code>, <code class="reqn">j=1,\ldots,J</code>, <code class="reqn">k=1,\ldots,K-1</code>, based on the previous run of EM algorithm. This is used in case of Initialization 2.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prev.beta</code></td>
<td>
<p>numeric array of dimension <code class="reqn">(K-1)\times T</code> containing the matrix of the ML estimates of the regression coefficients <code class="reqn">\beta_{k\tau}</code>, <code class="reqn">k=1,\ldots,K-1</code>, <code class="reqn">\tau=1,\ldots,T</code>, based on the previous run of EM algorithm. This is used in case of Initialization 2.
</p>
</td>
</tr>
</table>
<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>alpha </code></td>
<td>
<p>numeric array of dimension <code class="reqn">t_{EM}\times J \times K</code> containing the updates of regression constants <code class="reqn">\alpha_{jk}^{(t)})</code>, <code class="reqn">j=1,\ldots,J</code>, <code class="reqn">k=1,\ldots,K</code>, for each iteration <code class="reqn">t=1,2,\ldots,t_{EM}</code> of the EM algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta </code></td>
<td>
<p>numeric array of dimension <code class="reqn">t_{EM}\times K \times T</code> containing the updates of regression coefficients <code class="reqn">\beta_{k\tau}^{(t)})</code>, <code class="reqn">k=1,\ldots,K</code>, <code class="reqn">\tau=1,\ldots,T</code>, for each iteration <code class="reqn">t=1,2,\ldots,t_{EM}</code> of the EM algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma </code></td>
<td>
<p>numeric array of dimension <code class="reqn">J \times \max(L)</code> containing the MLE of <code class="reqn">\gamma_{j\ell}</code>, <code class="reqn">j=1,\ldots,J</code>, <code class="reqn">\ell=1,\ldots,L_j</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>psim </code></td>
<td>
<p>numeric array of dimension <code class="reqn">t_{EM}\times K</code> containing the updates of mixture weights <code class="reqn">\pi_{k}^{(t)})</code>, <code class="reqn">k=1,\ldots,K</code>, for each iteration <code class="reqn">t=1,2,\ldots,t_{EM}</code> of the EM algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>clust </code></td>
<td>
<p>numeric vector of length <code class="reqn">n</code> containing the estimated cluster for each observation according to the MAP rule.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>z </code></td>
<td>
<p>numeric array of length <code class="reqn">n\times K</code> containing the estimated conditional probabilities <code class="reqn">\tau_{ik}</code>, <code class="reqn">i=1,\ldots,n</code>, <code class="reqn">k=,\ldots,K</code>, according to the last iteration of the EM algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bic </code></td>
<td>
<p>numeric, the value of the BIC.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>icl </code></td>
<td>
<p>numeric, the value of the ICL.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ll </code></td>
<td>
<p>numeric, the value of the loglikelihood, computed according to the <code>mylogLikePoisMix</code> function.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>See Also</h3>

<p><code>init1.k</code>, <code>init2.k</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">############################################################
#1.            Example with Initialization 1               #
############################################################


## load a simulated dataset according to the b_jk model
## number of observations: 500
## design: L=(3,2,1)
data("simulated_data_15_components_bjk")
x &lt;- sim.data[,1]
x &lt;- array(x,dim=c(length(x),1))
y &lt;- sim.data[,-1]
## use Initialization 1 with 2 components
## the number of different small runs equals t2=5, 
##	each one consisting of m1 = 5 iterations
## the maximum number of EM iterations is set to m = 1000.
nc &lt;- 2
run &lt;- bkmodel(reference=x, response=y, L=c(3,2,1), m=1000, K=nc, nr=-10*log(10), 
               maxnr=10, t2=5, m2=5, prev.z, prev.clust, start.type=1, 
               prev.alpha, prev.beta)
## retrieve the iteration that the small em converged:
tem &lt;- length(run$psim)/nc
## print the estimate of regression constants alpha.
run$alpha[tem,,]
## print the estimate of regression coefficients beta.
beta &lt;- run$beta[tem,,]
## print the estimate of gamma.
run$gamma
## print the estimate of mixture weights.
run$psim[tem,]
## frequency table of the resulting clustering of the 
##		500 observations among the 2 components.
table(run$clust)
## print the value of the ICL criterion
run$icl
## print the value of the BIC
run$bic
## print the value of the loglikelihood
run$ll


############################################################
#2.            Example with Initialization 2               #
############################################################

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Given the estimates of Example 1, estimate a 3-component mixture using   ~
# Initialization 2. The number of different runs is set to $t2=2$ with     ~
# each one of them using $m2=5$ em iterations.                             ~
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
run.previous&lt;-run
## number of conditions
q &lt;- 3
## number of covariates
tau &lt;- 1
## number of components
nc &lt;- 3
## estimated conditional probabilities for K=10
z &lt;- run.previous$z
## number of iteration that the previous EM converged
ml &lt;- length(run.previous$psim)/(nc - 1) 	
## estimates of alpha when K=2
alpha &lt;- array(run.previous$alpha[ml, , ], dim = c(q, nc - 1)) 
## estimates of beta when K=2
beta &lt;- array(run.previous$beta[ml, , ], dim = c(nc - 1, tau))
clust &lt;- run.previous$clust ##(estimated clusters when K=2)


run &lt;- bkmodel(reference=x, response=y, L=c(3,2,1), m=1000, K=nc, nr=-10*log(10), 
               maxnr=10, t2=2, m2=5, prev.z=z, prev.clust=clust, start.type=2, 
               prev.alpha=alpha, prev.beta=beta)

# retrieve the iteration that EM converged 
tem &lt;- length(run$psim)/nc
# estimates of the mixture weights
run$psim[tem,]
# estimates of the regression constants alpha_{jk}, j = 1,2,3, k=1,..,11
run$alpha[tem,,]
# estimates of the regression coefficients beta_{k\tau}, k = 1,..,11, \tau=1
run$beta[tem,,]

# note: useR should specify larger values for Kmax, m1, m2, t1, t2 
#	for a complete analysis.



</code></pre>


</div>