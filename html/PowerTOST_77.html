<div class="container">

<table style="width: 100%;"><tr>
<td>sampleN.scABEL.sdsims</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Sample size estimation for BE decision via scaled (expanded) BE acceptance limits
</h2>

<h3>Description</h3>

<p>These functions performs the sample size estimation via power calculations of the BE decision via scaled (expanded) BE acceptance limits, based on <b>subject data</b> simulations.<br>
This function has an alias sampleN.scABEL.sds().
</p>


<h3>Usage</h3>

<pre><code class="language-R">sampleN.scABEL.sdsims(alpha = 0.05, targetpower = 0.8, theta0, theta1,
                      theta2, CV, design = c("2x3x3", "2x2x4", "2x2x3"),
                      regulator, nsims = 1e5, nstart, imax = 100,
                      print = TRUE, details = TRUE,
                      setseed = TRUE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>

<p>Type I error probability. Per convention mostly set to 0.05.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>targetpower</code></td>
<td>

<p>Power to achieve at least. Must be &gt;0 and &lt;1.<br>
Typical values are 0.8 or 0.9.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta0</code></td>
<td>

<p>‘True’ or assumed T/R ratio. <br>
Defaults to 0.90 according to the two Lászlós if not given explicitly.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta1</code></td>
<td>

<p>Conventional lower ABE limit to be applied in the mixed procedure if
<code>CVsWR &lt;= CVswitch</code>.<br>
Also Lower limit for the point estimate constraint.<br>
Defaults to 0.8 if not given explicitly.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta2</code></td>
<td>

<p>Conventional upper ABE limit to be applied in the mixed procedure if
<code>CVsWR &lt;= CVswitch</code>. Also upper limit for the point estimate constraint.<br>
Defaults to 1.25 if not given explicitly.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li>
<p> If given as a scalar (<code>length(CV) == 1</code>) the <em>same</em> <em>CV</em> of Test
and Reference is assumed (homoscedasticity, <em>CV</em><sub>wT</sub> = <em>CV</em><sub>wR</sub>).
</p>
</li>
<li>
<p> If given as a vector (<code>length(CV) == 2</code>), <em>i.e.</em>, assuming heteroscedasticity, the <em>CV</em> of the Test <strong>must</strong> be given in
<code>CV[1]</code> and the one of the Reference in the <code>CV[2]</code>.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>design</code></td>
<td>

<p>Design of the study to be planned.<br><code>"2x3x3"</code> is the partial replicate design.<br><code>"2x2x4"</code> is a full replicate design with 2 sequences and 4 periods.<br><code>"2x2x3"</code> is a full replicate design with 2 sequences and 3 periods.<br>
Defaults to <code>"2x3x3"</code>. Details are given the section about Designs.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>regulator</code></td>
<td>

<p>Regulatory settings for the widening of the BE acceptance limits.<br>
May be given as <code>"EMA"</code>, <code>"GCC"</code>, or as an object of class 'regSet' (see <code>reg_const</code>).<br>
Defaults to <code>regulator = "EMA"</code> if missing.<br>
This argument may be given also in lower case if given as character.<br>
If given as object of class 'regSet' the component <code>est_method</code> must not be <code>"ISC"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nsims</code></td>
<td>

<p>Number of simulations to be performed to obtain the (empirical) power.
The default value 100,000 = 1e+5 is usually sufficient. Consider to rise
this value if <code>theta0</code> &lt;=0.85 or &gt;=1.20. But see the warning section.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nstart</code></td>
<td>

<p>Set this to a start for the sample size search if a previous run failed.<br>
After reworking the start n in version 1.1-05 rarely needed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>imax</code></td>
<td>

<p>Maximum number of steps in sample size search. Defaults to 100.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>print</code></td>
<td>

<p>If <code style="white-space: pre;">⁠TRUE⁠</code> (default) the function prints its results. If <code style="white-space: pre;">⁠FALSE⁠</code> only the result data.frame will be returned.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>details</code></td>
<td>

<p>If set to <code>TRUE</code> (default), the steps during sample size search are shown.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo) random number generator. To avoid differences in power for different runs a <code>set.seed(123456)</code> is issued if <code>setseed = TRUE</code>, the default.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>progress</code></td>
<td>

<p>Should a progressbar be shown? Defaults to <code>TRUE</code> if missing and <code>nsims</code> &gt;5E5.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The methods rely on the analysis of log-transformed data, <em>i.e.</em>, assume a
log-normal distribution on the original scale.<br><br>
The expanded BE acceptance limits will be calculated by the formula<br><code style="white-space: pre;">⁠  [L, U] = exp(± r_const * sWR)⁠</code><br>
with <code>r_const</code> the regulatory constant and <code>sWR</code> the standard deviation of the within
subjects variability of the Reference. <code>r_const = 0.76</code> (~log(1.25)/0.29356) is used
in case of <code>regulator = "EMA"</code>.
If the CVwR is &lt; CVswitch=0.3 the conventional ABE limits apply (mixed procedure).<br>
In case of <code>regulator="EMA"</code> a cap is placed on the widened limits if
<em>CV</em><sub>wR</sub> &gt; 0.50, <em>i.e.</em>, the widened limits are held at value calculated for <em>CV</em><sub>wR</sub> = 0.50.<br>
In case of <code>regulator="GCC"</code> <em>fixed</em> wider limits of 0.7500 – 1.3333 for <em>CV</em><sub>wR</sub> &gt; 0.30 are applied and the conventional limits otherwise.<br><br>
The simulations are done by simulating subject data (all effects fixed except the
residuals) and evaluating these data via ANOVA of all data to get the point estimate
of T vs. R along with its 90% CI and an ANOVA of the data under R(eference) only
to get an estimate of <em>s</em>²<sub>wR</sub>.<br><br>
The estimated sample size gives always the <em>total</em> number of subjects (not subject/sequence – like in some other software packages).
</p>


<h3>Value</h3>

<p>Returns a data.frame with the input settings and sample size results.<br>
The <code>Sample size</code> column contains the total sample size.<br>
The <code>nlast</code> column contains the last <code>n</code> value. May be useful for restarting.
</p>


<h3>Designs</h3>

<p>Although some designs are more ‘popular’ than others, sample size estimations are valid for <em>all</em> of the following designs:
</p>

<table>
<tr>
<td style="text-align: left;">
    <code>"2x2x4"</code> </td>
<td style="text-align: left;"> TRTR | RTRT</td>
</tr>
<tr>
<td style="text-align: left;">
    </td>
<td style="text-align: left;"> TRRT | RTTR</td>
</tr>
<tr>
<td style="text-align: left;">
    </td>
<td style="text-align: left;"> TTRR | RRTT</td>
</tr>
<tr>
<td style="text-align: left;">
    <code>"2x2x3"</code> </td>
<td style="text-align: left;"> TRT | RTR</td>
</tr>
<tr>
<td style="text-align: left;">
    </td>
<td style="text-align: left;"> TRR | RTT</td>
</tr>
<tr>
<td style="text-align: left;">
    <code>"2x3x3"</code> </td>
<td style="text-align: left;"> TRR | RTR | RRT
  </td>
</tr>
</table>
<h3>Warning </h3>

<p>The sample size estimation for very extreme <code>theta0</code> (&lt;0.83 or &gt;1.21) may be very
time consuming and will eventually also fail since the start values chosen are
not really reasonable in that ranges.<br>
If you really need sample sizes in that range be prepared to restart the sample
size estimation via the argument nstart.<br>
Since the dependence of power from n is very flat in the mentioned region you may
also consider to adapt the number of simulations not to get caught in the simulation
error trap.
</p>


<h3>Note</h3>

<p>We are doing the sample size estimation only for balanced designs since the
break down of the total subject number in case of unbalanced sequence groups
is not unique. Moreover the formulas used are only for balanced designs.<br>
The minimum sample size is 6, even if the power is higher than the intended
targetpower.<br><br>
Subject simulations are easily more than 100times slower than simulations based
on the ‘key’ statistics. We recommend this function only for the partial
replicate design (TRR|RTR|RRT) assuming heteroscedasticity in the case of  <em>CV</em><sub>wT</sub> &gt; <em>CV</em><sub>wR</sub>.<br>
Thus be patient and go for a cup of coffee if you use this function with high
sample sizes!
</p>


<h3>Author(s)</h3>

<p>H. Schütz
</p>


<h3>References</h3>

<p>Tóthfalusi L, Endrényi L. <em>Sample Sizes for Designing Bioequivalence Studies for Highly Variable Drugs.</em> J Pharm Pharmaceut Sci. 2011;15(1):73–84. <a href="http://ejournals.library.ualberta.ca/index.php/JPPS/article/download/11612/9489">open access</a>
</p>


<h3>See Also</h3>

<p><code>power.scABEL.sdsims</code>, <code>sampleN.scABEL</code>, <code>reg_const</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># using the defaults:
# partial replicate design, targetpower=80%,
# true assumed ratio = 0.90, 1E+5 simulated studies
# ABE limits, PE constraint 0.8 - 1.25
# EMA regulatory settings
# Heteroscedasticity (CVwT 0.4, CVwR 0.3)
# compare results and run times

CV           &lt;- c(0.4, 0.3)
expl         &lt;- data.frame(method = c("subject simulations", "\'key\' statistics"),
                           n = NA, power = NA, seconds = NA)
start        &lt;- proc.time()[[3]]
expl[1, 2:3] &lt;- sampleN.scABEL.sdsims(CV = CV, print = FALSE,
                                      details = FALSE)[8:9]
expl[1, 4]   &lt;- proc.time()[[3]] - start
start        &lt;- proc.time()[[3]]
expl[2, 2:3] &lt;- sampleN.scABEL(CV = CV, print = FALSE,
                               details = FALSE)[8:9]
expl[2, 4]   &lt;- proc.time()[[3]] - start
print(expl, row.names = FALSE)
# should result in a sample size n=69, power=0.80198 for
# the subject simulations and n=66, power=0.80775 for the
# 'key' statistics
</code></pre>


</div>