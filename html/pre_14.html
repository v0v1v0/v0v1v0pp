<div class="container">

<table style="width: 100%;"><tr>
<td>gpe_rules_pre</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Get rule learner for gpe which mimics behavior of pre</h2>

<h3>Description</h3>

<p><code>gpe_rules_pre</code> generates a learner which generates rules like 
<code>pre</code>, which can be supplied to the <code>gpe</code> 
base_learner argument.
</p>


<h3>Usage</h3>

<pre><code class="language-R">gpe_rules_pre(
  learnrate = 0.01,
  par.init = FALSE,
  mtry = Inf,
  maxdepth = 3L,
  ntrees = 500,
  tree.control = ctree_control(),
  use.grad = TRUE,
  removeduplicates = TRUE,
  removecomplements = TRUE,
  tree.unbiased = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>learnrate</code></td>
<td>
<p>numeric value <code class="reqn">&gt; 0</code>. Learning rate or boosting parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>par.init</code></td>
<td>
<p>logical. Should parallel <code>foreach</code> be used to generate 
initial ensemble? Only used when <code>learnrate == 0</code>. Note: Must register 
parallel beforehand, such as doMC or others. Furthermore, setting 
<code>par.init = TRUE</code> will likely only increase computation time for smaller 
datasets.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mtry</code></td>
<td>
<p>positive integer. Number of randomly selected predictor variables for 
creating each split in each tree. Ignored when <code>tree.unbiased=FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxdepth</code></td>
<td>
<p>positive integer. Maximum number of conditions in rules. 
If <code>length(maxdepth) == 1</code>, it specifies the maximum depth of 
of each tree grown. If <code>length(maxdepth) == ntrees</code>, it specifies the
maximum depth of every consecutive tree grown. Alternatively, a random
sampling function may be supplied, which takes argument <code>ntrees</code> and 
returns integer values. See also <code>maxdepth_sampler</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ntrees</code></td>
<td>
<p>positive integer value. Number of trees to generate for the 
initial ensemble.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tree.control</code></td>
<td>
<p>list with control parameters to be passed to the tree 
fitting function, generated using <code>ctree_control</code>,
<code>mob_control</code> (if <code>use.grad = FALSE</code>), or 
<code>rpart.control</code> (if <code>tree.unbiased = FALSE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use.grad</code></td>
<td>
<p>logical. Should gradient boosting with regression trees be
employed when <code>learnrate &gt; 0</code>? If <code>TRUE</code>, use trees fitted by 
<code>ctree</code> or <code>rpart</code> as in Friedman 
(2001), but without the line search. If <code>use.grad = FALSE</code>, 
<code>glmtree</code> instead of <code>ctree</code> 
will be employed for rule induction, yielding longer computation times, 
higher complexity, but possibly higher predictive accuracy. See Details for 
supported combinations of <code>family</code>, <code>use.grad</code> and <code>learnrate</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>removeduplicates</code></td>
<td>
<p>logical. Remove rules from the ensemble which are 
identical to an earlier rule?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>removecomplements</code></td>
<td>
<p>logical. Remove rules from the ensemble which are
identical to (1 - an earlier rule)?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tree.unbiased</code></td>
<td>
<p>logical. Should an unbiased tree generation algorithm 
be employed for rule generation? Defaults to <code>TRUE</code>, if set to 
<code>FALSE</code>, rules will be generated employing the CART algorithm
(which suffers from biased variable selection) as implemented in 
<code>rpart</code>. See details below for possible combinations 
with <code>family</code>, <code>use.grad</code> and <code>learnrate</code>.</p>
</td>
</tr>
</table>
<h3>Examples</h3>

<pre><code class="language-R">## Obtain same fits with pre and gpe
set.seed(42)
gpe.mod &lt;- gpe(Ozone ~ ., data = airquality[complete.cases(airquality),],  
               base_learners = list(gpe_rules_pre(), gpe_linear()))
gpe.mod                
set.seed(42)
pre.mod &lt;- pre(Ozone ~ ., data = airquality[complete.cases(airquality),],)
pre.mod
</code></pre>


</div>