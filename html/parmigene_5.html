<div class="container">

<table style="width: 100%;"><tr>
<td>knnmi.all</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Parallel Mutual Information Estimation Between All Matrix Rows</h2>

<h3>Description</h3>

<p>A function that computes the mutual information between all pairs
of rows of matrix <code>mat</code> using entropy estimates from K-nearest neighbor distances.
</p>


<h3>Usage</h3>

<pre><code class="language-R">knnmi.all(mat, k=3, noise=1e-12)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>mat</code></td>
<td>
<p>a numeric matrix (for the reconstruction of gene regulatory
networks, genes on rows and samples on columns).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>the number of nearest neighbors to consider to estimate the
mutual information. Must be less than the number of columns of <code>mat</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>noise</code></td>
<td>
<p>the magnitude of the random noise added to break ties.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function adds a small random noise to the data in order to break ties due
to limited numerical precision.
</p>
<p>By default, the function uses all the available cores. You can
set the actual number of threads used to N by exporting the
environment variable <code>OMP_NUM_THREADS=N</code>.
</p>


<h3>References</h3>

<p>Kraskov, Alexander  and Stogbauer, Harald  and Grassberger, Peter.
<em>Estimating mutual information.</em> Phys. Rev. E, 2004.
</p>


<h3>See Also</h3>

<p><code>knnmi</code>
</p>
<p><code>knnmi.cross</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">mat &lt;- matrix(rnorm(1000), nrow=10)
knnmi.all(mat, 5)
</code></pre>


</div>