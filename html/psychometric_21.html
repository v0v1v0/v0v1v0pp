<div class="container">

<table style="width: 100%;"><tr>
<td>ClassUtil</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Classical Utility of a Test </h2>

<h3>Description</h3>

<p>Calculate the classical utility of a test given a correlation, base-rate and selection ratio.</p>


<h3>Usage</h3>

<pre><code class="language-R">ClassUtil(rxy = 0, BR = 0.5, SR = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>rxy</code></td>
<td>
<p> Correlation of Test X with Outcome Y </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>BR</code></td>
<td>
<p> Base Rate or prevalence without use of a test</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>SR</code></td>
<td>
<p> Selection Ratio: Number selected out of those tested </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The degree of utility of using a test as a selection instrument over randomly 
selecting individuals can be reflected in the decision outcomes expected by using the 
selection instrument. Suppose you have a predictor (selection instrument) and a criterion 
(job performance). By regressing the criterion on the predictor, and selecting individuals 
based on some cut-off value, we have 4 possible outcomes. A = True Positives, B = True Negatives, 
C = False Negatives, and D = False Positives. The classical utility of using the test over 
current procedures (random selection) is:
</p>
<p>[A / (A+D)] - [(A + C) / (A + B + C + D)]
</p>
<p>Various manipulations of these relationships can be used to assist in decision making. 
</p>


<h3>Value</h3>

<p>Returns a table with the following elements reflecting decision outcomes:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>True Positives</code></td>
<td>
<p> Probability of correctly selecting a successful candidate </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>False Negatives</code></td>
<td>
<p> Probability of incorrectly not selecting a successful candidate </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>False Positives</code></td>
<td>
<p> Probability of incorrectly selecting an unsuccessful candidate </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>True Negatives</code></td>
<td>
<p> Probability of correctly not selecting an unsuccessful candidate </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Sensitivity</code></td>
<td>
<p> True Positives / (True Positives + False Negatives)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Specificity</code></td>
<td>
<p> True Negatives / (True Negatives + False Positives)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>% of Decisions Correct</code></td>
<td>
<p> Percentage of correct decisions</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Proportion Selected Succesful</code></td>
<td>
<p> Proportion of those selected expected to be successful</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>% Improvement over BR</code></td>
<td>
<p> Percentage of improvement using the test over random selection</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Murphy, K. R. &amp; Davidshofer, C. O. (2005). <em>Psychological testing: Principles and 
applications (5th ed.).</em> Saddle River, NJ: Prentice Hall.
</p>


<h3>See Also</h3>

 <p><code>Utility</code> </p>


<h3>Examples</h3>

<pre><code class="language-R"># 50 percent of those randomly selected are expected to be successful
# A company need only select 1/10 applicants
# The correlation between test scores and performance is .35
ClassUtil(.35, .5, .1)

</code></pre>


</div>