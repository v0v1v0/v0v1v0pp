<div class="container">

<table style="width: 100%;"><tr>
<td>gibbsPLMIX</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Gibbs sampling for a Bayesian mixture of Plackett-Luce models</h2>

<h3>Description</h3>

<p>Perform Gibbs sampling simulation for a Bayesian mixture of Plackett-Luce models fitted to partial orderings.
</p>


<h3>Usage</h3>

<pre><code class="language-R">gibbsPLMIX(pi_inv, K, G, init = list(z = NULL, p = NULL),
  n_iter = 1000, n_burn = 500, hyper = list(shape0 = matrix(1, nrow =
  G, ncol = K), rate0 = rep(0.001, G), alpha0 = rep(1, G)),
  centered_start = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>pi_inv</code></td>
<td>
<p>An object of class <code>top_ordering</code>, collecting the numeric <code class="reqn">N</code><code class="reqn">\times</code><code class="reqn">K</code> data matrix of partial orderings, or an object that can be coerced with <code>as.top_ordering</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>Number of possible items.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>G</code></td>
<td>
<p>Number of mixture components.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>init</code></td>
<td>
<p>List of named objects with initialization values: <code>z</code> is a numeric <code class="reqn">N</code><code class="reqn">\times</code><code class="reqn">G</code> matrix of binary mixture component memberships; <code>p</code> is a numeric <code class="reqn">G</code><code class="reqn">\times</code><code class="reqn">K</code> matrix of component-specific support parameters. If starting values are not supplied (<code>NULL</code>), they are randomly generated with a uniform distribution. Default is <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_iter</code></td>
<td>
<p>Total number of MCMC iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_burn</code></td>
<td>
<p>Number of initial burn-in drawings removed from the returned MCMC sample.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hyper</code></td>
<td>
<p>List of named objects with hyperparameter values for the conjugate prior specification: <code>shape0</code> is a numeric <code class="reqn">G</code><code class="reqn">\times</code><code class="reqn">K</code> matrix of shape hyperparameters; <code>rate0</code> is a numeric vector of <code class="reqn">G</code> rate hyperparameters; <code>alpha0</code> is a numeric vector of <code class="reqn">G</code> Dirichlet hyperparameters. Default is vague prior setting.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>centered_start</code></td>
<td>
<p>Logical: whether a random start whose support parameters and weights should be centered around the observed relative frequency that each item has been ranked top. Default is <code>FALSE</code>. Ignored when <code>init</code> is not <code>NULL</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The size <code class="reqn">L</code> of the final MCMC sample is equal to <code>n_iter</code>-<code>n_burn</code>.
</p>


<h3>Value</h3>

<p>A list of S3 class <code>gsPLMIX</code> with named elements:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>W</code></td>
<td>
<p> Numeric <code class="reqn">L</code><code class="reqn">\times</code><code class="reqn">G</code> matrix with MCMC samples of the mixture weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>P</code></td>
<td>
<p> Numeric <code class="reqn">L</code><code class="reqn">\times</code><code class="reqn">(G*K)</code> matrix with MCMC samples of the component-specific support parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>log_lik</code></td>
<td>
<p> Numeric vector of <code class="reqn">L</code> posterior log-likelihood values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>deviance</code></td>
<td>
<p> Numeric vector of <code class="reqn">L</code> posterior deviance values (<code class="reqn">-2 * </code><code>log_lik</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>objective</code></td>
<td>
<p> Numeric vector of <code class="reqn">L</code> objective function values (that is the kernel of the log-posterior distribution).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p> The matched call.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Cristina Mollica and Luca Tardella
</p>


<h3>References</h3>

<p>Mollica, C. and Tardella, L. (2017). Bayesian Plackett-Luce mixture models for partially ranked data. <em>Psychometrika</em>, <b>82</b>(2), pages 442â€“458, ISSN: 0033-3123, DOI: 10.1007/s11336-016-9530-0.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(d_carconf)
GIBBS &lt;- gibbsPLMIX(pi_inv=d_carconf, K=ncol(d_carconf), G=3, n_iter=30, n_burn=10)
str(GIBBS)
GIBBS$P
GIBBS$W

</code></pre>


</div>