<div class="container">

<table style="width: 100%;"><tr>
<td>cv.plsRglm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Partial least squares regression glm models with k-fold cross validation</h2>

<h3>Description</h3>

<p>This function implements k-fold cross-validation on complete or incomplete datasets for partial least squares regression generalized linear models
</p>


<h3>Usage</h3>

<pre><code class="language-R">cv.plsRglm(object, ...)
## Default S3 method:
cv.plsRglmmodel(object,dataX,nt=2,limQ2set=.0975,
modele="pls", family=NULL, K=5, NK=1, grouplist=NULL, random=TRUE, 
scaleX=TRUE, scaleY=NULL, keepcoeffs=FALSE, keepfolds=FALSE, 
keepdataY=TRUE, keepMclassed=FALSE, tol_Xi=10^(-12), weights, method,
verbose=TRUE,...)
## S3 method for class 'formula'
cv.plsRglmmodel(object,data=NULL,nt=2,limQ2set=.0975,
modele="pls", family=NULL, K=5, NK=1, grouplist=NULL, random=TRUE, 
scaleX=TRUE, scaleY=NULL, keepcoeffs=FALSE, keepfolds=FALSE, 
keepdataY=TRUE, keepMclassed=FALSE, tol_Xi=10^(-12),weights,subset,
start=NULL,etastart,mustart,offset,method,control= list(),contrasts=NULL,
verbose=TRUE,...)
PLS_glm_kfoldcv(dataY, dataX, nt = 2, limQ2set = 0.0975, modele = "pls", 
family = NULL, K = 5, NK = 1, grouplist = NULL, random = TRUE, 
scaleX = TRUE, scaleY = NULL, keepcoeffs = FALSE, keepfolds = FALSE, 
keepdataY = TRUE, keepMclassed=FALSE, tol_Xi = 10^(-12), weights, method,
verbose=TRUE)
PLS_glm_kfoldcv_formula(formula,data=NULL,nt=2,limQ2set=.0975,modele="pls",
family=NULL, K=5, NK=1, grouplist=NULL, random=TRUE, 
scaleX=TRUE, scaleY=NULL, keepcoeffs=FALSE, keepfolds=FALSE, keepdataY=TRUE, 
keepMclassed=FALSE, tol_Xi=10^(-12),weights,subset,start=NULL,etastart,
mustart,offset,method,control= list(),contrasts=NULL, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>response (training) dataset or an object of class "<code>formula</code>" (or one that can be coerced to that class): a symbolic description of the model to be fitted. The details of model specification are given under 'Details'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataY</code></td>
<td>
<p>response (training) dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataX</code></td>
<td>
<p>predictor(s) (training) dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>an object of class "<code>formula</code>" (or one that can be coerced to that class): a symbolic description of the model to be fitted. The details of model specification are given under 'Details'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>an optional data frame, list or environment (or object coercible by <code>as.data.frame</code> to a data frame) containing the variables in the model. If not found in <code>data</code>, the variables are taken from <code>environment(formula)</code>, typically the environment from which <code>plsRglm</code> is called.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nt</code></td>
<td>
<p>number of components to be extracted</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>limQ2set</code></td>
<td>
<p>limit value for the Q2</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>modele</code></td>
<td>
<p>name of the PLS glm model to be fitted (<code>"pls"</code>, <code>"pls-glm-Gamma"</code>, <code>"pls-glm-gaussian"</code>, <code>"pls-glm-inverse.gaussian"</code>, <code>"pls-glm-logistic"</code>, <code>"pls-glm-poisson"</code>, <code>"pls-glm-polr"</code>). Use <code>"modele=pls-glm-family"</code> to enable the <code>family</code> option.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>a description of the error distribution and link function to be used in the model. This can be a character string naming a family function, a family function or the result of a call to a family function. (See <code>family</code> for details of family functions.) To use the family option, please set <code>modele="pls-glm-family"</code>. User defined families can also be defined. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>number of groups. Defaults to 5.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>NK</code></td>
<td>
<p>number of times the group division is made</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>grouplist</code></td>
<td>
<p>to specify the members of the <code>K</code> groups</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>random</code></td>
<td>
<p>should the <code>K</code> groups be made randomly. Defaults to <code>TRUE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleX</code></td>
<td>
<p>scale the predictor(s) : must be set to TRUE for <code>modele="pls"</code> and should be for glms pls.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleY</code></td>
<td>
<p>scale the response : Yes/No. Ignored since non always possible for glm responses.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keepcoeffs</code></td>
<td>
<p>shall the coefficients for each model be returned</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keepfolds</code></td>
<td>
<p>shall the groups' composition be returned</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keepdataY</code></td>
<td>
<p>shall the observed value of the response for each one of the predicted value be returned</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keepMclassed</code></td>
<td>
<p>shall the number of miss classed be returned (unavailable)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol_Xi</code></td>
<td>
<p>minimal value for Norm2(Xi) and <code class="reqn">\mathrm{det}(pp' \times pp)</code> if there is any missing value in the <code>dataX</code>. It defaults to <code class="reqn">10^{-12}</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>an optional vector of 'prior weights' to be used in the fitting process. Should be <code>NULL</code> or a numeric vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used in the fitting process.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start</code></td>
<td>
<p>starting values for the parameters in the linear predictor.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>etastart</code></td>
<td>
<p>starting values for the linear predictor.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mustart</code></td>
<td>
<p>starting values for the vector of means.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>offset</code></td>
<td>
<p>this can be used to specify an <em>a priori</em> known component to be included in the linear predictor during fitting. This should be <code>NULL</code> or a numeric vector of length equal to the number of cases. One or more <code>offset</code> terms can be included in the formula instead or as well, and if more than one is specified their sum is used. See <code>model.offset</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<dl>
<dt>for fitting glms with glm (<code>"pls-glm-Gamma"</code>, <code>"pls-glm-gaussian"</code>, <code>"pls-glm-inverse.gaussian"</code>, <code>"pls-glm-logistic"</code>, <code>"pls-glm-poisson"</code>, <code>"modele=pls-glm-family"</code>)</dt>
<dd>
<p>the method to be used in fitting the model. The default method <code>"glm.fit"</code> uses iteratively reweighted least squares (IWLS). User-supplied fitting functions can be supplied either as a function or a character string naming a function, with a function which takes the same arguments as <code>glm.fit</code>. If "model.frame", the model frame is returned.</p>
</dd>
<dt><code>pls-glm-polr</code></dt>
<dd>
<p>logistic, probit, complementary log-log or cauchit (corresponding to a Cauchy latent variable).</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>a list of parameters for controlling the fitting process. For <code>glm.fit</code> this is passed to <code>glm.control</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>contrasts</code></td>
<td>
<p>an optional list. See the <code>contrasts.arg</code> of <code>model.matrix.default</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>should info messages be displayed ?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>arguments to pass to <code>cv.plsRglmmodel.default</code> or to <code>cv.plsRglmmodel.formula</code></p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Predicts 1 group with the <code>K-1</code> other groups. Leave one out cross validation is thus obtained for <code>K==nrow(dataX)</code>.
</p>
<p>There are seven different predefined models with predefined link functions available :
</p>

<dl>
<dt><code>"pls"</code></dt>
<dd>
<p>ordinary pls models</p>
</dd>
<dt><code>"pls-glm-Gamma"</code></dt>
<dd>
<p>glm gaussian with inverse link pls models</p>
</dd>
<dt><code>"pls-glm-gaussian"</code></dt>
<dd>
<p>glm gaussian with identity link pls models</p>
</dd>
<dt><code>"pls-glm-inverse-gamma"</code></dt>
<dd>
<p>glm binomial with square inverse link pls models</p>
</dd>
<dt><code>"pls-glm-logistic"</code></dt>
<dd>
<p>glm binomial with logit link pls models</p>
</dd>
<dt><code>"pls-glm-poisson"</code></dt>
<dd>
<p>glm poisson with log link pls models</p>
</dd>
<dt><code>"pls-glm-polr"</code></dt>
<dd>
<p>glm polr with logit link pls models</p>
</dd>
</dl>
<p>Using the <code>"family="</code> option and setting <code>"modele=pls-glm-family"</code> allows changing the family and link function the same way as for the <code>glm</code> function. As a consequence user-specified families can also be used. 
</p>

<dl>
<dt>The <code>gaussian</code> family</dt>
<dd>
<p>accepts the links (as names) <code>identity</code>, <code>log</code> and <code>inverse</code>.</p>
</dd>
<dt>The <code>binomial</code> family</dt>
<dd>
<p>accepts the links <code>logit</code>, <code>probit</code>, <code>cauchit</code>, (corresponding to logistic, normal and Cauchy CDFs respectively) <code>log</code> and <code>cloglog</code> (complementary log-log).</p>
</dd> 
<dt>The <code>Gamma</code> family</dt>
<dd>
<p>accepts the links <code>inverse</code>, <code>identity</code> and <code>log</code>.</p>
</dd>
<dt>The <code>poisson</code> family</dt>
<dd>
<p>accepts the links <code>log</code>, <code>identity</code>, and <code>sqrt</code>.</p>
</dd>
<dt>The <code>inverse.gaussian</code> family</dt>
<dd>
<p>accepts the links <code>1/mu^2</code>, <code>inverse</code>, <code>identity</code> and <code>log</code>.</p>
</dd>
<dt>The <code>quasi</code> family</dt>
<dd>
<p>accepts the links <code>logit</code>, <code>probit</code>, <code>cloglog</code>, <code>identity</code>, <code>inverse</code>, <code>log</code>, <code>1/mu^2</code> and <code>sqrt</code>.</p>
</dd>
<dt>The function <code>power</code>
</dt>
<dd>
<p>can be used to create a power link function.</p>
</dd> 
<dt>...</dt>
<dd>
<p>arguments to pass to <code>cv.plsRglmmodel.default</code> or to <code>cv.plsRglmmodel.formula</code></p>
</dd>
</dl>
<p>A typical predictor has the form response ~ terms where response is the (numeric) response vector and terms is a series of terms which specifies a linear predictor for response. A terms specification of the form first + second indicates all the terms in first together with all the terms in second with any duplicates removed. 
</p>
<p>A specification of the form first:second indicates the the set of terms obtained by taking the interactions of all terms in first with all terms in second. The specification first*second indicates the cross of first and second. This is the same as first + second + first:second. 
</p>
<p>The terms in the formula will be re-ordered so that main effects come first, followed by the interactions, all second-order, all third-order and so on: to avoid this pass a terms object as the formula. 
</p>
<p>Non-NULL weights can be used to indicate that different observations have different dispersions (with the values in weights being inversely proportional to the dispersions); or equivalently, when the elements of weights are positive integers w_i, that each response y_i is the mean of w_i unit-weight observations. 
</p>


<h3>Value</h3>

<p>An object of class <code>"cv.plsRglmmodel"</code>.<br></p>
<table>
<tr style="vertical-align: top;">
<td><code>results_kfolds</code></td>
<td>
<p>list of <code>NK</code>. Each element of the list sums up the results for a group division:
</p>

<dl>
<dt>list</dt>
<dd>
<p> of <code>K</code> matrices of size about <code>nrow(dataX)/K * nt</code> with the predicted values for a growing number of components</p>
</dd>
<dt>...</dt>
<dd>
<p>...</p>
</dd>
<dt>list</dt>
<dd>
<p> of <code>K</code> matrices of size about <code>nrow(dataX)/K * nt</code> with the predicted values for a growing number of components</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>folds</code></td>
<td>
<p>list of <code>NK</code>. Each element of the list sums up the informations for a group division:
</p>

<dl>
<dt>list</dt>
<dd>
<p> of <code>K</code> vectors of length about <code>nrow(dataX)</code> with the numbers of the rows of <code>dataX</code> that were used as a training set</p>
</dd>
<dt>...</dt>
<dd>
<p>...</p>
</dd>
<dt>list</dt>
<dd>
<p> of <code>K</code> vectors of length about <code>nrow(dataX)</code> with the numbers of the rows of <code>dataX</code> that were used as a training set</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataY_kfolds</code></td>
<td>
<p>list of <code>NK</code>. Each element of the list sums up the results for a group division:
</p>

<dl>
<dt>list</dt>
<dd>
<p> of <code>K</code> matrices of size about <code>nrow(dataX)/K * 1</code> with the observed values of the response</p>
</dd>
<dt>...</dt>
<dd>
<p>...</p>
</dd>
<dt>list</dt>
<dd>
<p> of <code>K</code> matrices of size about <code>nrow(dataX)/K * 1</code> with the observed values of the response</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>the call of the function</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>Work for complete and incomplete datasets.</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand<br><a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a><br><a href="https://fbertran.github.io/homepage/">https://fbertran.github.io/homepage/</a>
</p>


<h3>References</h3>

<p>Nicolas Meyer, Myriam Maumy-Bertrand et Frederic Bertrand (2010). Comparing the linear and the logistic PLS regression with qualitative predictors: application to allelotyping data. <em>Journal de la Societe Francaise de Statistique</em>, 151(2), pages 1-18.
</p>


<h3>See Also</h3>

<p>Summary method <code>summary.cv.plsRglmmodel</code>. <code>kfolds2coeff</code>, <code>kfolds2Pressind</code>, <code>kfolds2Press</code>, <code>kfolds2Mclassedind</code>, <code>kfolds2Mclassed</code> and <code>summary</code> to extract and transform results from k-fold cross validation.</p>


<h3>Examples</h3>

<pre><code class="language-R">data(Cornell)
bbb &lt;- cv.plsRglm(Y~.,data=Cornell,nt=10)
(sum1&lt;-summary(bbb))
cvtable(sum1)

bbb2 &lt;- cv.plsRglm(Y~.,data=Cornell,nt=3,
modele="pls-glm-family",family=gaussian(),K=12,verbose=FALSE)
(sum2&lt;-summary(bbb2))
cvtable(sum2)


#random=TRUE is the default to randomly create folds for repeated CV
bbb3 &lt;- cv.plsRglm(Y~.,data=Cornell,nt=3,
modele="pls-glm-family",family=gaussian(),K=6,NK=10, verbose=FALSE)
(sum3&lt;-summary(bbb3))
plot(cvtable(sum3))

data(aze_compl)
bbb &lt;- cv.plsRglm(y~.,data=aze_compl,nt=10,K=10,modele="pls",keepcoeffs=TRUE, verbose=FALSE)

#For Jackknife computations
kfolds2coeff(bbb)
bbb2 &lt;- cv.plsRglm(y~.,data=aze_compl,nt=10,K=10,modele="pls-glm-family",
family=binomial(probit),keepcoeffs=TRUE, verbose=FALSE)
bbb2 &lt;- cv.plsRglm(y~.,data=aze_compl,nt=10,K=10,
modele="pls-glm-logistic",keepcoeffs=TRUE, verbose=FALSE)
summary(bbb,MClassed=TRUE)
summary(bbb2,MClassed=TRUE)
kfolds2coeff(bbb2)

kfolds2Chisqind(bbb2)
kfolds2Chisq(bbb2)
summary(bbb2)
rm(list=c("bbb","bbb2"))



data(pine)
Xpine&lt;-pine[,1:10]
ypine&lt;-pine[,11]
bbb &lt;- cv.plsRglm(round(x11)~.,data=pine,nt=10,modele="pls-glm-family",
family=poisson(log),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)
bbb &lt;- cv.plsRglm(round(x11)~.,data=pine,nt=10,
modele="pls-glm-poisson",K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)

#For Jackknife computations
kfolds2coeff(bbb)
boxplot(kfolds2coeff(bbb)[,1])

kfolds2Chisqind(bbb)
kfolds2Chisq(bbb)
summary(bbb)
PLS_lm(ypine,Xpine,10,typeVC="standard")$InfCrit

data(pineNAX21)
bbb2 &lt;- cv.plsRglm(round(x11)~.,data=pineNAX21,nt=10,
modele="pls-glm-family",family=poisson(log),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)
bbb2 &lt;- cv.plsRglm(round(x11)~.,data=pineNAX21,nt=10,
modele="pls-glm-poisson",K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)

#For Jackknife computations
kfolds2coeff(bbb2)
boxplot(kfolds2coeff(bbb2)[,1])

kfolds2Chisqind(bbb2)
kfolds2Chisq(bbb2)
summary(bbb2)

data(XpineNAX21)
PLS_lm(ypine,XpineNAX21,10,typeVC="standard")$InfCrit
rm(list=c("Xpine","XpineNAX21","ypine","bbb","bbb2"))



data(pine)
Xpine&lt;-pine[,1:10]
ypine&lt;-pine[,11]
bbb &lt;- cv.plsRglm(x11~.,data=pine,nt=10,modele="pls-glm-family",
family=Gamma,K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)
bbb &lt;- cv.plsRglm(x11~.,data=pine,nt=10,modele="pls-glm-Gamma",
K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)

#For Jackknife computations
kfolds2coeff(bbb)
boxplot(kfolds2coeff(bbb)[,1])

kfolds2Chisqind(bbb)
kfolds2Chisq(bbb)
summary(bbb)
PLS_lm(ypine,Xpine,10,typeVC="standard")$InfCrit

data(pineNAX21)
bbb2 &lt;- cv.plsRglm(x11~.,data=pineNAX21,nt=10,
modele="pls-glm-family",family=Gamma(),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)
bbb2 &lt;- cv.plsRglm(x11~.,data=pineNAX21,nt=10,
modele="pls-glm-Gamma",K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)

#For Jackknife computations
kfolds2coeff(bbb2)
boxplot(kfolds2coeff(bbb2)[,1])

kfolds2Chisqind(bbb2)
kfolds2Chisq(bbb2)
summary(bbb2)
XpineNAX21 &lt;- Xpine
XpineNAX21[1,2] &lt;- NA
PLS_lm(ypine,XpineNAX21,10,typeVC="standard")$InfCrit
rm(list=c("Xpine","XpineNAX21","ypine","bbb","bbb2"))



data(Cornell)
XCornell&lt;-Cornell[,1:7]
yCornell&lt;-Cornell[,8]
bbb &lt;- cv.plsRglm(Y~.,data=Cornell,nt=10,NK=1,modele="pls",verbose=FALSE)
summary(bbb)

cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele="pls-glm-inverse.gaussian",K=12,verbose=FALSE)
cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele="pls-glm-family",
family=inverse.gaussian,K=12,verbose=FALSE)
cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele="pls-glm-inverse.gaussian",K=6,
NK=2,verbose=FALSE)$results_kfolds
cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele="pls-glm-family",family=inverse.gaussian(),
K=6,NK=2,verbose=FALSE)$results_kfolds
cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele="pls-glm-inverse.gaussian",K=6,
NK=2,verbose=FALSE)$results_kfolds
cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele="pls-glm-family",
family=inverse.gaussian(link = "1/mu^2"),K=6,NK=2,verbose=FALSE)$results_kfolds

bbb2 &lt;- cv.plsRglm(Y~.,data=Cornell,nt=10,
modele="pls-glm-inverse.gaussian",keepcoeffs=TRUE,verbose=FALSE)

#For Jackknife computations
kfolds2coeff(bbb2)
boxplot(kfolds2coeff(bbb2)[,1])

kfolds2Chisqind(bbb2)
kfolds2Chisq(bbb2)
summary(bbb2)
PLS_lm(yCornell,XCornell,10,typeVC="standard")$InfCrit
rm(list=c("XCornell","yCornell","bbb","bbb2"))

data(Cornell)
bbb &lt;- cv.plsRglm(Y~.,data=Cornell,nt=10,NK=1,modele="pls")
summary(bbb)

cv.plsRglm(Y~.,data=Cornell,nt=3,modele="pls-glm-family",family=gaussian(),K=12)


cv.plsRglm(Y~.,data=Cornell,nt=3,modele="pls-glm-family",family=gaussian(),K=6,
NK=2,random=TRUE,keepfolds=TRUE,verbose=FALSE)$results_kfolds

#Different ways of model specifications
cv.plsRglm(Y~.,data=Cornell,nt=3,modele="pls-glm-family",family=gaussian(),K=6,
NK=2,verbose=FALSE)$results_kfolds
cv.plsRglm(Y~.,data=Cornell,nt=3,modele="pls-glm-family",family=gaussian,
K=6,NK=2,verbose=FALSE)$results_kfolds
cv.plsRglm(Y~.,data=Cornell,nt=3,modele="pls-glm-family",family=gaussian(),
K=6,NK=2,verbose=FALSE)$results_kfolds
cv.plsRglm(Y~.,data=Cornell,nt=3,modele="pls-glm-family",family=gaussian(link=log),
K=6,NK=2,verbose=FALSE)$results_kfolds

bbb2 &lt;- cv.plsRglm(Y~.,data=Cornell,nt=10,
modele="pls-glm-gaussian",keepcoeffs=TRUE,verbose=FALSE)
bbb2 &lt;- cv.plsRglm(Y~.,data=Cornell,nt=3,modele="pls-glm-family",
family=gaussian(link=log),K=6,keepcoeffs=TRUE,verbose=FALSE)

#For Jackknife computations
kfolds2coeff(bbb2)
boxplot(kfolds2coeff(bbb2)[,1])

kfolds2Chisqind(bbb2)
kfolds2Chisq(bbb2)
summary(bbb2)
PLS_lm_formula(Y~.,data=Cornell,10,typeVC="standard")$InfCrit
rm(list=c("bbb","bbb2"))


data(pine)
bbb &lt;- cv.plsRglm(x11~.,data=pine,nt=10,modele="pls-glm-family",
family=gaussian(log),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)
bbb &lt;- cv.plsRglm(x11~.,data=pine,nt=10,modele="pls-glm-family",family=gaussian(),
K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)

#For Jackknife computations
kfolds2coeff(bbb)
boxplot(kfolds2coeff(bbb)[,1])

kfolds2Chisqind(bbb)
kfolds2Chisq(bbb)
summary(bbb)
PLS_lm_formula(x11~.,data=pine,nt=10,typeVC="standard")$InfCrit

data(pineNAX21)
bbb2 &lt;- cv.plsRglm(x11~.,data=pineNAX21,nt=10,
modele="pls-glm-family",family=gaussian(log),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)
bbb2 &lt;- cv.plsRglm(x11~.,data=pineNAX21,nt=10,
modele="pls-glm-gaussian",K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)

#For Jackknife computations
kfolds2coeff(bbb2)
boxplot(kfolds2coeff(bbb2)[,1])

kfolds2Chisqind(bbb2)
kfolds2Chisq(bbb2)
summary(bbb2)
PLS_lm_formula(x11~.,data=pineNAX21,nt=10,typeVC="standard")$InfCrit
rm(list=c("bbb","bbb2"))


data(aze_compl)
bbb &lt;- cv.plsRglm(y~.,data=aze_compl,nt=10,K=10,modele="pls",
keepcoeffs=TRUE,verbose=FALSE)

#For Jackknife computations
kfolds2coeff(bbb)
bbb2 &lt;- cv.plsRglm(y~.,data=aze_compl,nt=3,K=10,
modele="pls-glm-family",family=binomial(probit),keepcoeffs=TRUE,verbose=FALSE)
bbb2 &lt;- cv.plsRglm(y~.,data=aze_compl,nt=3,K=10,
modele="pls-glm-logistic",keepcoeffs=TRUE,verbose=FALSE)
summary(bbb,MClassed=TRUE)
summary(bbb2,MClassed=TRUE)
kfolds2coeff(bbb2)

kfolds2Chisqind(bbb2)
kfolds2Chisq(bbb2)
summary(bbb2)
rm(list=c("bbb","bbb2"))



data(pine)
bbb &lt;- cv.plsRglm(round(x11)~.,data=pine,nt=10,
modele="pls-glm-family",family=poisson(log),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)
bbb &lt;- cv.plsRglm(round(x11)~.,data=pine,nt=10,
modele="pls-glm-poisson",K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)

#For Jackknife computations
kfolds2coeff(bbb)
boxplot(kfolds2coeff(bbb)[,1])

kfolds2Chisqind(bbb)
kfolds2Chisq(bbb)
summary(bbb)
PLS_lm_formula(x11~.,data=pine,10,typeVC="standard")$InfCrit

data(pineNAX21)
bbb2 &lt;- cv.plsRglm(round(x11)~.,data=pineNAX21,nt=10,
modele="pls-glm-family",family=poisson(log),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)
bbb2 &lt;- cv.plsRglm(round(x11)~.,data=pineNAX21,nt=10,
modele="pls-glm-poisson",K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)

#For Jackknife computations
kfolds2coeff(bbb2)
boxplot(kfolds2coeff(bbb2)[,1])

kfolds2Chisqind(bbb2)
kfolds2Chisq(bbb2)
summary(bbb2)
PLS_lm_formula(x11~.,data=pineNAX21,10,typeVC="standard")$InfCrit
rm(list=c("bbb","bbb2"))



data(pine)
bbb &lt;- cv.plsRglm(x11~.,data=pine,nt=10,modele="pls-glm-family",
family=Gamma,K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)
bbb &lt;- cv.plsRglm(x11~.,data=pine,nt=10,modele="pls-glm-Gamma",
K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)

#For Jackknife computations
kfolds2coeff(bbb)
boxplot(kfolds2coeff(bbb)[,1])

kfolds2Chisqind(bbb)
kfolds2Chisq(bbb)
summary(bbb)
PLS_lm_formula(x11~.,data=pine,10,typeVC="standard")$InfCrit

data(pineNAX21)
bbb2 &lt;- cv.plsRglm(x11~.,data=pineNAX21,nt=10,
modele="pls-glm-family",family=Gamma(),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)
bbb2 &lt;- cv.plsRglm(x11~.,data=pineNAX21,nt=10,
modele="pls-glm-Gamma",K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)

#For Jackknife computations
kfolds2coeff(bbb2)
boxplot(kfolds2coeff(bbb2)[,1])

kfolds2Chisqind(bbb2)
kfolds2Chisq(bbb2)
summary(bbb2)
PLS_lm_formula(x11~.,data=pineNAX21,10,typeVC="standard")$InfCrit
rm(list=c("bbb","bbb2"))



data(Cornell)
summary(cv.plsRglm(Y~.,data=Cornell,nt=10,NK=1,modele="pls",verbose=FALSE))

cv.plsRglm(Y~.,data=Cornell,nt=3,
modele="pls-glm-inverse.gaussian",K=12,verbose=FALSE)
cv.plsRglm(Y~.,data=Cornell,nt=3,modele="pls-glm-family",family=inverse.gaussian,K=12,verbose=FALSE)
cv.plsRglm(Y~.,data=Cornell,nt=3,modele="pls-glm-inverse.gaussian",K=6,
NK=2,verbose=FALSE)$results_kfolds
cv.plsRglm(Y~.,data=Cornell,nt=3,modele="pls-glm-family",
family=inverse.gaussian(),K=6,NK=2,verbose=FALSE)$results_kfolds
cv.plsRglm(Y~.,data=Cornell,nt=3,modele="pls-glm-inverse.gaussian",K=6,
NK=2,verbose=FALSE)$results_kfolds
cv.plsRglm(Y~.,data=Cornell,nt=3,modele="pls-glm-family",
family=inverse.gaussian(link = "1/mu^2"),K=6,NK=2,verbose=FALSE)$results_kfolds

bbb2 &lt;- cv.plsRglm(Y~.,data=Cornell,nt=10,
modele="pls-glm-inverse.gaussian",keepcoeffs=TRUE,verbose=FALSE)

#For Jackknife computations
kfolds2coeff(bbb2)
boxplot(kfolds2coeff(bbb2)[,1])

kfolds2Chisqind(bbb2)
kfolds2Chisq(bbb2)
summary(bbb2)
PLS_lm_formula(Y~.,data=Cornell,10,typeVC="standard")$InfCrit
rm(list=c("bbb","bbb2"))


data(bordeaux)
summary(cv.plsRglm(Quality~.,data=bordeaux,10,
modele="pls-glm-polr",K=7))

data(bordeauxNA)
summary(cv.plsRglm(Quality~.,data=bordeauxNA,
10,modele="pls-glm-polr",K=10,verbose=FALSE))

summary(cv.plsRglm(Quality~.,data=bordeaux,nt=2,K=7,
modele="pls-glm-polr",method="logistic",verbose=FALSE))
summary(cv.plsRglm(Quality~.,data=bordeaux,nt=2,K=7,
modele="pls-glm-polr",method="probit",verbose=FALSE))
summary(cv.plsRglm(Quality~.,data=bordeaux,nt=2,K=7,
modele="pls-glm-polr",method="cloglog",verbose=FALSE))
suppressWarnings(summary(cv.plsRglm(Quality~.,data=bordeaux,nt=2,K=7,
modele="pls-glm-polr",method="cauchit",verbose=FALSE)))

</code></pre>


</div>