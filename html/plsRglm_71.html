<div class="container">

<table style="width: 100%;"><tr>
<td>plsR</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Partial least squares Regression models with leave one out cross validation</h2>

<h3>Description</h3>

<p>This function implements Partial least squares Regression models with leave one out cross validation for complete or incomplete datasets.
</p>


<h3>Usage</h3>

<pre><code class="language-R">plsR(object, ...)
## Default S3 method:
plsRmodel(object, dataX, nt = 2, limQ2set = 0.0975, 
dataPredictY = dataX, modele = "pls", family = NULL, typeVC = "none", 
EstimXNA = FALSE, scaleX = TRUE, scaleY = NULL, pvals.expli = FALSE, 
alpha.pvals.expli = 0.05, MClassed = FALSE, tol_Xi = 10^(-12), weights,
sparse = FALSE, sparseStop = TRUE, naive = FALSE,verbose=TRUE,...)
## S3 method for class 'formula'
plsRmodel(object, data, nt = 2, limQ2set = 0.0975,
dataPredictY, modele = "pls", family = NULL, typeVC = "none",
EstimXNA = FALSE, scaleX = TRUE, scaleY = NULL, pvals.expli = FALSE, 
alpha.pvals.expli = 0.05, MClassed = FALSE, tol_Xi = 10^(-12), weights,
subset, contrasts = NULL, sparse = FALSE, sparseStop = TRUE, naive = FALSE,
verbose=TRUE,...)
PLS_lm(dataY, dataX, nt = 2, limQ2set = 0.0975, dataPredictY = dataX, 
modele = "pls", family = NULL, typeVC = "none", EstimXNA = FALSE, 
scaleX = TRUE, scaleY = NULL, pvals.expli = FALSE, 
alpha.pvals.expli = 0.05, MClassed = FALSE, tol_Xi = 10^(-12),
weights,sparse=FALSE,sparseStop=FALSE,naive=FALSE,verbose=TRUE)
PLS_lm_formula(formula,data=NULL,nt=2,limQ2set=.0975,dataPredictY=dataX,
modele="pls",family=NULL,typeVC="none",EstimXNA=FALSE,scaleX=TRUE,
scaleY=NULL,pvals.expli=FALSE,alpha.pvals.expli=.05,MClassed=FALSE,
tol_Xi=10^(-12),weights,subset,contrasts=NULL,sparse=FALSE,
sparseStop=FALSE,naive=FALSE,verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>response (training) dataset or an object of class "<code>formula</code>" (or one that can be coerced to that class): a symbolic description of the model to be fitted. The details of model specification are given under 'Details'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataY</code></td>
<td>
<p>response (training) dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataX</code></td>
<td>
<p>predictor(s) (training) dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>an object of class "<code>formula</code>" (or one that can be coerced to that class): a symbolic description of the model to be fitted. The details of model specification are given under 'Details'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>an optional data frame, list or environment (or object coercible by <code>as.data.frame</code> to a data frame) containing the variables in the model. If not found in <code>data</code>, the variables are taken from <code>environment(formula)</code>, typically the environment from which <code>plsR</code> is called.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nt</code></td>
<td>
<p>number of components to be extracted</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>limQ2set</code></td>
<td>
<p>limit value for the Q2</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataPredictY</code></td>
<td>
<p>predictor(s) (testing) dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>modele</code></td>
<td>
<p>name of the PLS model to be fitted, only (<code>"pls"</code> available for this fonction.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>for the present moment the family argument is ignored and set thanks to the value of modele.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>typeVC</code></td>
<td>
<p>type of leave one out cross validation. Several procedures are available. If cross validation is required, one needs to selects the way of predicting the response for left out observations. For complete rows, without any missing value, there are two different ways of computing these predictions. As a consequence, for mixed datasets, with complete and incomplete rows, there are two ways of computing prediction : either predicts any row as if there were missing values in it (<code>missingdata</code>) or selects the prediction method accordingly to the completeness of the row (<code>adaptative</code>).
</p>

<dl>
<dt><code>none</code></dt>
<dd>
<p>no cross validation</p>
</dd>
<dt><code>standard</code></dt>
<dd>
<p>as in SIMCA for datasets without any missing value. For datasets with any missing value, it is the as using <code>missingdata</code></p>
</dd>
<dt><code>missingdata</code></dt>
<dd>
<p>all values predicted as those with missing values for datasets with any missing values</p>
</dd>
<dt><code>adaptative</code></dt>
<dd>
<p>predict a response value for an x with any missing value as those with missing values and for an x without any missing value as those without missing values.</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>EstimXNA</code></td>
<td>
<p>only for <code>modele="pls"</code>. Set whether the missing X values have to be estimated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleX</code></td>
<td>
<p>scale the predictor(s) : must be set to TRUE for <code>modele="pls"</code> and should be for glms pls.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleY</code></td>
<td>
<p>scale the response : Yes/No. Ignored since non always possible for glm responses.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pvals.expli</code></td>
<td>
<p>should individual p-values be reported to tune model selection ?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha.pvals.expli</code></td>
<td>
<p>level of significance for predictors when pvals.expli=TRUE</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MClassed</code></td>
<td>
<p>number of missclassified cases, should only be used for binary responses</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol_Xi</code></td>
<td>
<p>minimal value for Norm2(Xi) and <code class="reqn">\mathrm{det}(pp' \times pp)</code> if there is any missing value in the <code>dataX</code>. It defaults to <code class="reqn">10^{-12}</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>an optional vector of 'prior weights' to be used in the fitting process. Should be <code>NULL</code> or a numeric vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used in the fitting process.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>contrasts</code></td>
<td>
<p>an optional list. See the <code>contrasts.arg</code> of <code>model.matrix.default</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sparse</code></td>
<td>
<p>should the coefficients of non-significant predictors (&lt;<code>alpha.pvals.expli</code>) be set to 0</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sparseStop</code></td>
<td>
<p>should component extraction stop when no significant predictors (&lt;<code>alpha.pvals.expli</code>) are found</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>naive</code></td>
<td>
<p>Use the naive estimates for the Degrees of Freedom in plsR? Default is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>should info messages be displayed ?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>arguments to pass to <code>plsRmodel.default</code> or to <code>plsRmodel.formula</code></p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>There are several ways to deal with missing values that leads to different computations of leave one out cross validation criteria.
</p>
<p>A typical predictor has the form response ~ terms where response is the (numeric) response vector and terms is a series of terms which specifies a linear predictor for response. A terms specification of the form first + second indicates all the terms in first together with all the terms in second with any duplicates removed. 
</p>
<p>A specification of the form first:second indicates the the set of terms obtained by taking the interactions of all terms in first with all terms in second. The specification first*second indicates the cross of first and second. This is the same as first + second + first:second. 
</p>
<p>The terms in the formula will be re-ordered so that main effects come first, followed by the interactions, all second-order, all third-order and so on: to avoid this pass a terms object as the formula. 
</p>
<p>Non-NULL weights can be used to indicate that different observations have different dispersions (with the values in weights being inversely proportional to the dispersions); or equivalently, when the elements of weights are positive integers w_i, that each response y_i is the mean of w_i unit-weight observations. 
</p>
<p>The default estimator for Degrees of Freedom is the Kramer and Sugiyama's one. Information criteria are computed accordingly to these estimations. Naive Degrees of Freedom and Information Criteria are also provided for comparison purposes. For more details, see N. Kraemer and M. Sugiyama. (2011). The Degrees of Freedom of Partial Least Squares Regression. <em>Journal of the American Statistical Association</em>, 106(494), 697-705, 2011. 
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>nr</code></td>
<td>
<p>Number of observations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nc</code></td>
<td>
<p>Number of predictors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nt</code></td>
<td>
<p>Number of requested components</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ww</code></td>
<td>
<p>raw weights (before L2-normalization)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wwnorm</code></td>
<td>
<p>L2 normed weights (to be used with deflated matrices of predictor variables)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wwetoile</code></td>
<td>
<p>modified weights (to be used with original matrix of predictor variables)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tt</code></td>
<td>
<p>PLS components</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pp</code></td>
<td>
<p>loadings of the predictor variables</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>CoeffC</code></td>
<td>
<p>coefficients of the PLS components</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>uscores</code></td>
<td>
<p>scores of the response variable</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>YChapeau</code></td>
<td>
<p>predicted response values for the dataX set</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>residYChapeau</code></td>
<td>
<p>residuals of the deflated response on the standardized scale</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>RepY</code></td>
<td>
<p>scaled response vector</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.miss.Y</code></td>
<td>
<p>is there any NA value in the response vector</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>YNA</code></td>
<td>
<p>indicatrix vector of missing values in RepY</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>residY</code></td>
<td>
<p>deflated scaled response vector</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ExpliX</code></td>
<td>
<p>scaled matrix of predictors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.miss.X</code></td>
<td>
<p>is there any NA value in the predictor matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>XXNA</code></td>
<td>
<p>indicator of non-NA values in the predictor matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>residXX</code></td>
<td>
<p>deflated predictor matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>PredictY</code></td>
<td>
<p>response values with NA replaced with 0</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>press.ind</code></td>
<td>
<p>individual PRESS value for each observation (scaled scale)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>press.tot</code></td>
<td>
<p>total PRESS value for all observations (scaled scale)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>glm family used to fit PLSGLR model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ttPredictY</code></td>
<td>
<p>PLS components for the dataset on which prediction was requested</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>typeVC</code></td>
<td>
<p>type of leave one out cross-validation used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataX</code></td>
<td>
<p>predictor values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataY</code></td>
<td>
<p>response values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>computed_nt</code></td>
<td>
<p>number of components that were computed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>CoeffCFull</code></td>
<td>
<p>matrix of the coefficients of the predictors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>CoeffConstante</code></td>
<td>
<p>value of the intercept (scaled scale)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Std.Coeffs</code></td>
<td>
<p>Vector of standardized regression coefficients</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>press.ind2</code></td>
<td>
<p>individual PRESS value for each observation (original scale)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>RSSresidY</code></td>
<td>
<p>residual sum of squares (scaled scale)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Coeffs</code></td>
<td>
<p>Vector of regression coefficients (used with the original data scale)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Yresidus</code></td>
<td>
<p>residuals of the PLS model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>RSS</code></td>
<td>
<p>residual sum of squares (original scale)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>residusY</code></td>
<td>
<p>residuals of the deflated response on the standardized scale</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>AIC.std</code></td>
<td>
<p>AIC.std vs number of components (AIC computed for the standardized model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>AIC</code></td>
<td>
<p>AIC vs number of components</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optional</code></td>
<td>
<p>If the response is assumed to be binary:<br>
i.e. <code>MClassed=TRUE</code>.    
</p>

<dl>
<dt><code>MissClassed</code></dt>
<dd>
<p>Number of miss classed results</p>
</dd>
<dt><code>Probs</code></dt>
<dd>
<p>"Probability" predicted by the model. These are not true probabilities since they may lay outside of [0,1]</p>
</dd>
<dt><code>Probs.trc</code></dt>
<dd>
<p>Probability predicted by the model and constrained to belong to [0,1]</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ttPredictFittedMissingY</code></td>
<td>
<p>Description of 'comp2'</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optional</code></td>
<td>
<p>If cross validation was requested:<br>
i.e. <code>typeVC="standard"</code>, <code>typeVC="missingdata"</code> or <code>typeVC="adaptative"</code>.
</p>

<dl>
<dt><code>R2residY</code></dt>
<dd>
<p>R2 coefficient value on the standardized scale</p>
</dd>
<dt><code>R2</code></dt>
<dd>
<p>R2 coefficient value on the original scale</p>
</dd>
<dt><code>press.tot2</code></dt>
<dd>
<p>total PRESS value for all observations (original scale)</p>
</dd>
<dt><code>Q2</code></dt>
<dd>
<p>Q2 value (standardized scale)</p>
</dd>
<dt><code>limQ2</code></dt>
<dd>
<p>limit of the Q2 value</p>
</dd>
<dt><code>Q2_2</code></dt>
<dd>
<p>Q2 value (original scale)</p>
</dd>
<dt><code>Q2cum</code></dt>
<dd>
<p>cumulated Q2 (standardized scale)</p>
</dd>
<dt><code>Q2cum_2</code></dt>
<dd>
<p>cumulated Q2 (original scale)</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>InfCrit</code></td>
<td>
<p>table of Information Criteria</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Std.ValsPredictY</code></td>
<td>
<p>predicted response values for supplementary dataset (standardized scale)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ValsPredictY</code></td>
<td>
<p>predicted response values for supplementary dataset (original scale)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Std.XChapeau</code></td>
<td>
<p>estimated values for missing values in the predictor matrix (standardized scale)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>XXwotNA</code></td>
<td>
<p>predictor matrix with missing values replaced with 0</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>Use <code>cv.plsR</code> to cross-validate the plsRglm models and <code>bootpls</code> to bootstrap them.</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand<br><a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a><br><a href="https://fbertran.github.io/homepage/">https://fbertran.github.io/homepage/</a>
</p>


<h3>References</h3>

<p>Nicolas Meyer, Myriam Maumy-Bertrand et Frederic Bertrand (2010). Comparing the linear and the logistic PLS regression with qualitative predictors: application to allelotyping data. <em>Journal de la Societe Francaise de Statistique</em>, 151(2), pages 1-18.
<a href="http://publications-sfds.math.cnrs.fr/index.php/J-SFdS/article/view/47">http://publications-sfds.math.cnrs.fr/index.php/J-SFdS/article/view/47</a>
</p>


<h3>See Also</h3>

<p>See also <code>plsRglm</code> to fit PLSGLR models.</p>


<h3>Examples</h3>

<pre><code class="language-R">data(Cornell)
XCornell&lt;-Cornell[,1:7]
yCornell&lt;-Cornell[,8]

#maximum 6 components could be extracted from this dataset
#trying 10 to trigger automatic stopping criterion
modpls10&lt;-plsR(yCornell,XCornell,10)
modpls10

#With iterated leave one out CV PRESS
modpls6cv&lt;-plsR(Y~.,data=Cornell,6,typeVC="standard")
modpls6cv
cv.modpls&lt;-cv.plsR(Y~.,data=Cornell,6,NK=100, verbose=FALSE)
res.cv.modpls&lt;-cvtable(summary(cv.modpls))
plot(res.cv.modpls)

rm(list=c("XCornell","yCornell","modpls10","modpls6cv"))


#A binary response example
data(aze_compl)
Xaze_compl&lt;-aze_compl[,2:34]
yaze_compl&lt;-aze_compl$y
modpls.aze &lt;- plsR(yaze_compl,Xaze_compl,10,MClassed=TRUE,typeVC="standard")
modpls.aze

#Direct access to not cross-validated values
modpls.aze$AIC
modpls.aze$AIC.std
modpls.aze$MissClassed

#Raw predicted values (not really probabily since not constrained in [0,1]
modpls.aze$Probs
#Truncated to [0;1] predicted values (true probabilities)
modpls.aze$Probs.trc
modpls.aze$Probs-modpls.aze$Probs.trc

#Repeated cross validation of the model (NK=100 times)
cv.modpls.aze&lt;-cv.plsR(y~.,data=aze_compl,10,NK=100, verbose=FALSE)
res.cv.modpls.aze&lt;-cvtable(summary(cv.modpls.aze,MClassed=TRUE))
#High discrepancy in the number of component choice using repeated cross validation
#and missclassed criterion
plot(res.cv.modpls.aze)

rm(list=c("Xaze_compl","yaze_compl","modpls.aze","cv.modpls.aze","res.cv.modpls.aze"))

#24 predictors
dimX &lt;- 24
#2 components
Astar &lt;- 2
simul_data_UniYX(dimX,Astar)
dataAstar2 &lt;- data.frame(t(replicate(250,simul_data_UniYX(dimX,Astar))))
modpls.A2&lt;- plsR(Y~.,data=dataAstar2,10,typeVC="standard")
modpls.A2
cv.modpls.A2&lt;-cv.plsR(Y~.,data=dataAstar2,10,NK=100, verbose=FALSE)
res.cv.modpls.A2&lt;-cvtable(summary(cv.modpls.A2,verbose=FALSE))
#Perfect choice for the Q2 criterion in PLSR
plot(res.cv.modpls.A2)

#Binarized data.frame
simbin1 &lt;- data.frame(dicho(dataAstar2))
modpls.B2 &lt;- plsR(Y~.,data=simbin1,10,typeVC="standard",MClassed=TRUE, verbose=FALSE)
modpls.B2
modpls.B2$Probs
modpls.B2$Probs.trc
modpls.B2$MissClassed
plsR(simbin1$Y,dataAstar2[,-1],10,typeVC="standard",MClassed=TRUE,verbose=FALSE)$InfCrit
cv.modpls.B2&lt;-cv.plsR(Y~.,data=simbin1,2,NK=100,verbose=FALSE)
res.cv.modpls.B2&lt;-cvtable(summary(cv.modpls.B2,MClassed=TRUE))
#Only one component found by repeated CV missclassed criterion
plot(res.cv.modpls.B2)

rm(list=c("dimX","Astar","dataAstar2","modpls.A2","cv.modpls.A2",
"res.cv.modpls.A2","simbin1","modpls.B2","cv.modpls.B2","res.cv.modpls.B2"))

</code></pre>


</div>