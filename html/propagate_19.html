<div class="container">

<table style="width: 100%;"><tr>
<td>propagate</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Propagation of uncertainty using higher-order Taylor expansion and Monte Carlo simulation</h2>

<h3>Description</h3>

<p>A general function for the calculation of uncertainty propagation by first-/second-order Taylor expansion and Monte Carlo simulation including covariances. Input data can be any symbolic/numeric differentiable expression and data based on summaries (mean &amp; s.d.) or sampled from distributions. Uncertainty propagation is based completely on matrix calculus accounting for full covariance structure. Monte Carlo simulation is conducted using a multivariate t-distribution with covariance structure. Propagation confidence intervals are calculated from the expanded uncertainties by means of the degrees of freedom obtained from <code>WelchSatter</code>, or from the [<code class="reqn">\frac{\alpha}{2}, 1-\frac{\alpha}{2}</code>] quantiles of the MC evaluations.
</p>


<h3>Usage</h3>

<pre><code class="language-R">propagate(expr, data, second.order = TRUE, do.sim = TRUE, cov = TRUE, 
          df = NULL, nsim = 1000000, alpha = 0.05, ...)  
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>expr</code></td>
<td>
<p>an expression, such as <code>expression(x/y)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>a dataframe or matrix containing either a) the means <code class="reqn">\mu_i</code>, standard deviations <code class="reqn">\sigma_i</code> and degrees of freedom <code class="reqn">\nu_i</code> (optionally) in the first, second and third (optionally) row, or b) sampled data generated from any of <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span>'s <code>distributions</code> or those implemented in this package (<code>rDistr</code>). If <code>nrow(data)</code> &gt; 3, sampled data is assumed. The column names must match the variable names.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>second.order</code></td>
<td>
<p>logical. If <code>TRUE</code>, error propagation will be calculated with first- and second-order Taylor expansion. See 'Details'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>do.sim</code></td>
<td>
<p>logical. Should Monte Carlo simulation be applied?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov</code></td>
<td>
<p>logical or variance-covariance matrix with the same column names as <code>data</code>. See 'Details'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>an optional scalar with the total degrees of freedom <code class="reqn">\nu_{\mathrm{tot}}</code> of the system.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nsim</code></td>
<td>
<p>the number of Monte Carlo simulations to be performed, minimum is 10000.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>the 1 - confidence level.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>other parameters to be supplied to future methods.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The implemented methods are:<br><br>
1) <b>Monte Carlo simulation:</b><br>
For each variable <code class="reqn">m</code> in <code>data</code>, simulated data <code class="reqn">X = [x_1, x_2, \ldots, x_n]</code> with <code class="reqn">n</code> = <code>nsim</code> samples is generated from a multivariate t-distribution <code class="reqn">X_{m, n} \sim t(\mu, \Sigma, \nu)</code> using means <code class="reqn">\mu_i</code> and covariance matrix <code class="reqn">\boldsymbol{\Sigma}</code> constructed from the standard deviations <code class="reqn">\sigma_i</code> of each variable. All data is coerced into a new dataframe that has the same covariance structure as the initial <code>data</code>: <code class="reqn">\boldsymbol{\Sigma}(\mathtt{data}) = \boldsymbol{\Sigma}(X_{m, n})</code>. Each row <code class="reqn">i = 1, \ldots, n</code> of the simulated dataset <code class="reqn">X_{m, n}</code> is evaluated with <code>expr</code>, <code class="reqn">y_i = f(x_{m, i})</code>, and summary statistics (mean, sd, median, mad, quantile-based confidence interval based on [<code class="reqn">\frac{\alpha}{2}, 1-\frac{\alpha}{2}</code>]) are calculated on <code class="reqn">y</code>. 
</p>
<p>2) <b>Error propagation:</b><br>
The propagated error is calculated by first-/second-order Taylor expansion accounting for full covariance structure using matrix algebra.<br>
The following transformations based on two variables <code class="reqn">x_1, x_2</code> illustrate the equivalence of the matrix-based approach with well-known classical notations:<br><b>First-order mean:</b> <code class="reqn">\rm{E[y]} = f(\bar{x}_i)</code><br><b>First-order variance:</b> <code class="reqn">\sigma_y^2 = {\color{red} \nabla \mathbf{\Sigma} \nabla^T}</code>:<br></p>
<p style="text-align: center;"><code class="reqn">{ \color{red}[\rm{j_1}\; \rm{j_2}] \left[ \begin{array}{cc} \sigma_1^2 &amp; \sigma_1\sigma_2 \\ \sigma_2\sigma_1 &amp; \sigma_2^2 \end{array} \right] \left[ \begin{array}{c} \rm{j_1} \\ \rm{j_2} \end{array} \right]} = \rm{j_1}^2 \sigma_1^2 + \rm{2 j_1 j_2} \sigma_1 \sigma_2 + \rm{j_2}^2 \sigma_2^2</code>
</p>

<p style="text-align: center;"><code class="reqn">= \underbrace{\sum_{i=1}^2 \rm{j_i}^2 \sigma_i^2 + 2\sum_{i=1\atop i \neq k}^2\sum_{k=1\atop k \neq i}^2 \rm{j_i j_k} \sigma_{ik}}_{\rm{classical\;notation}} = \frac{1}{1!} \left(\sum_{i=1}^2 \frac{\partial f}{\partial x_i} \sigma_i \right)^2</code>
</p>

<p><br><b>Second-order mean:</b> <code class="reqn">\rm{E}[y] = f(\bar{x}_i) + {\color{blue} \frac{1}{2}\rm{tr}(\mathbf{H\Sigma)}}</code>:<br></p>
<p style="text-align: center;"><code class="reqn">{ \color{blue} \frac{1}{2} \rm{tr} \left[ \begin{array}{cc} \rm{h_1} &amp; \rm{h_2} \\ \rm{h_3} &amp; \rm{h_4} \end{array} \right] \left[ \begin{array}{cc} \sigma_1^2 &amp; \sigma_1\sigma_2 \\ \sigma_2\sigma_1 &amp; \sigma_2^2 \end{array} \right]} = \frac{1}{2} \rm{tr} \left[ \begin{array}{cc} \rm{h_1} \sigma_1^2 + \rm{h_2}\sigma_1\sigma_2 &amp; \rm{h_1}\sigma_1\sigma_2 + \rm{h_2}\sigma_2^2 \\ \rm{h_3} \sigma_1^2 + \rm{h_4} \sigma_1\sigma_2 &amp; \rm{h_3} \sigma_1\sigma_2 + \rm{h_4} \sigma_2^2 \end{array} \right]</code>
</p>

<p style="text-align: center;"><code class="reqn"> = \frac{1}{2}(\rm{h_1}\sigma_1^2 + \rm{h_2}\sigma_1\sigma_2 + \rm{h_3}\sigma_1\sigma_2 + \rm{h_4}\sigma_2^2) = \frac{1}{2!} \left(\sum_{i=1}^2 \frac{\partial}{\partial x_i} \sigma_i \right)^2 \it f</code>
</p>
 
<p><br><b>Second-order variance:</b> <code class="reqn">\sigma_y^2 = {\color{red} \nabla\mathbf{\Sigma}\nabla^T} + {\color{blue} \frac{1}{2}\rm{tr}(\mathbf{H\Sigma H\Sigma)}}</code>:<br></p>
<p style="text-align: center;"><code class="reqn">{\color{blue}\frac{1}{2} \rm{tr} \left[ \begin{array}{cc} \rm{h_1} &amp; \rm{h_2} \\ \rm{h_3} &amp; \rm{h_4} \end{array} \right] \left[ \begin{array}{cc} \rm{\sigma_1^2} &amp; \rm{\sigma_1\sigma_2} \\ \rm{\sigma_2\sigma_1} &amp; \rm{\sigma_2^2} \end{array} \right] \left[ \begin{array}{cc} \rm{h_1} &amp; \rm{h_2} \\ \rm{h_3} &amp; \rm{h_4} \end{array} \right] \left[ \begin{array}{cc} \rm{\sigma_1^2} &amp; \rm{\sigma_1\sigma_2} \\ \rm{\sigma_2\sigma_1} &amp; \rm{\sigma_2^2} \end{array} \right]} = \ldots</code>
</p>

<p style="text-align: center;"><code class="reqn">= \frac{1}{2} (\rm{h_1}^2\sigma_1^4 + \rm{2h_1h_2}\sigma_1^3\sigma_2 + \rm{2h_1h_3}\sigma_1^3\sigma_2 + \rm{h_2}^2\sigma_1^2\sigma_2^2 + \rm{2h_2h_3}\sigma_1^2\sigma_2^2 + \rm{h_3}^2\sigma_1^2\sigma_2^2 + \rm{2h_1h_4}\sigma_1^2\sigma_2^2</code>
</p>

<p style="text-align: center;"><code class="reqn">+ \rm{2h_2h_4}\sigma_1\sigma_2^3 + \rm{2h_3h_4}\sigma_1\sigma_2^3 + \rm{h_4}^2\sigma_2^4 = \frac{1}{2} (\rm{h_1}\sigma_1^2 + \rm{h_2}\sigma_1\sigma_2 + \rm{h_3}\sigma_1\sigma_2 + \rm{h_4}\sigma_2^2)^2</code>
</p>

<p style="text-align: center;"><code class="reqn">= \frac{1}{2!} \left( \left(\sum_{i=1}^2 \frac{\partial}{\partial x_i} \sigma_i \right)^2 \it f \right)^2</code>
</p>

<p><br>
with <code class="reqn">\mathrm{E}(y)</code> = expectation of <code class="reqn">y</code>, <code class="reqn">\mathbf{\sigma_y^2}</code> = variance of <code class="reqn">y</code>, <code class="reqn">{\color{red} \nabla}</code> = the p x n gradient matrix with all partial first derivatives <code class="reqn">{\color{red} \rm{j_i}}</code>, <code class="reqn">\mathbf{\Sigma}</code> = the p x p covariance matrix, <code class="reqn">{\color{blue}\mathbf{H}}</code> the Hessian matrix with all partial second derivatives <code class="reqn">{\color{blue} \rm{h_i}}</code>, <code class="reqn">\sigma_i</code> = the uncertainties and <code class="reqn">\rm{tr}(\cdot)</code> = the trace (sum of diagonal) of a matrix. Note that because the Hessian matrices are symmetric, <code class="reqn">{\color{blue} \rm{h_2}} = {\color{blue} \rm{h_3}}</code>. For a detailed derivation, see 'References'.<br>
The second-order Taylor expansion corrects for bias in nonlinear expressions as the first-order Taylor expansion assumes linearity around <code class="reqn">\bar{x}_i</code>. There is also a Python library available for second-order error propagation ('soerp', <a href="https://pypi.python.org/pypi/soerp">https://pypi.python.org/pypi/soerp</a>). The 'propagate' package gives <b>exactly</b> the same results, see last example under "Examples".<br>
Depending on the input expression, the uncertainty propagation may result in an error that is not normally distributed. The Monte Carlo simulation, starting with a symmetric t-distributions of the variables, can clarify this. For instance, a high tendency from deviation of normality is encountered in formulas in which the error of the denominator is relatively large or in exponential models with a large error in the exponent.<br></p>
<p>For setups in which there is no symbolic derivation possible (i.e. <code>e &lt;- expression(abs(x))</code> =&gt; "Function 'abs' is not in the derivatives table") the function automatically switches from symbolic (using <code>makeGrad</code> or <code>makeHess</code>) to numeric (<code>numGrad</code> or <code>numHess</code>) differentiation.<br></p>
<p>The function will try to evaluate the expression in an environment using <code>eval</code> which results in a significant speed enhancement (~ 10-fold). If that fails, evaluation is done over the rows of the simulated data using <code>apply</code>.
</p>
<p><code>cov</code> is used in the following ways:<br>
1) If <code class="reqn">\mu_i, \sigma_i</code> are supplied, a covariance matrix is built with diagonals <code class="reqn">\sigma_i^2</code>, independent of <code>cov = TRUE, FALSE</code>.<br>
2) When simulated data is supplied, a covariance matrix is constructed that either has (<code>cov = TRUE</code>) or has not (<code>cov = FALSE</code>) off-diagonal covariances.<br>
3) The user can supply an own covariance matrix <code class="reqn">\Sigma</code>, with the same column/row names as in <code>data</code>.
</p>
<p>The expanded uncertainty used for constructing the confidence interval is calculated from the Welch-Satterthwaite degrees of freedom <code class="reqn">\nu_{\mathrm{WS}}</code> of the <code>WelchSatter</code> function.
</p>


<h3>Value</h3>

<p>A list with the following components:   
</p>
<table>
<tr style="vertical-align: top;">
<td><code>gradient</code></td>
<td>
<p>the symbolic gradient vector <code class="reqn">\nabla</code> of partial first-order derivatives.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>evalGrad</code></td>
<td>
<p>the evaluated gradient vector <code class="reqn">\nabla</code> of partial first-order derivatives, also known as the "sensitivity". See <code>summary.propagate</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hessian</code></td>
<td>
<p>the symbolic Hessian matrix <code class="reqn">\mathbf{H}</code> of partial second-order derivatives.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>evalHess</code></td>
<td>
<p>the evaluated Hessian matrix <code class="reqn">\mathbf{H}</code> of partial second-order derivatives.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rel.contr</code></td>
<td>
<p>the relative contribution matrix, see <code>summary.propagate</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>covMat</code></td>
<td>
<p>the covariance matrix <code class="reqn">\mathbf{\Sigma}</code> used for Monte Carlo simulation and uncertainty propagation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ws.df</code></td>
<td>
<p>the Welch-Satterthwaite degrees of freedom <code class="reqn">\nu_{\mathrm{ws}}</code>, as obtained from <code>WelchSatter</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>the coverage factor <code class="reqn">k</code>, as calculated by <code class="reqn">t(1-(\alpha/2), \nu_{\mathrm{ws}})</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>u.exp</code></td>
<td>
<p>the expanded uncertainty, <code class="reqn">k\sigma(y)</code>, where <code class="reqn">\sigma(y)</code> is derived either from the second-order uncertainty, if successfully calculated, or first-order otherwise.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>resSIM</code></td>
<td>
<p>a vector containing the <code>nsim</code> values obtained from the row-wise expression evaluations <code class="reqn">f(x_{m, i})</code> of the simulated data in <code>datSIM</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>datSIM</code></td>
<td>
<p>a vector containing the <code>nsim</code> simulated multivariate values for each variable in column format.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prop</code></td>
<td>
<p>a summary vector containing first-/second-order expectations and uncertainties as well as the confidence interval based on <code>alpha</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sim</code></td>
<td>
<p>a summary vector containing the mean, standard deviation, median, MAD as well as the confidence interval based on <code>alpha</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>expr</code></td>
<td>
<p>the original expression <code>expr</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>the original data <code>data</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>the otiginal <code>alpha</code>.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p><b>Error propagation (in general):</b><br>
An Introduction to error analysis.<br>
Taylor JR.<br>
University Science Books (1996), New York.
</p>
<p>Evaluation of measurement data - Guide to the expression of uncertainty in measurement.<br>
JCGM 100:2008 (GUM 1995 with minor corrections).<br><a href="http://www.bipm.org/utils/common/documents/jcgm/JCGM_100_2008_E.pdf">http://www.bipm.org/utils/common/documents/jcgm/JCGM_100_2008_E.pdf</a>.
</p>
<p>Evaluation of measurement data - Supplement 1 to the Guide to the expression of uncertainty in measurement - Propagation of distributions using a Monte Carlo Method.<br>
JCGM 101:2008.<br><a href="http://www.bipm.org/utils/common/documents/jcgm/JCGM_101_2008_E.pdf">http://www.bipm.org/utils/common/documents/jcgm/JCGM_101_2008_E.pdf</a>.
</p>
<p><b>Higher-order Taylor expansion:</b><br>
On higher-order corrections for propagating uncertainties.<br>
Wang CM &amp; Iyer HK.<br><em>Metrologia</em> (2005), <b>42</b>: 406-410.
</p>
<p>Propagation of uncertainty: Expressions of second and third order uncertainty with third and fourth moments.<br>
Mekid S &amp; Vaja D.<br><em>Measurement</em> (2008), <b>41</b>: 600-609.
</p>
<p><b>Matrix algebra for error propagation:</b><br>
An Introduction to Error Propagation: Derivation, Meaning and Examples of Equation Cy = FxCxFx^t.<br><a href="www.nada.kth.se/~kai-a/papers/arrasTR-9801-R3.pdf">www.nada.kth.se/~kai-a/papers/arrasTR-9801-R3.pdf</a>.
</p>
<p>Second order nonlinear uncertainty modeling in strapdown integration using MEMS IMUs.<br>
Zhang M, Hol JD, Slot L, Luinge H.<br>
2011 Proceedings of the 14th International Conference on Information Fusion (FUSION) (2011).
</p>
<p>Uncertainty propagation in non-linear measurement equations.<br>
Mana G &amp; Pennecchi F.<br><em>Metrologia</em> (2007), <b>44</b>: 246-251.
</p>
<p>A compact tensor algebra expression of the law of propagation of uncertainty.<br>
Bouchot C, Quilantan JLC, Ochoa JCS.<br><em>Metrologia</em> (2011), <b>48</b>: L22-L28.
</p>
<p>Nonlinear error propagation law.<br>
Kubacek L.<br><em>Appl Math</em> (1996), <b>41</b>: 329-345.
</p>
<p><b>Monte Carlo simulation (normal- and t-distribution):</b><br>
MUSE: computational aspects of a GUM supplement 1 implementation.<br>
Mueller M, Wolf M, Roesslein M.<br><em>Metrologia</em> (2008), <b>45</b>: 586-594.
</p>
<p>Copulas for uncertainty analysis.<br>
Possolo A.<br><em>Metrologia</em> (2010), <b>47</b>: 262-271.
</p>
<p><b>Multivariate normal distribution:</b><br>
Stochastic Simulation.<br>
Ripley BD.<br>
Stochastic Simulation (1987). Wiley. Page 98.
</p>
<p><b>Testing for normal distribution:</b><br>
Testing for  Normality.<br>
Thode Jr. HC.<br>
Marcel Dekker (2002), New York.
</p>
<p>Approximating the Shapiro-Wilk W-test for non-normality.<br>
Royston P.<br><em>Stat Comp</em> (1992), <b>2</b>: 117-119.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## In these examples, 'nsim = 100000' to save
## Rcmd check time (CRAN). It is advocated
## to use at least 'nsim = 1000000' though...

## Example without given degrees-of-freedom.
EXPR1 &lt;- expression(x/y)
x &lt;- c(5, 0.01)
y &lt;- c(1, 0.01)
DF1 &lt;- cbind(x, y)
RES1 &lt;- propagate(expr = EXPR1, data = DF1, type = "stat", 
                  do.sim = TRUE, verbose = TRUE, 
                  nsim = 100000)
RES1

## Same example with given degrees-of-freedom
## =&gt; third row in input 'data'.
EXPR2 &lt;- expression(x/y)
x &lt;- c(5, 0.01, 12)
y &lt;- c(1, 0.01, 5)
DF2 &lt;- cbind(x, y)
RES2 &lt;- propagate(expr = EXPR2, data = DF2, type = "stat", 
                  do.sim = TRUE, verbose = TRUE,
                  nsim = 100000)
RES2

## With the 'summary' function, we can get the
## Welch-Satterthwaite DF's, coverage, expanded uncertainty,
## Gradient and Hessian matrix etc.
summary(RES2)

## Example using a recursive function:
## no Taylor expansion possible, only Monte-Carlo.
a &lt;- c(5, 0.1)
b &lt;- c(100, 2)
DAT &lt;- cbind(a, b)

f &lt;- function(a, b) {
  N &lt;- 0
  for (i in 1:100) {
    N &lt;- N + i * log(a) + b^(1/i)
  }
  return(N)
}

propagate(f, DAT, nsim = 100000)

## Not run: 
################# GUM 2008 (1) ########################
## Example in Annex H.1 from the GUM 2008 manual
## (see 'References'), an end gauge calibration
## study. We use only first-order error propagation,
## with total df = 16 and alpha = 0.01, 
## as detailed in GUM H.1.6.
EXPR3 &lt;- expression(ls + d - ls * (da * the + as * dt))
ls &lt;- c(50000623, 25)
d &lt;- c(215, 9.7)
da &lt;- c(0, 0.58E-6)
the &lt;- c(-0.1, 0.41)
as &lt;- c(11.5E-6, 1.2E-6)
dt &lt;- c(0, 0.029)
DF3 &lt;- cbind(ls, d, da, the, as, dt)
RES3 &lt;- propagate(expr = EXPR3, data = DF3, second.order = FALSE,
                  df = 16, alpha = 0.01)
RES3
## propagate: sd.1 = 31.71 
## GUM H.1.4/H.6c: u = 32  

## Expanded uncertainty, from summary function.
summary(RES3)
## propagate: 92.62
## GUM H.1.6: 93

## Proof that covariance of Monte-Carlo
## simulated dataset is "fairly"" the same 
## as from initial data.
RES3$covMat
cov(RES3$datSIM)
all.equal(RES3$covMat, cov(RES3$datSIM))

## Now using second-order Taylor expansion.
RES4 &lt;- propagate(expr = EXPR3, data = DF3)
RES4
## propagate: sd.2 = 33.91115
## GUM H.1.7: u = 34.
## Also similar to the non-matrix-based approach
## in Wang et al. (2005, page 408): u1 = 33.91115.
## NOTE: After second-order correction ("sd.2"), 
## uncertainty is more similar to the uncertainty
## obtained from Monte Carlo simulation!

#################### GUM 2008 (2) #################
## Example in Annex H.2 from the GUM 2008 manual
## (see 'References'), simultaneous resistance
## and reactance measurement.
data(H.2)

## This gives exactly the means, uncertainties and
## correlations as given in Table H.2:
colMeans(H.2)
sqrt(colVarsC(H.2))/sqrt(5)
cor(H.2)

## H.2.3 Approach 1 using mean values and
## standard uncertainties:
EXPR6a &lt;- expression((V/I) *  cos(phi)) ## R
EXPR6b &lt;- expression((V/I) *  sin(phi)) ## X
EXPR6c &lt;- expression(V/I) ## Z
MEAN6 &lt;- colMeans(H.2)
SD6 &lt;- sqrt(colVarsC(H.2))
DF6 &lt;- rbind(MEAN6, SD6)
COV6ab &lt;- cov(H.2) ## covariance matrix of V, I, phi
COV6c &lt;- cov(H.2[, 1:2])  ## covariance matrix of V, I

RES6a &lt;- propagate(expr = EXPR6a, data = DF6, cov = COV6ab)
RES6b &lt;- propagate(expr = EXPR6b, data = DF6, cov = COV6ab)
RES6c &lt;- propagate(expr = EXPR6c, data = DF6[, 1:2], 
                   cov = COV6c)

## This gives exactly the same values of mean and sd/sqrt(5)
## as given in Table H.4.
RES6a$prop # 0.15892/sqrt(5) = 0.071
RES6b$prop # 0.66094/sqrt(5) = 0.296
RES6c$prop # 0.52846/sqrt(5) = 0.236

######### GUM 2008 Supplement 1 (1) #######################
## Example from 9.2.2 of the GUM 2008 Supplement 1
## (see 'References'), normally distributed input
## quantities. Assign values as in 9.2.2.1.
EXPR7 &lt;- expression(X1 + X2 + X3 + X4)
X1 &lt;- c(0, 1)
X2 &lt;- c(0, 1)
X3 &lt;- c(0, 1)
X4 &lt;- c(0, 1)
DF7 &lt;- cbind(X1, X2, X3, X4)
RES7 &lt;- propagate(expr = EXPR7, data = DF7, nsim = 1E5)
## This will give exactly the same results as in 
## 9.2.2.6, Table 2.
RES7

######### GUM 2008 Supplement 1 (2) #######################
## Example from 9.3 of the GUM 2008 Supplement 1
## (see 'References'), mass calibration.
## Formula 24 in 9.3.1.3 and values as in 9.3.1.4, Table 5.
EXPR8 &lt;- expression((Mrc + dMrc) * (1 + (Pa - Pa0) * ((1/Pw) - (1/Pr))) - Mnom)
Mrc &lt;- rnorm(1E5, 100000, 0.050)
dMrc &lt;- rnorm(1E5, 1.234, 0.020)
Pa &lt;- runif(1E5, 1.10, 1.30)  ## E(Pa) = 1.2, (b-a)/2 = 0.1 
Pw &lt;- runif(1E5, 7000, 9000)  ## E(Pw) = 8000, (b-a)/2 = 1000
Pr &lt;- runif(1E5, 7950, 8050) ## E(Pr) = 8000, (b-a)/2 = 50
Pa0 &lt;- 1.2 
Mnom &lt;- 100000
DF8 &lt;- cbind(Mrc, dMrc, Pa, Pw, Pr, Pa0, Mnom)
RES8 &lt;- propagate(expr = EXPR8, data = DF8, nsim = 1E5)
## This will give exactly the same results as in 
## 9.3.2.3, Table 6
RES8
RES8
 
######### GUM 2008 Supplement 1 (3) #######################
## Example from 9.4 of the GUM 2008 Supplement 1
## (see 'References'), comparioson loss in microwave
## power meter calibration, zero covariance.
## Formula 28 in 9.4.1.5 and values as in 9.4.1.7.
EXPR9 &lt;- expression(X1^2 - X2^2)
X1 &lt;- c(0.050, 0.005)
X2 &lt;- c(0, 0.005)
DF9 &lt;- cbind(X1, X2)
RES9a &lt;- propagate(expr = EXPR9, data = DF9, nsim = 1E5)
## This will give exactly the same results as in 
## 9.4.2.2.7, Table 8, x1 = 0.050.
RES9a

## Using covariance matrix with r(x1, x2) = 0.9
## We convert to covariances using cor2cov.
COR9 &lt;- matrix(c(1, 0.9, 0.9, 1), nrow = 2)
COV9 &lt;- cor2cov(COR9, c(0.005^2, 0.005^2))
colnames(COV9) &lt;- c("X1", "X2")
rownames(COV9) &lt;- c("X1", "X2")
RES9b &lt;- propagate(expr = EXPR9, data = DF9, cov = COV9)
## This will give exactly the same results as in 
## 9.4.3.2.1, Table 9, x1 = 0.050.
RES9b

######### GUM 2008 Supplement 1 (4) #######################
## Example from 9.5 of the GUM 2008 Supplement 1
## (see 'References'), gauge block calibration.
## Assignment of PDF's as in Table 10 of 9.5.2.1.
EXPR10 &lt;- expression(Ls + D + d1 + d2 - Ls *(da *(t0 + Delta) + as * dt) - Lnom)
Lnom &lt;- 50000000
Ls &lt;- propagate:::rst(1000000, mean = 50000623, sd  = 25, df = 18)
D &lt;- propagate:::rst(1000000, mean = 215, sd = 6, df = 25)
d1 &lt;- propagate:::rst(1000000, mean = 0, sd = 4, df = 5)
d2 &lt;- propagate:::rst(1000000, mean = 0, sd = 7, df = 8)
as &lt;- runif(1000000, 9.5E-6, 13.5E-6)
t0 &lt;- rnorm(1000000, -0.1, 0.2)
Delta &lt;- propagate:::rarcsin(1000000, -0.5, 0.5)
da &lt;- propagate:::rctrap(1000000, -1E-6, 1E-6, 0.1E-6)
dt &lt;- propagate:::rctrap(1000000, -0.050, 0.050, 0.025)
DF10 &lt;- cbind(Ls, D, d1, d2, as, t0, Delta, da, dt, Lnom)
RES10 &lt;- propagate(expr = EXPR10, data = DF10, cov = FALSE, alpha = 0.01)
RES10
## This gives the same results as in 9.5.4.2, Table 11.
## However: results are exacter than in the GUM 2008
## manual, especially when comparing sd(Monte Carlo) with sd.2!
## GUM 2008 gives 32 and 36, respectively.
RES10

########## Comparison to Pythons 'soerp' ###################
## Exactly the same results as under 
## https://pypi.python.org/pypi/soerp ! 
EXPR11 &lt;- expression(C * sqrt((520 * H * P)/(M *(t + 460))))
H &lt;- c(64, 0.5)
M &lt;- c(16, 0.1)
P &lt;- c(361, 2)
t &lt;- c(165, 0.5)
C &lt;- c(38.4, 0) 
DAT11 &lt;- makeDat(EXPR11)
RES11 &lt;- propagate(expr = EXPR11, data = DAT11) 
RES11

## End(Not run)   
</code></pre>


</div>