<div class="container">

<table style="width: 100%;"><tr>
<td>LCplfm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Latent class probabilistic feature analysis of three-way three-mode binary data</h2>

<h3>Description</h3>

<p>Computation of parameter estimates, standard errors, criteria for model selection, and measures of descriptive fit for 
disjunctive, conjunctive and additive latent class probabilistic  feature models.</p>


<h3>Usage</h3>

<pre><code class="language-R">  
LCplfm(data,F=2,T=2,M=5,maprule="disj",emcrit1=1e-3,emcrit2=1e-8,
       model=1,start.objectparameters=NULL,start.attributeparameters=NULL,
       start.sizeparameters=NULL,delta=0.0001,printrun=FALSE,
       update.objectparameters=NULL,update.attributeparameters=NULL,
       Nbootstrap=2000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A <em>I X J X K</em> data array of binary observations. Observation <em>(i,j,k)</em> <em>(i=1,..,I; j=1,..,J; k=1,..,K)</em>  indicates 
whether object <em>j</em> is associated to attribute <em>k</em> according to rater <em>i</em>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>F</code></td>
<td>
<p>The number of latent features included in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>T</code></td>
<td>
<p>The number of latent classes included in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>M</code></td>
<td>
<p>The number of times a particular model is estimated using random starting points.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maprule</code></td>
<td>
<p>Disjunctive (<code>maprule</code>="disj"), conjunctive (<code>maprule</code>="conj") or additive (<code>maprule</code>="add") mapping rule of the probabilistic latent feature model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>emcrit1</code></td>
<td>
<p>Convergence criterion to be used for the estimation of candidate models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>emcrit2</code></td>
<td>
<p>Convergence criterion to be used for the estimation of the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>The type of dependency and heterogeneity assumption included in the model. <code>model</code>=1, <code>model</code>=2, <code>model</code>=3 represent models with a constant 
object-feature classification per person and with, respectively, class-specific object parameters, class-specific attribute parameters, 
and class-specific object- and attribute parameters. <code>model</code>=4, <code>model</code>=5, <code>model</code>=6 represent models with a constant 
attribute-feature classification per person and with, respectively, class-specific object parameters, class-specific attribute parameters, 
and class-specific object- and attribute parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start.objectparameters</code></td>
<td>
<p>An array of object parameters to be used as starting value for each run.
The size of the array equals <em>J x F x T x M</em>  when <code>model = 1,4,3,6</code> and 
<em>J x F x M</em> when <code>model = 2,5</code>.  
If <code>start.objectparameters=NULL</code> randomly generated object parameters 
are used as starting values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start.attributeparameters</code></td>
<td>
<p>An  array of attribute parameters to be used as starting value for each run. 
The size of the array equals <em>K x F x T x M</em>  when <code>model = 2,5,3,6</code> 
and <em>K x F x M</em> when <code>model = 1,3</code>. 
If <code>start.attributeparameters=NULL</code> randomly generated attribute parameters 
are used as starting values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start.sizeparameters</code></td>
<td>
<p>A <em>T x M</em> matrix of latent class size parameters to be used as starting value for each run. 
If <code>start.sizeparameters=NULL</code> randomly  generated class size parameters are used 
as starting values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta</code></td>
<td>
<p>The precision used to compute standard errors of the parameters with the method of finite differences.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>printrun</code></td>
<td>
<p><code>printrun</code>=TRUE prints the analysis type (disjunctive, conjunctive, additive), the number of features (<em>F</em>), the number of latent classes (<em>T</em>) 
and the number of the run to the output screen, whereas <code>printrun</code>=FALSE suppresses the printing.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>update.objectparameters</code></td>
<td>
<p>A binary valued array that indicates for each object parameter whether it has to be 	estimated 
from the data or constrained to the starting value. A value of 1 means that the corresponding object parameter is estimated and 
a value of 0 means that the corresponding object parameter is constrained to the starting value provided by the user.
The size of the array equals <em>J x F x T</em>  when <code>model = 1,4,3,6</code> and <em>J x F</em> when <code>model = 2,5</code>.  
If <code>update.objectparameters</code> <code>= NULL</code> all object parameters are estimated from the data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>update.attributeparameters</code></td>
<td>
<p>A binary valued array that indicates for each attribute parameter whether it has to be estimated 
from the data or constrained to the starting value. A value of 1 means that the corresponding attribute parameter is estimated and 
a value of 0 means that the corresponding attribute parameter is constrained to the starting value provided by the user.
The size of the array equals <em>K x F x T</em>  when <code>model = 2,5,3,6</code> and <em>K x F</em> when <code>model = 1,3</code>.  
If <code>update.attributeparameters</code> <code>= NULL</code> all attribute parameters are estimated from the data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Nbootstrap</code></td>
<td>
<p>Number of bootstrap iterations to be used for simulating the reference distribution of odds-ratio dependency measures.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><em>Estimation</em>
The estimation algorithm includes two steps. In a first exploratory step an EM algorithm is used to conduct <code>M</code> runs using random starting points. Each exploratory run is 
terminated if the convergence criterium (i.e., the sum of absolute differences between parameter values in subsequent iterations) is smaller than <code>emcrit1</code>. In a second step, 
the best solution  among the <code>M</code> runs (i.e., with the highest posterior density) is used as the starting point of the EM algorithm for conducting a final analysis. The final 
analysis is terminated if the convergence criterion <code>emcrit2</code> is smaller than the convergence criterion. 
</p>
<p><em>Model selection criteria, goodness-of-fit and statistical dependency measures</em>
</p>
<p>To choose among models with different numbers of features, or with different mapping rules, 
one may use information criteria such as the Akaike Information Criterion (AIC, Akaike, 1973, 1974),
or the Schwarz Bayesian Information Criterion (BIC, Schwarz, 1978). AIC and BIC are computed as <em>-2*loglikelihood+k*Npar</em>.
For AIC <em>k</em> equals 2 and for BIC <em>k</em> equals <em>log(N)</em>, with <em>N</em> the observed number of replications (<em>I</em>) 
for which object-attribute associations are collected. <em>Npar</em> represents the number of model parameters.
Models with the lowest value for AIC or BIC should be selected.
</p>
<p>The descriptive goodness-of-fit of the model is assessed with the correlation between observed and expected frequencies in the <em>J X K</em> table, 
and the proportion of the variance in the observed frequencies accounted for by the model (VAF)
(i.e. the squared correlation between observed and expected frequencies).
</p>
<p>To assess to which extent the model can capture observed statistical dependencies between object-attribute pairs with a common object or attribute, a parametric 
bootstrap procedure is used to evaluate whether observed dependencies are within the simulated 95 or 99 percent confidence interval. Let <em>D(i,j,k)</em> be equal to 1 if rater i
indicates that object <em>j</em> is associated to attribute <em>k</em>. The statistical dependency between pairs <em>(j,k)</em> and <em>(j*,k*)</em> is measured with the odds ratio (OR) statistic: 
</p>
<p style="text-align: center;"><code class="reqn">OR(j,k,j^{*},k^{*})=\mbox{log}\left\lbrack\frac{N_{11}*N_{00}}{N_{10}*N_{01}}\right\rbrack</code>
</p>

<p>with 
</p>
<p style="text-align: center;"><code class="reqn">N_{11}=\sum_i D(i,j,k) D(i,j^{*},k^{*}) +0.5</code>
</p>

<p style="text-align: center;"><code class="reqn">N_{00}=\sum_i (1-D(i,j,k)) (1-D(i,j^{*},k^{*})) +0.5</code>
</p>
 
<p style="text-align: center;"><code class="reqn">N_{10}=\sum_i D(i,j,k) (1-D(i,j^{*},k^{*})) +0.5</code>
</p>

<p style="text-align: center;"><code class="reqn">N_{01}=\sum_i (1-D(i,j,k)) D(i,j^{*},k^{*}) +0.5</code>
</p>

<p>The model selection criteria AIC and BIC, the descriptive goodness-of-fit measures  (correlation observed and expected frequencies, and VAF) and a summary of the OR dependency measures 
(i.e., proportion of observed OR dependencies of a certain type that are in the simulated 95 or 99 percent confidence interval) are stored in the object <code>fitmeasures</code> of the output list
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>Parameters used to call the function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logpost.runs</code></td>
<td>
<p>A list with the logarithm of the posterior density for each of the <em>M</em> computed models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>best</code></td>
<td>
<p>An index which indicates the model with the highest posterior density among each of the <em>M</em> computed models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>objpar</code></td>
<td>
<p>Estimated object parameters for the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>attpar</code></td>
<td>
<p>Estimated attribute parameters for the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sizepar</code></td>
<td>
<p>A vector of <code>T</code> class size parameters for the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>SE.objpar</code></td>
<td>
<p>Estimated standard errors for the object parameters of the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>SE.attpar</code></td>
<td>
<p>Estimated standard errors for the attribute parameters of the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>SE.sizepar</code></td>
<td>
<p>Estimated standard errors for the class size parameters  of the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gradient.objpar</code></td>
<td>
<p>Gradient of the object parameters for the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gradient.attpar</code></td>
<td>
<p>Gradient of the attribute parameters for the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gradient.sizepar</code></td>
<td>
<p>Gradient of the class size parameters for the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitmeasures</code></td>
<td>
<p>A list of model selection criteria, goodness-of-fit measures and OR dependency measures for the model with the highest posterior density.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>postprob</code></td>
<td>
<p>A <em>I X T</em> matrix of posterior probabilities for the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>margprob.JK</code></td>
<td>
<p>A <em>J X K</em> matrix of marginal object-attribute association probabilities.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>condprob.JKT</code></td>
<td>
<p>A <em>J X K X T</em> array of conditional object-attribute association probabilities (i.e., probability of object-attribute association given latent class membership).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>report.OR.attpair</code></td>
<td>
<p>A matrix that contains for all attribute pairs per object the observed OR dependency (OR.obs), the expected OR dependency (OR.mean) 
and the upper and lower bounds of the corresponding simulated 95 and 99 percent confidence interval (OR.p025, OR.p975, OR.p005, OR.p995).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>report.OR.objpair</code></td>
<td>
<p>A matrix that contains for all object pairs per attribute the observed OR dependency (OR.obs), the expected OR dependency (OR.mean) 
and the upper and lower bounds of the corresponding simulated 95 and 99 percent confidence interval (OR.p025, OR.p975, OR.p005, OR.p995).</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Michel Meulders and Philippe De Bruecker
</p>


<h3>References</h3>

<p>Akaike, H. (1973). Information theory and an extension of the maximum likelihood
principle. In B. N. Petrov and F. Csaki (Eds.), <em>Second international symposium on
information theory</em> (p. 271-283). Budapest: Academiai Kiado.
</p>
<p>Akaike, H. (1974). A new look at the statistical model identification. <em>IEEE Transactions
on Automatic Control, 19</em>, 716-723.
</p>
<p>Candel, M. J. J. M., and Maris, E. (1997). Perceptual analysis of two-way two-mode
frequency data: probability matrix decomposition and two alternatives.
<em>International Journal of Research in Marketing, 14</em>, 321-339.
</p>
<p>Louis, T. A. (1982). Finding observed information using the em algorithm. <em>Journal of the
Royal Statistical Society, Series B, 44</em>, 98-130.
</p>
<p>Maris, E. (1999). Estimating multiple classification latent class models. <em>Psychometrika, 64</em>, 187-212.
</p>
<p>Maris, E., De Boeck, P., and Van Mechelen, I. (1996). Probability matrix decomposition models. <em>Psychometrika, 61</em>, 7-29.
</p>
<p>Meulders, M., De Boeck, P., and Van Mechelen, I. (2001). Probability matrix decomposition
models and main-effects generalized linear models for the analysis of replicated
binary associations. <em>Computational Statistics and Data Analysis, 38</em>, 217-233.
</p>
<p>Meulders, M., De Boeck, P., Van Mechelen, I., Gelman, A., and Maris, E. (2001). Bayesian inference with probability matrix decomposition models. 
<em>Journal of Educational and Behavioral Statistics, 26</em>, 153-179.
</p>
<p>Meulders, M., De Boeck, P., Van Mechelen, I., and Gelman, A. (2005). Probabilistic feature analysis of facial perception of emotions. 
<em>Applied Statistics, 54</em>, 781-793.
</p>
<p>Meulders, M. and De Bruecker, P. (2018). Latent class probabilistic latent feature analysis of three-way three-mode binary data. 
<em>Journal of Statistical Software, 87(1)</em>, 1-45.
</p>
<p>Meulders, M. (2013). An R Package for Probabilistic Latent Feature Analysis of Two-Way Two-Mode Frequencies. <em>Journal of Statistical Software, 54(14)</em>, 1-29. 
URL http://www.jstatsoft.org/v54/i14/.
</p>
<p>Meulders, M., Tuerlinckx, F., and Vanpaemel, W. (2013). Constrained multilevel latent class models for the analysis of three-way three-mode binary data. 
<em>Journal of Classification, 30 (3)</em>, 306-337.
</p>
<p>Tanner, M. A. (1996). <em>Tools for statistical inference: Methods for the exploration of
posterior distributions and likelihood functions</em> (Third ed.). New York:
Springer-Verlag.
</p>
<p>Tatsuoka, K. (1984). <em>Analysis of errors in fraction addition and subtraction problems</em>. Final Report for NIE-G-81-0002, University of Illinois, Urbana-Champaign. 
</p>
<p>Schwarz, G. (1978). Estimating the dimensions of a model. <em>Annals of Statistics, 6</em>, 461-464.
</p>


<h3>See Also</h3>

<p><code>print.LCplfm</code></p>


<h3>Examples</h3>

<pre><code class="language-R">
## Not run: 

# example 1: analysis on determinants of anger-related behavior

# load anger data
data(anger)

# estimate a disjunctive LCplfm model with F=2 and T=2 
# assume constant situation-feature classification
# and class-specific situation parameters (i.e. model 1)
# use 10 exploratory runs with random starting points 
anger.LCplfm.disj&lt;-LCplfm(data=anger$data,F=2, T=2, M=10)

# print the output of the model 
print (anger.LCplfm.disj)


# estimate an additive LCplfm model with F=2 and T=2 
# assume constant situation-feature classification
# and class-specific situation parameters (i.e. model 1)
# use 10 exploratory runs with random starting points 
anger.LCplfm.add&lt;-LCplfm(data=anger$data,F=2, T=2, M=10, maprule="add")

# print the output of the model 
print (anger.LCplfm.add)


# estimate a disjunctive LCplfm model with F=4 and T=2
# assume constant situation-feature classifications
# and class-specific situation parameters (i.e. model 1)
# use 20 exploratory runs with random starting points (M=20)
# constrain parameters of subsequent behavior pairs to "load"
# on only one feature

# specify which attribute parameters have to be estimated from the data
update.attribute&lt;-matrix(rep(0,8*4),ncol=4)
update.attribute[1:2,1]&lt;-c(1,1)
update.attribute[3:4,2]&lt;-c(1,1)
update.attribute[5:6,3]&lt;-c(1,1)
update.attribute[7:8,4]&lt;-c(1,1)

# specify starting values for attribute parameters in each of M=20 runs
# for parameters with update.attribute==0 starting values are constrained to 1e-6
# for parameters with update.attribute==1 starting values are sampled from a unif(0,1)
start.attribute&lt;-array(runif(8*4*20),c(8,4,20))
start.attribute[update.attribute%o%rep(1,20)==0]&lt;-1e-6 

# estimate the constrained model
anger.LCplfm.constr&lt;-LCplfm(data=anger$data,F=4, T=2, M=20, 
                     update.attributeparameters=update.attribute,
                     start.attributeparameters=start.attribute)

# estimate a disjunctive LCplfm model with F=4 and T=2
# assume constant situation-feature classifications
# class-specific situation and bahavior parameters (i.e. model 3)
# use 20 exploratory runs with random starting points (M=20)
# constrain parameters of subsequent behavior pairs to "load"
# on only one feature

# specify which attribute parameters have to be estimated from the data
 
update.attribute&lt;-matrix(rep(0,8*4),ncol=4)
update.attribute[1:2,1]&lt;-c(1,1)
update.attribute[3:4,2]&lt;-c(1,1)
update.attribute[5:6,3]&lt;-c(1,1)
update.attribute[7:8,4]&lt;-c(1,1)
update.attribute&lt;-update.attribute%o%rep(1,2)

# specify starting values for attribute parameters in each of M=20 runs
# for parameters with update.attribute==0 starting values are constrained to 1e-6
# for parameters with update.attribute==1 starting values are sampled from a unif(0,1)
start.attribute&lt;-array(runif(8*4*2*20),c(8,4,2,20))
start.attribute[update.attribute%o%rep(1,20)==0]&lt;-1e-6 

# estimate the constrained model
anger.LCplfm.m3.constr&lt;-LCplfm(data=anger$data,F=4, T=2, M=20, model=3, 
                     update.attributeparameters=update.attribute,
                     start.attributeparameters=start.attribute)


## End(Not run)

## Not run: 
# example 2: analysis of car perception data

# load car data
data(car)

# estimate a disjunctive LCplfm with F=3 and T=2
# assume constant attribute-feature classification
# and class-specific car parameters (i.e. model 4)
# use 10 exploratory runs with random starting points 
car.LCplfm.disj&lt;-LCplfm(data=car$data3w,F=3, T=2, M=10,model=4)

# print the output of the model 
print(car.LCplfm.disj)

# estimate an additive LCplfm with F=3 and T=2
# assume constant attribute-feature classification
# and class-specific car parameters (i.e. model 4)
# use 10 exploratory runs with random starting points 
car.LCplfm.add&lt;-LCplfm(data=car$data3w,F=3, T=2, M=10, model=4, maprule="add")

# print the output of the model 
print(car.LCplfm.add)


## End(Not run)

## Not run: 

# example 3: estimation of multiple classification latent class 
# model (Maris, 1999) for cognitive diagnosis


# load subtraction data
library(CDM)
data(fraction.subtraction.data)
data(fraction.subtraction.qmatrix)


# create three-way data as input for LCplfm
I&lt;-536
J&lt;-1
K&lt;-20
data3w&lt;-array(c(as.matrix(fraction.subtraction.data)),c(I,J,K))

# add item labels

itemlabel&lt;-c("5/3 - 3/4", 
"3/4 - 3/8", 
"5/6 - 1/9",
"3 1/2 - 2 3/2", 
"4 3/5 - 3 4/10", 
"6/7 - 4/7", 
"3 - 2 1/5", 
"2/3 - 2/3", 
"3 7/8 - 2", 
"4 4/12 - 2 7/12", 
"4 1/3 - 2 4/3", 
"1 1/8 - 1/8", 
"3 3/8 - 2 5/6", 
"3 4/5 - 3 2/5", 
"2 - 1/3", 
"4 5/7 - 1 4/7", 
"7 3/5 - 4/5", 
"4 1/10 - 2 8/10", 
"4 - 1 4/3", 
"4 1/3 - 1 5/3") 

dimnames(data3w)[[3]]&lt;-itemlabel

# estimate multiple classification latent class model (Maris, 1999)

set.seed(537982)
subtract.m1.lst&lt;-stepLCplfm(data3w,minF=3,maxF=5,minT=1,maxT=3,model=1,M=20,maprule="conj")


# print BIC values
sumar&lt;-summary(subtract.m1.lst)
as.matrix(sort(sumar[,5]))

# print output best model
subtract.m1.lst[[5,2]]

# correlation between extracted skills and qmatrix
round(cor(fraction.subtraction.qmatrix,subtract.m1.lst[[5,2]]$attpar),2)

## End(Not run)
</code></pre>


</div>