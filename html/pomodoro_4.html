<div class="container">

<table style="width: 100%;"><tr>
<td>GBM_Model</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Gradient Boosting Model</h2>

<h3>Description</h3>

<p>Gradient Boosting Model
</p>


<h3>Usage</h3>

<pre><code class="language-R">GBM_Model(Data, xvar, yvar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Data</code></td>
<td>
<p>The name of the Dataset.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xvar</code></td>
<td>
<p>X variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>yvar</code></td>
<td>
<p>Y variable.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Unlike bagging trees, boosting does not use bootstrap sampling,
rather each tree is fit using information from previous trees.
An event probability of stochastic gradient boosting model is given by
</p>
<p style="text-align: center;"><code class="reqn">\hat{\pi_i} = \frac{1}{1 + exp[-f(x)]^\prime}</code>
</p>

<p>where <code class="reqn">f(x)</code> is in the range of <code class="reqn">[-\infty,\infty]</code> and its initial estimate of the model is
<code class="reqn">f^{(0)}_i=log(\frac{\pi_{i}}{1-\pi_{i}})</code>,
where <code class="reqn">\hat{\pi}</code> is the estimated sample proportion of a single class from the training set.
</p>


<h3>Value</h3>

<p>The output from  <code>GBM_Model</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
yvar &lt;- c("Loan.Type")
sample_data &lt;- sample_data[c(1:120),]
xvar &lt;- c("sex", "married", "age", "havejob", "educ", "political.afl",
"rural", "region", "fin.intermdiaries", "fin.knowldge", "income")
BchMk.GBM &lt;- GBM_Model(sample_data, c(xvar, "networth"), yvar )
BchMk.GBM$finalModel
BchMk.GBM$Roc$auc

</code></pre>


</div>