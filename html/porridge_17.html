<div class="container">

<table style="width: 100%;"><tr>
<td>ridgePgen</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Ridge estimation of the inverse covariance matrix with element-wise penalization and shrinkage.
</h2>

<h3>Description</h3>

<p>Function that evaluates the generalized ridge estimator of the inverse covariance matrix with element-wise penalization and shrinkage. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">ridgePgen(S, lambda, target, nInit=100, minSuccDiff=10^(-10))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>S</code></td>
<td>
<p>           Sample covariance <code>matrix</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>      A symmetric <code>matrix</code> with element-wise positive penalty parameters. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>target</code></td>
<td>
<p>      A semi-positive definite target <code>matrix</code> towards which the estimate is shrunken. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nInit</code></td>
<td>
<p>       A <code>numeric</code> specifying the number of iteration. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minSuccDiff</code></td>
<td>
<p> A <code>numeric</code>: minimum distance between two succesive estimates to be achieved. </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function generalizes the <code>ridgeP</code>-function in the sense that, besides element-wise shrinkage, it allows for element-wise penalization in the estimation of the precision matrix of a zero-mean multivariate normal distribution. Hence, it assumes that the data stem from <code class="reqn">\mathcal{N}(\mathbf{0}_p, \boldsymbol{\Omega}^{-1})</code>. The estimator maximizes the following penalized loglikelihood:
</p>
<p style="text-align: center;"><code class="reqn">
\log( | \boldsymbol{\Omega} |) - \mbox{tr} ( \boldsymbol{\Omega} \mathbf{S} ) - \| \boldsymbol{\Lambda} \circ (\boldsymbol{\Omega} - \mathbf{T}) \|_F^2,
</code>
</p>

<p>where <code class="reqn">\mathbf{S}</code> the sample covariance matrix, <code class="reqn">\boldsymbol{\Lambda}</code> a symmetric, positive matrix of penalty parameters, the <code class="reqn">\circ</code>-operator represents the Hadamard or element-wise multipication, and <code class="reqn">\mathbf{T}</code> the precision matrix' shrinkage target. For more details see van Wieringen (2019).
</p>


<h3>Value</h3>

<p>The function returns a regularized inverse covariance <code>matrix</code>.
</p>


<h3>Author(s)</h3>

<p>W.N. van Wieringen.
</p>


<h3>References</h3>

<p>van Wieringen, W.N. (2019), "The generalized ridge estimator of the inverse covariance matrix", <em>Journal of Computational and Graphical Statistics</em>, 28(4), 932-942.
</p>


<h3>See Also</h3>

<p><code>ridgeP</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># set dimension and sample size
p &lt;- 10
n &lt;- 10

# penalty parameter matrix
lambda       &lt;- matrix(1, p, p)
diag(lambda) &lt;- 0.1

# generate precision matrix
Omega       &lt;- matrix(0.4, p, p)
diag(Omega) &lt;- 1
Sigma       &lt;- solve(Omega)

# data 
Y &lt;- mvtnorm::rmvnorm(n, mean=rep(0,p), sigma=Sigma)
S &lt;- cov(Y)

# unpenalized diagonal estimate
Phat &lt;- ridgePgen(S, lambda, 0*S)
</code></pre>


</div>